{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b8e1e",
   "metadata": {},
   "source": [
    "# Model Training (cavity_claw_RouteMeander_eigenmode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7659a-fe1b-4fdf-8c09-a398e498373b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9418886-6a3f-4473-ae89-53bab6428eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter file is where the hyperparameters are set. \n",
    "# It's reccomended to look at that file first, its interesting and you can set stuff there\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17135-58ce-45e4-9c16-1d1b76f34ea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa89948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, joblib\n",
    "\n",
    "# Disable some console warnings so you can be free of them printing. \n",
    "# Comment the next two lines if you are a professional and like looking at warnings.\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "os.environ.pop(\"TF_XLA_FLAGS\", None)      # disable XLA \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # show warnings/errors while debugging\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf, gc\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float32\") # make the backend use float32 which will be the same as the data--helps speed it up\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35ed7bf-9c4f-41d4-8652-1fe11dd8c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# Input seed value. If this value is the same, the random number generator \n",
    "# will generate the same set of random values every time. We like reproducibility:)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the seed value for reproducibility in tensorflow\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9e65e-f247-4388-a274-6041e8cdcc27",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dc079f-6430-41bc-8342-0cc5ffbe4a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5252479277815712275\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 40538013696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8063713112341099537\n",
      "physical_device_desc: \"device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768584159.309226 2360945 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1768584159.309459 2360945 gpu_device.cc:2020] Created device /device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Look at what you are working with. If you dont have a nice GPU I highly reccomend finding one\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad03d-ae5d-4bc6-b055-3e8579849c5d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0b8c-6699-4caf-b257-abc4f8e49b99",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667c238f-0e0f-4e4c-b185-f76d1ca261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the nice data you saved from the previous notebook, or downloaded from the drive\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        encoding = ENCODING_TYPE.replace(' ','_')\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec9efd-ee93-429d-95b4-4e6efef296db",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb45684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (851, 2)\n",
      "X_val.shape: (182, 2)\n",
      "y_value_train.shape: (851, 16)\n",
      "y_value_val.shape: (182, 16)\n",
      "y_exists_train.shape: (851, 16)\n",
      "y_exists_val.shape: (182, 16)\n",
      "y_value_train[0]: [0.1773399  0.         0.         1.         1.         1.\n",
      " 0.35714286 1.         0.65217391 0.         0.5        0.\n",
      " 0.         1.         1.         0.        ]\n",
      "y_exists_train[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "y_exists_val[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Look at the shapes of training and test sets in case you want to orient yourself\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    print('X_train.shape:', X_train.shape)\n",
    "    print('X_val.shape:', X_val.shape)\n",
    "    print('y_value_train.shape:', y_value_train.shape)\n",
    "    print('y_value_val.shape:', y_value_val.shape)\n",
    "    print('y_exists_train.shape:', y_exists_train.shape)\n",
    "    print('y_exists_val.shape:', y_exists_val.shape)\n",
    "    print('y_value_train[0]:', y_value_train[0])\n",
    "    print('y_exists_train[0]:', y_exists_train[0])\n",
    "    print('y_exists_val[0]:', y_exists_val[0])\n",
    "\n",
    "else:\n",
    "    print('X_train_linear_encoding.shape:', X_train_linear_encoding.shape)\n",
    "    print('X_val_linear_encoding.shape:', X_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding.shape:', y_value_train_linear_encoding.shape)\n",
    "    print('y_value_val_linear_encoding.shape:', y_value_val_linear_encoding.shape)\n",
    "    print('y_exists_train_linear_encoding.shape:', y_exists_train_linear_encoding.shape)\n",
    "    print('y_exists_val_linear_encoding.shape:', y_exists_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding[0]:', y_value_train_linear_encoding[0])\n",
    "    print('y_exists_train_linear_encoding[0]:', y_exists_train_linear_encoding[0])\n",
    "\n",
    "    print('X_train_one_hot_encoding.shape:', X_train_one_hot_encoding.shape)\n",
    "    print('X_val_one_hot_encoding.shape:', X_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding.shape:', y_value_train_one_hot_encoding.shape)\n",
    "    print('y_value_val_one_hot_encoding.shape:', y_value_val_one_hot_encoding.shape)\n",
    "    print('y_exists_train_one_hot_encoding.shape:', y_exists_train_one_hot_encoding.shape)\n",
    "    print('y_exists_val_one_hot_encoding.shape:', y_exists_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding[0]:', y_value_train_one_hot_encoding[0])\n",
    "    print('y_exists_train_one_hot_encoding[0]:', y_exists_train_one_hot_encoding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e90f9a-14a8-41e2-ad9a-cfe4e3000d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33514963, 0.00078676],\n",
       "       [0.01809174, 0.15265725],\n",
       "       [0.01032841, 0.14763822],\n",
       "       ...,\n",
       "       [0.05754841, 0.25609945],\n",
       "       [0.57781303, 0.0013409 ],\n",
       "       [0.06168676, 0.26742149]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    display(X_train) #can check this in previous script as well after loading to make sure it matches\n",
    "else:\n",
    "    display(X_train_one_hot_encoding)\n",
    "    display(X_train_linear_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95debf17-6de3-49fc-9064-b01c985c3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Train set shape x:                851, 69.98%\n",
      "Validation set shape x:           182, 14.97%\n",
      "Test set shape x:                 183, 15.05%\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Train set shape y_value:          851, 69.98%\n",
      "Validation set shape y_value:     182, 14.97%\n",
      "Test set shape y_value:           183, 15.05%\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Look at how it was split and decide if you like the split\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    total = len(X_train) + len(X_test) + len(X_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x:                {}, {:.2f}%'.format(len(X_train), (len(X_train) * 100.) / total))\n",
    "    print('Validation set shape x:           {}, {:.2f}%'.format(len(X_val), (len(X_val) * 100.) / total))\n",
    "    print('Test set shape x:                 {}, {:.2f}%'.format(len(X_test), (len(X_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train) + len(y_value_test) + len(y_value_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value:          {}, {:.2f}%'.format(len(y_value_train), (len(y_value_train) * 100.) / total))\n",
    "    print('Validation set shape y_value:     {}, {:.2f}%'.format(len(y_value_val), (len(y_value_val) * 100.) / total))\n",
    "    print('Test set shape y_value:           {}, {:.2f}%'.format(len(y_value_test), (len(y_value_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "else:\n",
    "    total = len(X_train_one_hot_encoding) + len(X_test_one_hot_encoding) + len(X_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x one_hot_encoding:      {}, {:.2f}%'.format(len(X_train_one_hot_encoding), (len(X_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape x one_hot_encoding: {}, {:.2f}%'.format(len(X_val_one_hot_encoding), (len(X_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape x one_hot_encoding:       {}, {:.2f}%'.format(len(X_test_one_hot_encoding), (len(X_test_one_hot_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_one_hot_encoding) + len(y_value_test_one_hot_encoding) + len(y_value_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value one_hot_encoding:      {}, {:.2f}%'.format(len(y_value_train_one_hot_encoding), (len(y_value_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value one_hot_encoding: {}, {:.2f}%'.format(len(y_value_val_one_hot_encoding), (len(y_value_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value one_hot_encoding:       {}, {:.2f}%'.format(len(y_value_test_one_hot_encoding), (len(y_value_test_one_hot_encoding) * 100.) / total))\n",
    "\n",
    "    total = len(X_train_linear_encoding) + len(X_test_linear_encoding) + len(X_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x linear_encoding:      {}, {:.2f}%'.format(len(X_train_linear_encoding), (len(X_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape x linear_encoding: {}, {:.2f}%'.format(len(X_val_linear_encoding), (len(X_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape x linear_encoding:       {}, {:.2f}%'.format(len(X_test_linear_encoding), (len(X_test_linear_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_linear_encoding) + len(y_value_test_linear_encoding) + len(y_value_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value linear_encoding:      {}, {:.2f}%'.format(len(y_value_train_linear_encoding), (len(y_value_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value linear_encoding: {}, {:.2f}%'.format(len(y_value_val_linear_encoding), (len(y_value_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value linear_encoding:       {}, {:.2f}%'.format(len(y_value_test_linear_encoding), (len(y_value_test_linear_encoding) * 100.) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6e25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b32e05-b5df-4647-8dae-6ee5f8cddcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bin the data and look at how its distributed, probably the more random/spread out the better \n",
    "# for training, but this will improve as the database fills out\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    #--------------------Training Set---------------------\n",
    "    save_encoding = ENCODING_TYPE.replace(' ','_')\n",
    "    \n",
    "    num_cols = X_train.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/training_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/validation_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/test_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "else: #just plot linear encoding for now to not get plot overwhelm\n",
    "    #--------------------Training Set---------------------\n",
    "    num_cols = X_train_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/training_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/validation_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/test_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8215af-8030-4399-bbc5-b235f2ca3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(np.ceil(len(X_train) / TRAIN_BATCH_SIZE))\n",
    "LR_DECAY_STEPS = steps_per_epoch * 20   # decay every ~10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecc581",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251cf19c",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4f8c5",
   "metadata": {},
   "source": [
    "Create a classical multi-layer perceptron for regression. Taking some inspiration from [Deep learning-based I-V Global Parameter Extraction for BSIM-CMG](https://www.sciencedirect.com/science/article/pii/S003811012300179X), Solid-State Electronics, Vol. 209, November 2023.\n",
    "\n",
    "The above publication predicted parameters for BSIM, which is a physics model for advanced transistors that is complicated and might be a similar complexity to the physics we are trying to target/map with these SC qubit hamiltonian values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945bd67-9923-4f7c-8e32-56672a6c3a4a",
   "metadata": {},
   "source": [
    "Reccomended to download a third party app like \"Sleep control Center\" or \"Amphetamine\" to prevent computer from sleeping during the many hour/day long training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4f485-e3da-4663-832c-3bc917660e45",
   "metadata": {},
   "source": [
    "### Create Model by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce671ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # n output neurons for n parameters (value and exists heads both use this size)\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Multilayer perceptron (MLP)\n",
    "        model_shape = f'mlp_{len(X_test[0])}_'\n",
    "        # inner layer sizes\n",
    "        model_shape += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        print(len(y_value_train[0]))\n",
    "        model_shape += f'_{len(y_value_train[0])}'\n",
    "    else:\n",
    "        # Multilayer perceptron (MLP) for both encodings\n",
    "        model_shape_one_hot_encoding = f'mlp_{len(X_test_one_hot_encoding[0])}_'\n",
    "        model_shape_linear_encoding = f'mlp_{len(X_test_linear_encoding[0])}_'\n",
    "        model_shape_one_hot_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        model_shape_linear_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "\n",
    "        print('one hot:', len(y_value_train_one_hot_encoding[0]))\n",
    "        model_shape_one_hot_encoding += f'_{len(y_value_train_one_hot_encoding[0])}'\n",
    "        print('linear:', len(y_value_train_linear_encoding[0]))\n",
    "        model_shape_linear_encoding += f'_{len(y_value_train_linear_encoding[0])}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ba881d-a212-402c-86d8-ed5ab2bed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        #initialize a model, which lets us build a stack of layers\n",
    "        inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "        x = inputs\n",
    "\n",
    "        #iterate over the configuration of neurons for each hidden layer specified in NEURONS_PER_LAYER\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            # add a fully connected (dense) hidden layer with specified number of neurons\n",
    "            # the LeCun uniform initializer is used when initializing weights, this makes the model more stable\n",
    "            # l2 regularization is used in each layer to penalizing large weights, which prevents overfitting\n",
    "            x = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "\n",
    "            # apply a Leaky ReLU activation function to the outputs of the dense layer\n",
    "            # this introduces non-linearities, allowing the network to learn complex functions\n",
    "            #leaky ReLU is chosen over standard ReLU to help mitigate the \"dying ReLU\" problem:\n",
    "            #     - this problem is when neurons using the ReLU activation function output zero for all inputs and stop learning\n",
    "            #     - can be mitigated by using variations like Leaky ReLU or proper initialization\n",
    "            x = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x)\n",
    "            \n",
    "            # add a dropout layer to reduce overfitting -- randomly drops a set fraction (like 30%) of outputs from the layer\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x)\n",
    "        \n",
    "        # add the output layers consisting of # neurons, corresponding to the # target variables we aim to predict.\n",
    "        # value_out predicts the numerical parameter values; exists_out predicts if each parameter is defined (0/1).\n",
    "        value_out = Dense(len(y_value_train[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x)\n",
    "        exists_out = Dense(len(y_value_train[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x)\n",
    "\n",
    "        model = tf.keras.Model(\n",
    "            inputs=inputs,\n",
    "            outputs={'value_out': value_out, 'exists_out': exists_out},\n",
    "            name='mlp_multi_output'\n",
    "        )\n",
    "\n",
    "    \n",
    "    else:\n",
    "        # One-hot encoding model\n",
    "        inputs_one_hot = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "        x_oh = inputs_one_hot\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_oh = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_oh)\n",
    "            x_oh = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_oh)\n",
    "            x_oh = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_oh)\n",
    "        value_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        exists_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        model_one_hot_encoding = tf.keras.Model(\n",
    "            inputs=inputs_one_hot,\n",
    "            outputs={'value_out': value_out_oh, 'exists_out': exists_out_oh},\n",
    "            name='mlp_multi_output_one_hot'\n",
    "        )\n",
    "\n",
    "        # Linear encoding model\n",
    "        inputs_lin = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "        x_lin = inputs_lin\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_lin = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_lin)\n",
    "            x_lin = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_lin)\n",
    "            x_lin = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_lin)\n",
    "        value_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        exists_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        model_linear_encoding = tf.keras.Model(\n",
    "            inputs=inputs_lin,\n",
    "            outputs={'value_out': value_out_lin, 'exists_out': exists_out_lin},\n",
    "            name='mlp_multi_output_linear'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0181fd2-e4ee-4e41-aaae-4603c1a853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # The exponential decay learning rate schedule gradually reduces the learning rate, fine-tuning the learning process for better convergence\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LR_INITIAL,\n",
    "        decay_steps=LR_DECAY_STEPS,\n",
    "        decay_rate=LR_DECAY_RATE,\n",
    "        staircase=LR_STAIRCASE\n",
    "    )\n",
    "    \n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Set model to minimize loss specified by TRAIN_LOSS, and also to report the loss during training\n",
    "        model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "    else:\n",
    "        # Linear encoding model\n",
    "        model_linear_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "        # One-hot encoding model\n",
    "        model_one_hot_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e3657d-d0ac-40e6-9829-694436270bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    !mkdir -p model\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model_file = 'model/{}_best_model.keras'.format(model_shape)\n",
    "        last_model_file = 'model/{}_last_model.keras'.format(model_shape)\n",
    "    else:\n",
    "        best_model_file_one_hot_encoding = 'model/{}_best_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "        last_model_file_one_hot_encoding = 'model/{}_last_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "    \n",
    "        best_model_file_linear_encoding = 'model/{}_best_model_linear_encoding.keras'.format(model_shape_linear_encoding)\n",
    "        last_model_file_linear_encoding = 'model/{}_last_model_linear_encoding.keras'.format(model_shape_linear_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49516260-5078-4162-ab99-cdb45f9f9827",
   "metadata": {},
   "source": [
    "Enable training (`train_and_save`) to overwrite the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95e4501-3aea-4053-9788-30b4532d7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2957910-f200-4e9f-91c3-6e7ed0926ceb",
   "metadata": {},
   "source": [
    "We use Adam optimizer, minimize the Mean Squared Logarithmic Error, and early stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a00680-7b7f-4877-babb-481f0682b7b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b4fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Set up monitors and plots for later tracking purposes\n",
    "\n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    class TrainingPlot(tf.keras.callbacks.Callback):\n",
    "         \n",
    "        # This function is called when the training begins\n",
    "        def on_train_begin(self, logs={}):\n",
    "            # Initialize the lists for holding the logs, losses \n",
    "            self.losses = []\n",
    "            self.val_losses = []\n",
    "            self.logs = []\n",
    "        \n",
    "        # This function is called at the end of each epoch\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            \n",
    "            # Append the logs, losses  to the lists\n",
    "            self.logs.append(logs)\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            \n",
    "            # Before plotting ensure at least 2 epochs have passed\n",
    "            if len(self.losses) > 1:\n",
    "                \n",
    "                # Clear the previous plot\n",
    "                clear_output(wait=True)\n",
    "                N = np.arange(0, len(self.losses))\n",
    "                \n",
    "                # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "                plt.figure()\n",
    "                plt.plot(N, self.losses, label = \"train_loss\")\n",
    "                plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "                plt.title(\"Training Loss [Epoch {}]\".format(epoch))\n",
    "                plt.xlabel(\"Epoch #\")\n",
    "                plt.ylabel(\"Loss/Accuracy\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "           \n",
    "\n",
    "class LearningRateMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.learning_rates = []\n",
    "\n",
    "    #we have to do some checking for versions here or else we will get an Adam error when using this monitor\n",
    "    def _current_lr(self, optimizer):\n",
    "        # look and see if you get \"lr\" ir \"learning_rate\" depending on the version\n",
    "        lr = getattr(optimizer, \"lr\", None) or getattr(optimizer, \"learning_rate\", None)\n",
    "\n",
    "        # if this is a shecdule then evaluate it at current iteration step\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            return float(lr(optimizer.iterations).numpy())\n",
    "\n",
    "        # if not a schedule, its a scalar/variable/tensor\n",
    "        return float(tf.keras.backend.get_value(lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            lr_val = self._current_lr(self.model.optimizer)\n",
    "        except Exception:\n",
    "            # for anything else fallback\n",
    "            lr_val = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.learning_rates.append(lr_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef223c28-cc33-4721-b049-be7023eb13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 6 s, total: 6 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "history = None  \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if train_and_save: \n",
    "        # Set up early stopping to prevent overfitting by halting training when validation loss stops improving\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_value_out_loss',                      # Monitor validation loss for stopping criteria \n",
    "            mode='min',                              # Stop when the monitored quantity has stopped decreasing\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,  # Number of epochs to wait after last improvement\n",
    "            verbose=1                                # Enable logging when early stopping happens\n",
    "        )\n",
    "    \n",
    "        # Train the model on the training data and validate on a portion of it\n",
    "        if 'Try Both' not in ENCODING_TYPE:\n",
    "            plot_callback = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            # sample weights: use exists mask for value_out, ones for exists_out\n",
    "            value_sample_weight_train = np.asarray(y_exists_train)\n",
    "            value_sample_weight_val = np.asarray(y_exists_val)  # not used directly but handy to keep\n",
    "            exists_sample_weight_train = np.ones_like(value_sample_weight_train)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                filepath=best_model_file,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "   \n",
    "            history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            {\n",
    "                \"value_out\": np.asarray(y_value_train),\n",
    "                \"exists_out\": np.asarray(y_exists_train),\n",
    "            },\n",
    "            sample_weight={\n",
    "                \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),  # (N,) OR (N,16) depending on your value loss setup\n",
    "                \"exists_out\": np.ones((len(y_exists_train),), dtype=\"float32\"),  # <-- MUST be (N,)\n",
    "            },\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_value_val),\n",
    "                    \"exists_out\": np.asarray(y_exists_val),\n",
    "                },\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(y_exists_val),), dtype=\"float32\"),  # <-- MUST be (N,)\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping, model_checkpoint, plot_callback, lr_monitor],\n",
    "            verbose=1,\n",
    "        )\n",
    "                    \n",
    "\n",
    "\n",
    "            \n",
    "            model.save(last_model_file)  # Save the final model when done training!\n",
    "        \n",
    "        else:\n",
    "            #-----------------------------------------linear--------------------------------------------\n",
    "            plot_callback_linear_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_linear_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_linear = np.asarray(y_exists_train_linear_encoding)\n",
    "            value_sample_weight_val_linear = np.asarray(y_exists_val_linear_encoding)\n",
    "            exists_sample_weight_train_linear = np.ones_like(value_sample_weight_train_linear)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_linear_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_linear_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_linear_encoding = model_linear_encoding.fit(\n",
    "                np.asarray(X_train_linear_encoding),\n",
    "                [\n",
    "                    np.asarray(y_value_train_linear_encoding),\n",
    "                    np.asarray(y_exists_train_linear_encoding)\n",
    "                ],\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_linear_encoding),\n",
    "                    [\n",
    "                        np.asarray(y_value_val_linear_encoding),\n",
    "                        np.asarray(y_exists_val_linear_encoding)\n",
    "                    ]\n",
    "                ),\n",
    "                sample_weight=[\n",
    "                    np.asarray(y_exists_train_linear_encoding).astype(\"float32\"),                   # value mask (n,16)\n",
    "                    np.ones_like(np.asarray(y_exists_train_linear_encoding), dtype=\"float32\")       # exists weights (n,16)\n",
    "                ]\n",
    "                ,\n",
    "                callbacks=[early_stopping, model_checkpoint_linear_encoding, plot_callback_linear_encoding, lr_monitor_linear_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "            model_linear_encoding.save(last_model_file_linear_encoding)  # Save the final model when done training!\n",
    "            \n",
    "            #-----------------------------------------one hot--------------------------------------------\n",
    "            plot_callback_one_hot_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_one_hot_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_oh = np.asarray(y_exists_train_one_hot_encoding)\n",
    "            value_sample_weight_val_oh = np.asarray(y_exists_val_one_hot_encoding)\n",
    "            exists_sample_weight_train_oh = np.ones_like(value_sample_weight_train_oh)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_one_hot_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_one_hot_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_one_hot_encoding = model_one_hot_encoding.fit(\n",
    "                np.asarray(X_train_one_hot_encoding),\n",
    "                {\n",
    "                    'value_out': np.asarray(y_value_train_one_hot_encoding),\n",
    "                    'exists_out': np.asarray(y_exists_train_one_hot_encoding)\n",
    "                },\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_one_hot_encoding),\n",
    "                    {\n",
    "                        'value_out': np.asarray(y_value_val_one_hot_encoding),\n",
    "                        'exists_out': np.asarray(y_exists_val_one_hot_encoding)\n",
    "                    }\n",
    "                ),\n",
    "                callbacks=[early_stopping, model_checkpoint_one_hot_encoding, plot_callback_one_hot_encoding, lr_monitor_one_hot_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            model_one_hot_encoding.save(last_model_file_one_hot_encoding)  # Save the final model when done training!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4074c-a8ef-4a69-a8cd-5714edb90166",
   "metadata": {},
   "source": [
    "Load the saved best model and use it from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2447145e-91b5-4070-aefe-38f8e6bc33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        model = load_model(best_model_file, custom_objects={})\n",
    "    else:\n",
    "        model_one_hot_encoding = load_model(best_model_file_one_hot_encoding, custom_objects={})\n",
    "        model_linear_encoding = load_model(best_model_file_linear_encoding, custom_objects={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002f4a5-df05-4ff2-be6d-24f8027ca4ea",
   "metadata": {},
   "source": [
    "### Sweep total number of parameters to find the right range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c72fea-fbf1-48fc-8e8d-7353f631e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    \n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def train_one_config(neurons_per_layer, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=X_train.shape[1],\n",
    "            output_dim=y_value_train.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # returns (batch,)\n",
    "        \n",
    "        def elementwise_mae(y_true, y_pred):\n",
    "            # returns (batch, output_dim) so your (batch, output_dim) mask works correctly\n",
    "            return tf.abs(y_true - y_pred)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\n",
    "                \"value_out\": elementwise_mae,\n",
    "                \"exists_out\": bce,\n",
    "            },\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            # If your Keras supports it, this helps avoid XLA weirdness:\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor= 'val_value_out_loss', \n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        Xtr = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr = np.asarray(y_value_train)\n",
    "        ye_tr = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "        \n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr.astype(\"float32\"),                  # (batch, 16) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\"),   # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va.astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        best_val_loss = float(np.min(history.history[\"val_loss\"]))\n",
    "        best_epoch = int(np.argmin(history.history[\"val_loss\"]) + 1)\n",
    "\n",
    "        return {\n",
    "            \"neurons_per_layer\": tuple(neurons_per_layer),\n",
    "            \"depth\": len(neurons_per_layer),\n",
    "            \"width\": int(neurons_per_layer[0]),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"best_epoch\": best_epoch,\n",
    "        }\n",
    "    configs = []\n",
    "    for depth in [1, 2, 3, 4, 5]:\n",
    "        for width in [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 5000, 6000]:\n",
    "            configs.append([width] * depth)\n",
    "    for depth in [1, 2]:\n",
    "        for width in [2048, 4096]:\n",
    "            configs.append([width] * depth)\n",
    "\n",
    "    # remove duplicates if any\n",
    "    configs = [list(x) for x in {tuple(c) for c in configs}]\n",
    "\n",
    "    results = []\n",
    "    for cfg in sorted(configs, key=lambda c: (len(c), c[0])):\n",
    "        out = train_one_config(cfg, seed=0)\n",
    "        results.append(out)\n",
    "        print(out)\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(\"total_params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "584b9bf8-f2b1-45cd-811f-e0ab2981101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    # save the data\n",
    "\n",
    "    from datetime import datetime\n",
    "    \n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = \"sweep_outputs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(out_dir, f\"sweep_results_{run_id}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d3c698f-d105-46fb-84a6-60ad839aa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    plt.figure()\n",
    "    plt.scatter(df[\"total_params\"], df[\"best_val_loss\"])\n",
    "    plt.xscale(\"log\")  # will be helpful if params grow fast\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size\")\n",
    "    plt.savefig('plots/params_vs_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    plt.figure()\n",
    "    sc = plt.scatter(\n",
    "        df2[\"total_params\"],\n",
    "        df2[\"best_val_loss\"],\n",
    "        c=df2[\"depth\"],\n",
    "        s=20 + 10*np.log2(df2[\"width\"]),\n",
    "    )\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size (color=depth, size=width)\")\n",
    "    plt.colorbar(sc, label=\"Depth\")\n",
    "    plt.savefig(\"plots/params_vs_loss_width_color_coded.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f20c5e-2bb5-4847-a8ee-da10db0e828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    df.to_csv(\"sweep_results.csv\", index=False)\n",
    "\n",
    "    old = pd.read_csv(\"sweep_results.csv\")\n",
    "    combined = pd.concat([old, df], ignore_index=True).drop_duplicates(\n",
    "        subset=[\"neurons_per_layer\"], keep=\"last\"\n",
    "    )\n",
    "    combined.to_csv(\"sweep_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202f375-0326-4767-96f0-9a5252e5799f",
   "metadata": {},
   "source": [
    "### Sweep amount of data used in training to determine if data amount is limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d64c0f2f-1316-4e29-b09c-6d99ce882cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "\n",
    "    FIXED_DEPTH = 5\n",
    "    FIXED_WIDTH = 64\n",
    "    FIXED_NEURONS = [FIXED_WIDTH] * FIXED_DEPTH\n",
    "\n",
    "    TRAIN_FRACTIONS = np.linspace(0.3, 1.0, 20)\n",
    "\n",
    "    # avg over many seeds for error bars\n",
    "    SWEEP_SEEDS = [0, 1, 2, 3, 4]\n",
    "\n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE,\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def elementwise_mae(y_true, y_pred):\n",
    "        return tf.abs(y_true - y_pred)  \n",
    "\n",
    "    def make_subset(X, y_value, y_exists, frac, seed):\n",
    "        assert 0 < frac <= 1.0\n",
    "        n = len(X)\n",
    "        m = max(1, int(np.floor(frac * n)))\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(n, size=m, replace=False)\n",
    "        return X[idx], y_value[idx], y_exists[idx], m\n",
    "\n",
    "    def train_one_fraction(neurons_per_layer, train_frac, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Full arrays\n",
    "        Xtr_full = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr_full = np.asarray(y_value_train)\n",
    "        ye_tr_full = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "\n",
    "        Xtr, yv_tr, ye_tr, n_sub = make_subset(Xtr_full, yv_tr_full, ye_tr_full, train_frac, seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=Xtr.shape[1],\n",
    "            output_dim=yv_tr.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\"value_out\": elementwise_mae, \"exists_out\": bce},\n",
    "            loss_weights={\"value_out\": 1.0, \"exists_out\": 1.0},\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr,                                # (batch, output_dim) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\") # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va,                              # (val_batch, output_dim) mask\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # grab best epoch by val_loss\n",
    "        val_loss_hist = np.asarray(history.history[\"val_loss\"], dtype=float)\n",
    "        best_i = int(np.argmin(val_loss_hist))\n",
    "        best_epoch = best_i + 1\n",
    "\n",
    "        out = {\n",
    "            \"train_frac\": float(train_frac),\n",
    "            \"train_n\": int(n_sub),\n",
    "            \"seed\": int(seed),\n",
    "            \"neurons_per_layer\": str(list(neurons_per_layer)),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": float(val_loss_hist[best_i]),\n",
    "            \"best_val_value_out_loss\": float(np.asarray(history.history.get(\"val_value_out_loss\"))[best_i]),\n",
    "            \"best_val_exists_out_loss\": float(np.asarray(history.history.get(\"val_exists_out_loss\"))[best_i]),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "        }\n",
    "        return out\n",
    "\n",
    "    results = []\n",
    "    for frac in TRAIN_FRACTIONS:\n",
    "        for seed in SWEEP_SEEDS:\n",
    "            out = train_one_fraction(FIXED_NEURONS, train_frac=frac, seed=seed)\n",
    "            results.append(out)\n",
    "            print(out)\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values([\"train_frac\", \"seed\"]).reset_index(drop=True)\n",
    "\n",
    "    summary = (\n",
    "        df.groupby([\"train_frac\", \"train_n\", \"total_params\"], as_index=False)\n",
    "          .agg(\n",
    "              best_val_loss_mean=(\"best_val_loss\", \"mean\"),\n",
    "              best_val_loss_std=(\"best_val_loss\", \"std\"),\n",
    "              best_epoch_mean=(\"best_epoch\", \"mean\"),\n",
    "              best_val_value_out_loss_mean=(\"best_val_value_out_loss\", \"mean\"),\n",
    "              best_val_exists_out_loss_mean=(\"best_val_exists_out_loss\", \"mean\"),\n",
    "          )\n",
    "          .sort_values(\"train_frac\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # save to csv\n",
    "    run_id = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = os.path.join(\"sweeps\", f\"data_fraction_sweep_{run_id}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_path = os.path.join(out_dir, \"sweep_raw.csv\")\n",
    "    summary_path = os.path.join(out_dir, \"sweep_summary.csv\")\n",
    "    meta_path = os.path.join(out_dir, \"metadata.json\")\n",
    "    fig_path = os.path.join(out_dir, \"val_loss_vs_train_fraction.png\")\n",
    "\n",
    "    df.to_csv(df_path, index=False)\n",
    "    summary.to_csv(summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b458abc-b03a-4910-9dfd-d92637c4cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "    def _jsonify(o):\n",
    "        if isinstance(o, np.ndarray): return o.tolist()\n",
    "        if isinstance(o, (np.integer,)): return int(o)\n",
    "        if isinstance(o, (np.floating,)): return float(o)\n",
    "        return o\n",
    "\n",
    "    metadata = {\n",
    "        \"run_id\": run_id,\n",
    "        \"fixed_depth\": FIXED_DEPTH,\n",
    "        \"fixed_width\": FIXED_WIDTH,\n",
    "        \"fixed_neurons\": FIXED_NEURONS,\n",
    "        \"train_fractions\": TRAIN_FRACTIONS,\n",
    "        \"seeds\": SWEEP_SEEDS,\n",
    "        \"batch_size\": int(TRAIN_BATCH_SIZE),\n",
    "        \"early_stopping_patience\": int(TRAIN_EARLY_STOPPING_PATIENCE),\n",
    "        \"notes\": \"Subset sampling only on TRAIN split. value_out loss is masked using y_exists via sample_weight.\",\n",
    "    }\n",
    "\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2, default=_jsonify)\n",
    "\n",
    "    plt.figure()\n",
    "    y = summary[\"best_val_loss_mean\"].to_numpy()\n",
    "    x = summary[\"train_frac\"].to_numpy()\n",
    "    if len(SWEEP_SEEDS) > 1:\n",
    "        yerr = summary[\"best_val_loss_std\"].fillna(0.0).to_numpy()\n",
    "        plt.errorbar(x, y, yerr=yerr, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss (mean  std)\")\n",
    "    else:\n",
    "        plt.plot(x, y, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss\")\n",
    "\n",
    "    plt.xlabel(\"Training data fraction\")\n",
    "    plt.title(f\"Val loss vs training fraction (depth={FIXED_DEPTH}, width={FIXED_WIDTH})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nSaved:\\n- {df_path}\\n- {summary_path}\\n- {meta_path}\\n- {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d39c98-db42-48fe-9e64-8c153c978203",
   "metadata": {},
   "source": [
    "### Keras Tuner to Find Best Hyperparameters and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe2de3-ba0a-4103-bfd1-466d73bd9b8c",
   "metadata": {},
   "source": [
    "Run this if you want to use keras tuner to make the model rather than doing it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d804553-ae82-4f8f-9182-806c7f22b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras_tuner import HyperModel, RandomSearch\n",
    "    from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081aa70b-c54e-48af-b895-5e9ddd2746cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        def build_hypermodel(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            # multi-output heads: value_out (regression) and exists_out (existence classification)\n",
    "            value_out = Dense(len(y_value_train[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "        \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 2e-3, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "        \n",
    "            model.compile(optimizer=tf.optimizers.Adam(learning_rate=lr_schedule), \n",
    "                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model\n",
    "    else:\n",
    "        def build_hypermodel_one_hot_encoding(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------one hot-------------------------------------------\n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_one_hot_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_one_hot_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_one_hot_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 2e-3, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_one_hot_encoding.compile(optimizer=optimizer, \n",
    "                                           loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                           loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                           metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_one_hot_encoding\n",
    "\n",
    "        def build_hypermodel_linear_encoding(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------linear------------------------------------------- \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_linear_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_linear_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_linear_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            #----------------------------------------------continue-------------------------------------------\n",
    "\n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 2e-3, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_linear_encoding.compile(optimizer=optimizer, \n",
    "                                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_linear_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cfea157-b0b4-4148-8d0a-e37c877877a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras/hyper_tuning_one_hot_encoding/mlp_tuning_one_hot_encoding/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        tuner = RandomSearch(\n",
    "            build_hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + f'/hyper_tuning_{encoding}_encoding',\n",
    "            project_name=f'mlp_tuning_{encoding}_encoding'\n",
    "        )\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # Start tuning linear encoding\n",
    "        tuner_linear_encoding = RandomSearch(\n",
    "            build_hypermodel_linear_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_linear_encoding',\n",
    "            project_name='mlp_tuning_linear_encoding'\n",
    "        )\n",
    "\n",
    "        # Start tuning one hot encoding\n",
    "        tuner_one_hot_encoding = RandomSearch(\n",
    "            build_hypermodel_one_hot_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_one_hot_encoding',\n",
    "            project_name='mlp_tuning_one_hot_encoding'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c11608cb-5b05-45af-af22-0bcab2827734",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    # Setup Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_value_out_loss',\n",
    "        mode='min',\n",
    "        patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15440869-6be6-4005-9db4-3b37695adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Perform hyperparameter tuning\n",
    "        tuner.search(\n",
    "            np.asarray(X_train),\n",
    "            {'value_out': np.asarray(y_value_train), 'exists_out': np.asarray(y_exists_train)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val), {'value_out': np.asarray(y_value_val), 'exists_out': np.asarray(y_exists_val)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # one-hot encoding branch\n",
    "        tuner_one_hot_encoding.search(\n",
    "            np.asarray(X_train_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # linear encoding branch\n",
    "        tuner_linear_encoding.search(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "598b1b58-8413-4573-a02d-fe8363165edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768584169.845050 2360945 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\n",
      "/home/olivias/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 29 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file= f'model/best_keras_model_{encoding}_encoding.keras'\n",
    "\n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        best_model.save(best_model_file)\n",
    "\n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_model = load_model(best_model_file, compile=False)\n",
    "    else:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file_linear = 'model/best_keras_model_linear_encoding.keras'\n",
    "        best_model_file_onehot = 'model/best_keras_model_one_hot_encoding.keras'\n",
    "        \n",
    "        best_linear_model = tuner_linear_encoding.get_best_models(1)[0]\n",
    "        best_onehot_model = tuner_one_hot_encoding.get_best_models(1)[0]\n",
    "        \n",
    "        best_linear_model.save(best_model_file_linear)\n",
    "        best_onehot_model.save(best_model_file_onehot)\n",
    "        \n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_linear_model = load_model(best_model_file_linear, compile=False)\n",
    "            loaded_onehot_model = load_model(best_model_file_onehot, compile=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291953b-7ce8-498d-88ce-20974516af77",
   "metadata": {},
   "source": [
    "### View the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "137d2a50-a4ef-4ccc-8cb9-04e380f0fcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " fc0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500</span>  input1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " leaky_relu0          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1400</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">701,400</span>  dropout0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1400</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1400</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,148,820</span>  dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu2          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">430</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">353,030</span>  dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">430</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">430</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">344,800</span>  dropout3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " value_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">12,816</span>  dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " exists_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">12,816</span>  dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input1 (\u001b[38;5;33mInputLayer\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
       "\n",
       " fc0 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)             \u001b[38;5;34m1,500\u001b[0m  input1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " leaky_relu0          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout0 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc1 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1400\u001b[0m)          \u001b[38;5;34m701,400\u001b[0m  dropout0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1400\u001b[0m)                \u001b[38;5;34m0\u001b[0m  fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout1 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1400\u001b[0m)                \u001b[38;5;34m0\u001b[0m  leaky_relu1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc2 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m820\u001b[0m)         \u001b[38;5;34m1,148,820\u001b[0m  dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu2          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m820\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout2 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m820\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc3 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m430\u001b[0m)           \u001b[38;5;34m353,030\u001b[0m  dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m430\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout3 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m430\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc4 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)           \u001b[38;5;34m344,800\u001b[0m  dropout3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout4 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " value_out (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m12,816\u001b[0m  dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " exists_out (\u001b[38;5;33mDense\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m12,816\u001b[0m  dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,575,182</span> (9.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,575,182\u001b[0m (9.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,575,182</span> (9.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,575,182\u001b[0m (9.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model.summary()\n",
    "    else:\n",
    "        best_onehot_model.summary()\n",
    "        best_linear_model.summary()\n",
    "        \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        print(\"\\n---- Model Summary ----\")\n",
    "        model.summary()\n",
    "    else:\n",
    "        print(\"\\n---- Linear Encoding Model Summary ----\")\n",
    "        model_linear_encoding.summary()\n",
    "        \n",
    "        print(\"\\n---- One-Hot Encoding Model Summary ----\")\n",
    "        model_one_hot_encoding.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f05d0a25-2890-4ddc-b888-57b849fa2a0f",
   "metadata": {},
   "source": [
    "if KERAS_TUNER:\n",
    "    keras2ascii(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57cb40-ca2c-4ac7-905c-e13beaf71a51",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5556f8-c81b-4522-b7be-d847b6f20452",
   "metadata": {},
   "source": [
    "Although we may plot and print many metrics, we focus only on **Mean Squared Error (MSE).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc9acc-ad33-4df3-ac56-8ed3913ce16d",
   "metadata": {},
   "source": [
    "Plot training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "523cc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a721cc-cc18-4bc6-96b9-520b736e2382",
   "metadata": {},
   "source": [
    "### Visualize gradients for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d64ca5e-a7e8-49fe-8734-becc35d4998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        class GradientNormLogger(tf.keras.callbacks.Callback):\n",
    "            \"\"\"\n",
    "            Logs gradient norms on a fixed probe batch at epoch end.\n",
    "            Works for:\n",
    "              - single-output models (y_true array)\n",
    "              - multi-output dict models (e.g., {\"value_out\":..., \"exists_out\":...})\n",
    "            Supports passing sample_weight (incl. per-output dict), which is required for masked losses.\n",
    "            \"\"\"\n",
    "            def __init__(\n",
    "                self,\n",
    "                x_probe,\n",
    "                y_probe,\n",
    "                sample_weight_probe=None,\n",
    "                layer_name_prefixes=(\"fc\", \"value_out\", \"exists_out\"),\n",
    "                log_every=1,\n",
    "                verbose=1\n",
    "            ):\n",
    "                super().__init__()\n",
    "                self.x_probe = tf.convert_to_tensor(x_probe)\n",
    "                self.y_probe = y_probe  # keep as-is; we will convert lazily (dict vs array)\n",
    "                self.sample_weight_probe = sample_weight_probe\n",
    "                self.layer_name_prefixes = tuple(layer_name_prefixes)\n",
    "                self.log_every = int(log_every)\n",
    "                self.verbose = int(verbose)\n",
    "                self.records = []\n",
    "        \n",
    "            def _to_tensor_tree(self, obj):\n",
    "                # converts arrays (or dict of arrays) to tensors\n",
    "                if obj is None:\n",
    "                    return None\n",
    "                if isinstance(obj, dict):\n",
    "                    return {k: tf.convert_to_tensor(v) for k, v in obj.items()}\n",
    "                return tf.convert_to_tensor(obj)\n",
    "        \n",
    "            def _want_var(self, var_name: str) -> bool:\n",
    "                # var_name like \"fc0/kernel:0\", \"value_out/bias:0\", etc.\n",
    "                base = var_name.split(\":\")[0]\n",
    "                return any(base.startswith(pfx) for pfx in self.layer_name_prefixes)\n",
    "        \n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                logs = logs or {}\n",
    "                if (epoch + 1) % self.log_every != 0:\n",
    "                    return\n",
    "        \n",
    "                y_probe_t = self._to_tensor_tree(self.y_probe)\n",
    "                sw_probe_t = self._to_tensor_tree(self.sample_weight_probe)\n",
    "        \n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = self.model(self.x_probe, training=True)\n",
    "                    # IMPORTANT: use compiled_loss the same way training does\n",
    "                    loss = self.model.compiled_loss(\n",
    "                        y_probe_t,\n",
    "                        y_pred,\n",
    "                        sample_weight=sw_probe_t,\n",
    "                        regularization_losses=self.model.losses\n",
    "                    )\n",
    "        \n",
    "                grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        \n",
    "                rec = {\"epoch\": int(epoch + 1), \"probe_loss\": float(loss.numpy())}\n",
    "        \n",
    "                per_layer = {}\n",
    "                for w, g in zip(self.model.trainable_weights, grads):\n",
    "                    if g is None:\n",
    "                        continue\n",
    "        \n",
    "                    wname = w.name  # includes :0\n",
    "                    if not self._want_var(wname):\n",
    "                        continue\n",
    "        \n",
    "                    wbase = wname.split(\":\")[0]\n",
    "                    g_norm = float(tf.linalg.global_norm([g]).numpy().item())\n",
    "                    rec[f\"grad_norm__{wbase}\"] = g_norm\n",
    "        \n",
    "                    layer_key = wbase.split(\"/\")[0]\n",
    "                    per_layer.setdefault(layer_key, []).append(g_norm)\n",
    "        \n",
    "                for layer_key, norms in per_layer.items():\n",
    "                    rec[f\"grad_mean__{layer_key}\"] = float(np.mean(norms))\n",
    "                    rec[f\"grad_max__{layer_key}\"] = float(np.max(norms))\n",
    "        \n",
    "                g_all = [g for g in grads if g is not None]\n",
    "                rec[\"grad_global_norm\"] = float(tf.linalg.global_norm(g_all).numpy().item()) if g_all else float(\"nan\")\n",
    "        \n",
    "                self.records.append(rec)\n",
    "        \n",
    "                # push scalars into History\n",
    "                for k, v in rec.items():\n",
    "                    if k != \"epoch\":\n",
    "                        logs[k] = v\n",
    "        \n",
    "                if self.verbose:\n",
    "                    msg = f\"[Grad] epoch={rec['epoch']} probe_loss={rec['probe_loss']:.6g} global={rec['grad_global_norm']:.3g}\"\n",
    "                    # show a couple common layers if present\n",
    "                    for lk in (\"fc0\", \"value_out\", \"exists_out\"):\n",
    "                        mk = f\"grad_mean__{lk}\"\n",
    "                        xk = f\"grad_max__{lk}\"\n",
    "                        if mk in rec:\n",
    "                            msg += f\" | {lk}:mean={rec[mk]:.3g} max={rec[xk]:.3g}\"\n",
    "                    print(msg)\n",
    "        \n",
    "            def to_csv(self, path: str):\n",
    "                import csv, os\n",
    "                os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "                if not self.records:\n",
    "                    return\n",
    "                keys = sorted({k for r in self.records for k in r.keys()})\n",
    "                with open(path, \"w\", newline=\"\") as f:\n",
    "                    w = csv.DictWriter(f, fieldnames=keys)\n",
    "                    w.writeheader()\n",
    "                    w.writerows(self.records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9969df9e-8593-4cb0-9051-2a085a051d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        probe_n = min(256, len(X_train))\n",
    "\n",
    "        x_probe = np.asarray(X_train[:probe_n])\n",
    "\n",
    "        # y_true dict for the notebook model\n",
    "        y_probe = {\n",
    "            \"value_out\": np.asarray(y_value_train[:probe_n]),\n",
    "            \"exists_out\": np.asarray(y_exists_train[:probe_n]).astype(\"float32\"),\n",
    "        }\n",
    "\n",
    "        # sample_weight dict: mask value_out by exists_out, neutral weight for exists_out\n",
    "        sw_probe = {\n",
    "            \"value_out\": y_probe[\"exists_out\"],  # (probe_n, output_dim)\n",
    "            \"exists_out\": np.ones((probe_n,), dtype=\"float32\"),\n",
    "        }\n",
    "\n",
    "        grad_logger = GradientNormLogger(\n",
    "            x_probe=x_probe,\n",
    "            y_probe=y_probe,\n",
    "            sample_weight_probe=sw_probe,\n",
    "            layer_name_prefixes=(\"fc0\", \"value_out\", \"exists_out\"),  # adjust as you like\n",
    "            log_every=1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()\n",
    "\n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            {\"value_out\": np.asarray(y_value_train), \"exists_out\": np.asarray(y_exists_train).astype(\"float32\")},\n",
    "            sample_weight={\n",
    "                \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),\n",
    "                \"exists_out\": np.ones((len(X_train),), dtype=\"float32\"),\n",
    "            },\n",
    "            epochs=400,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                {\"value_out\": np.asarray(y_value_val), \"exists_out\": np.asarray(y_exists_val).astype(\"float32\")},\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(X_val),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            callbacks=[early_stopping, lr_monitor, grad_logger],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grad_logger.to_csv(f\"plots/{encoding}_gradients.csv\")\n",
    "\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc30d21b-458b-4518-bdae-04f505e45c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        dfg = pd.DataFrame(grad_logger.records)\n",
    "        \n",
    "        # Plot global grad norm\n",
    "        plt.figure()\n",
    "        plt.plot(dfg[\"epoch\"], dfg[\"grad_global_norm\"])\n",
    "        plt.yscale(\"log\")  # very helpful to see vanishing/exploding\n",
    "        plt.title(\"Gradient tracking for a single batch across epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Gradient magnitude (log scale)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"plots/{encoding}_grad_global_norm.pdf\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot fc0 and output mean norms if present\n",
    "        for lk in [\"fc0\", \"output\"]:\n",
    "            col = f\"grad_mean__{lk}\"\n",
    "            if col in dfg.columns:\n",
    "                plt.figure()\n",
    "                plt.plot(dfg[\"epoch\"], dfg[col])\n",
    "                plt.yscale(\"log\")\n",
    "                plt.title(f\"Gradient Mean Norm: {lk} (probe batch)\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Mean grad norm (log scale)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"plots/{encoding}_grad_mean_{lk}.pdf\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa8eb5-11a2-4ca0-832f-e0cfb057a75a",
   "metadata": {},
   "source": [
    "### Look at the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347263a8-570e-4a04-bbae-3ea0662e4012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output order: ListWrapper(['value_out', 'exists_out'])\n",
      "Epoch 1/400\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step - exists_out_accuracy: 0.3594 - exists_out_loss: 0.6928 - loss: 5.0105 - value_out_loss: 0.3452 - value_out_mean_squared_error: 0.3452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768584177.152486 2363113 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - exists_out_accuracy: 0.2280 - exists_out_loss: 0.5754 - loss: 4.1162 - value_out_loss: 0.4926 - value_out_mean_squared_error: 0.5080 - val_exists_out_accuracy: 0.3681 - val_exists_out_loss: 0.2352 - val_loss: 3.5595 - val_value_out_loss: 1.2573 - val_value_out_mean_squared_error: 1.2716\n",
      "Epoch 2/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0564 - exists_out_loss: 0.2161 - loss: 2.3776 - value_out_loss: 0.3964 - value_out_mean_squared_error: 0.4027 - val_exists_out_accuracy: 0.0385 - val_exists_out_loss: 0.1220 - val_loss: 1.8599 - val_value_out_loss: 0.2619 - val_value_out_mean_squared_error: 0.2665\n",
      "Epoch 3/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - exists_out_accuracy: 0.2374 - exists_out_loss: 0.1090 - loss: 1.6359 - value_out_loss: 0.1427 - value_out_mean_squared_error: 0.1457 - val_exists_out_accuracy: 0.3626 - val_exists_out_loss: 0.0806 - val_loss: 1.4570 - val_value_out_loss: 0.1012 - val_value_out_mean_squared_error: 0.1019\n",
      "Epoch 4/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.2949 - exists_out_loss: 0.0610 - loss: 1.3387 - value_out_loss: 0.0589 - value_out_mean_squared_error: 0.0596 - val_exists_out_accuracy: 0.0495 - val_exists_out_loss: 0.0392 - val_loss: 1.2174 - val_value_out_loss: 0.0435 - val_value_out_mean_squared_error: 0.0435\n",
      "Epoch 5/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.2515 - exists_out_loss: 0.0367 - loss: 1.1592 - value_out_loss: 0.0419 - value_out_mean_squared_error: 0.0422 - val_exists_out_accuracy: 0.3626 - val_exists_out_loss: 0.0296 - val_loss: 1.0690 - val_value_out_loss: 0.0372 - val_value_out_mean_squared_error: 0.0371\n",
      "Epoch 6/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.3231 - exists_out_loss: 0.0303 - loss: 1.0209 - value_out_loss: 0.0378 - value_out_mean_squared_error: 0.0379 - val_exists_out_accuracy: 0.3626 - val_exists_out_loss: 0.0268 - val_loss: 0.9466 - val_value_out_loss: 0.0357 - val_value_out_mean_squared_error: 0.0358\n",
      "Epoch 7/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.3278 - exists_out_loss: 0.0285 - loss: 0.9060 - value_out_loss: 0.0350 - value_out_mean_squared_error: 0.0351 - val_exists_out_accuracy: 0.3297 - val_exists_out_loss: 0.0265 - val_loss: 0.8421 - val_value_out_loss: 0.0299 - val_value_out_mean_squared_error: 0.0300\n",
      "Epoch 8/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.2726 - exists_out_loss: 0.0283 - loss: 0.8124 - value_out_loss: 0.0328 - value_out_mean_squared_error: 0.0330 - val_exists_out_accuracy: 0.2747 - val_exists_out_loss: 0.0268 - val_loss: 0.7609 - val_value_out_loss: 0.0297 - val_value_out_mean_squared_error: 0.0298\n",
      "Epoch 9/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - exists_out_accuracy: 0.2597 - exists_out_loss: 0.0287 - loss: 0.7373 - value_out_loss: 0.0327 - value_out_mean_squared_error: 0.0328 - val_exists_out_accuracy: 0.2747 - val_exists_out_loss: 0.0272 - val_loss: 0.6936 - val_value_out_loss: 0.0301 - val_value_out_mean_squared_error: 0.0300\n",
      "Epoch 10/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.2491 - exists_out_loss: 0.0287 - loss: 0.6728 - value_out_loss: 0.0319 - value_out_mean_squared_error: 0.0320 - val_exists_out_accuracy: 0.3077 - val_exists_out_loss: 0.0277 - val_loss: 0.6352 - val_value_out_loss: 0.0296 - val_value_out_mean_squared_error: 0.0294\n",
      "Epoch 11/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.2667 - exists_out_loss: 0.0288 - loss: 0.6180 - value_out_loss: 0.0320 - value_out_mean_squared_error: 0.0322 - val_exists_out_accuracy: 0.3132 - val_exists_out_loss: 0.0274 - val_loss: 0.5849 - val_value_out_loss: 0.0304 - val_value_out_mean_squared_error: 0.0301\n",
      "Epoch 12/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.3055 - exists_out_loss: 0.0291 - loss: 0.5708 - value_out_loss: 0.0325 - value_out_mean_squared_error: 0.0328 - val_exists_out_accuracy: 0.3626 - val_exists_out_loss: 0.0269 - val_loss: 0.5393 - val_value_out_loss: 0.0295 - val_value_out_mean_squared_error: 0.0293\n",
      "Epoch 13/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.3126 - exists_out_loss: 0.0290 - loss: 0.5286 - value_out_loss: 0.0327 - value_out_mean_squared_error: 0.0329 - val_exists_out_accuracy: 0.3626 - val_exists_out_loss: 0.0266 - val_loss: 0.4982 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0278\n",
      "Epoch 14/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.3137 - exists_out_loss: 0.0290 - loss: 0.4905 - value_out_loss: 0.0324 - value_out_mean_squared_error: 0.0325 - val_exists_out_accuracy: 0.2637 - val_exists_out_loss: 0.0265 - val_loss: 0.4636 - val_value_out_loss: 0.0285 - val_value_out_mean_squared_error: 0.0284\n",
      "Epoch 15/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.2115 - exists_out_loss: 0.0288 - loss: 0.4560 - value_out_loss: 0.0317 - value_out_mean_squared_error: 0.0318 - val_exists_out_accuracy: 0.2967 - val_exists_out_loss: 0.0264 - val_loss: 0.4323 - val_value_out_loss: 0.0288 - val_value_out_mean_squared_error: 0.0287\n",
      "Epoch 16/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.1892 - exists_out_loss: 0.0287 - loss: 0.4255 - value_out_loss: 0.0313 - value_out_mean_squared_error: 0.0315 - val_exists_out_accuracy: 0.3297 - val_exists_out_loss: 0.0262 - val_loss: 0.4038 - val_value_out_loss: 0.0288 - val_value_out_mean_squared_error: 0.0286\n",
      "Epoch 17/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.3102 - exists_out_loss: 0.0285 - loss: 0.3977 - value_out_loss: 0.0309 - value_out_mean_squared_error: 0.0311 - val_exists_out_accuracy: 0.3297 - val_exists_out_loss: 0.0261 - val_loss: 0.3773 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0280\n",
      "Epoch 18/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.3090 - exists_out_loss: 0.0284 - loss: 0.3729 - value_out_loss: 0.0308 - value_out_mean_squared_error: 0.0309 - val_exists_out_accuracy: 0.2802 - val_exists_out_loss: 0.0261 - val_loss: 0.3541 - val_value_out_loss: 0.0283 - val_value_out_mean_squared_error: 0.0281\n",
      "Epoch 19/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.1504 - exists_out_loss: 0.0284 - loss: 0.3505 - value_out_loss: 0.0307 - value_out_mean_squared_error: 0.0308 - val_exists_out_accuracy: 0.1044 - val_exists_out_loss: 0.0259 - val_loss: 0.3327 - val_value_out_loss: 0.0281 - val_value_out_mean_squared_error: 0.0278\n",
      "Epoch 20/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0353 - exists_out_loss: 0.0282 - loss: 0.3297 - value_out_loss: 0.0304 - value_out_mean_squared_error: 0.0305 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0258 - val_loss: 0.3127 - val_value_out_loss: 0.0276 - val_value_out_mean_squared_error: 0.0273\n",
      "Epoch 21/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0284 - loss: 0.3113 - value_out_loss: 0.0307 - value_out_mean_squared_error: 0.0308 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0260 - val_loss: 0.2962 - val_value_out_loss: 0.0286 - val_value_out_mean_squared_error: 0.0284\n",
      "Epoch 22/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0284 - loss: 0.2948 - value_out_loss: 0.0310 - value_out_mean_squared_error: 0.0312 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0256 - val_loss: 0.2795 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 23/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0279 - loss: 0.2781 - value_out_loss: 0.0303 - value_out_mean_squared_error: 0.0305 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0257 - val_loss: 0.2639 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0275\n",
      "Epoch 24/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0289 - loss: 0.2657 - value_out_loss: 0.0320 - value_out_mean_squared_error: 0.0321 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0270 - val_loss: 0.2547 - val_value_out_loss: 0.0309 - val_value_out_mean_squared_error: 0.0307\n",
      "Epoch 25/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0288 - loss: 0.2538 - value_out_loss: 0.0325 - value_out_mean_squared_error: 0.0326 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0256 - val_loss: 0.2388 - val_value_out_loss: 0.0277 - val_value_out_mean_squared_error: 0.0274\n",
      "Epoch 26/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0278 - loss: 0.2398 - value_out_loss: 0.0311 - value_out_mean_squared_error: 0.0313 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0255 - val_loss: 0.2257 - val_value_out_loss: 0.0268 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 27/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0279 - loss: 0.2272 - value_out_loss: 0.0306 - value_out_mean_squared_error: 0.0307 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0259 - val_loss: 0.2147 - val_value_out_loss: 0.0274 - val_value_out_mean_squared_error: 0.0271\n",
      "Epoch 28/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0288 - loss: 0.2181 - value_out_loss: 0.0320 - value_out_mean_squared_error: 0.0320 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0264 - val_loss: 0.2062 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0280\n",
      "Epoch 29/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0288 - loss: 0.2099 - value_out_loss: 0.0323 - value_out_mean_squared_error: 0.0324 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.1954 - val_value_out_loss: 0.0256 - val_value_out_mean_squared_error: 0.0258\n",
      "Epoch 30/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0273 - loss: 0.1979 - value_out_loss: 0.0299 - value_out_mean_squared_error: 0.0299 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.1854 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0252\n",
      "Epoch 31/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0278 - loss: 0.1893 - value_out_loss: 0.0300 - value_out_mean_squared_error: 0.0301 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0254 - val_loss: 0.1785 - val_value_out_loss: 0.0265 - val_value_out_mean_squared_error: 0.0266\n",
      "Epoch 32/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0281 - loss: 0.1820 - value_out_loss: 0.0304 - value_out_mean_squared_error: 0.0304 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0254 - val_loss: 0.1718 - val_value_out_loss: 0.0265 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 33/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0275 - loss: 0.1740 - value_out_loss: 0.0295 - value_out_mean_squared_error: 0.0296 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.1632 - val_value_out_loss: 0.0250 - val_value_out_mean_squared_error: 0.0252\n",
      "Epoch 34/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0273 - loss: 0.1665 - value_out_loss: 0.0290 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.1569 - val_value_out_loss: 0.0255 - val_value_out_mean_squared_error: 0.0256\n",
      "Epoch 35/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0285 - loss: 0.1636 - value_out_loss: 0.0309 - value_out_mean_squared_error: 0.0309 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0273 - val_loss: 0.1597 - val_value_out_loss: 0.0305 - val_value_out_mean_squared_error: 0.0307\n",
      "Epoch 36/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0289 - loss: 0.1614 - value_out_loss: 0.0320 - value_out_mean_squared_error: 0.0321 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0254 - val_loss: 0.1502 - val_value_out_loss: 0.0261 - val_value_out_mean_squared_error: 0.0262\n",
      "Epoch 37/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0270 - loss: 0.1531 - value_out_loss: 0.0298 - value_out_mean_squared_error: 0.0298 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.1410 - val_value_out_loss: 0.0241 - val_value_out_mean_squared_error: 0.0240\n",
      "Epoch 38/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.1459 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0243 - val_loss: 0.1368 - val_value_out_loss: 0.0257 - val_value_out_mean_squared_error: 0.0258\n",
      "Epoch 39/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0273 - loss: 0.1413 - value_out_loss: 0.0297 - value_out_mean_squared_error: 0.0297 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.1323 - val_value_out_loss: 0.0257 - val_value_out_mean_squared_error: 0.0259\n",
      "Epoch 40/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0272 - loss: 0.1363 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.1280 - val_value_out_loss: 0.0255 - val_value_out_mean_squared_error: 0.0256\n",
      "Epoch 41/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0270 - loss: 0.1321 - value_out_loss: 0.0288 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0242 - val_loss: 0.1236 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0251\n",
      "Epoch 42/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0267 - loss: 0.1282 - value_out_loss: 0.0285 - value_out_mean_squared_error: 0.0286 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0241 - val_loss: 0.1197 - val_value_out_loss: 0.0247 - val_value_out_mean_squared_error: 0.0246\n",
      "Epoch 43/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0268 - loss: 0.1251 - value_out_loss: 0.0287 - value_out_mean_squared_error: 0.0287 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0243 - val_loss: 0.1173 - val_value_out_loss: 0.0252 - val_value_out_mean_squared_error: 0.0251\n",
      "Epoch 44/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0269 - loss: 0.1229 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0243 - val_loss: 0.1148 - val_value_out_loss: 0.0252 - val_value_out_mean_squared_error: 0.0252\n",
      "Epoch 45/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0267 - loss: 0.1198 - value_out_loss: 0.0290 - value_out_mean_squared_error: 0.0290 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.1100 - val_value_out_loss: 0.0239 - val_value_out_mean_squared_error: 0.0239\n",
      "Epoch 46/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0264 - loss: 0.1158 - value_out_loss: 0.0284 - value_out_mean_squared_error: 0.0283 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.1076 - val_value_out_loss: 0.0245 - val_value_out_mean_squared_error: 0.0244\n",
      "Epoch 47/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0287 - loss: 0.1181 - value_out_loss: 0.0315 - value_out_mean_squared_error: 0.0313 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0240 - val_loss: 0.1067 - val_value_out_loss: 0.0253 - val_value_out_mean_squared_error: 0.0253\n",
      "Epoch 48/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0310 - loss: 0.1232 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0394 - val_loss: 0.1436 - val_value_out_loss: 0.0451 - val_value_out_mean_squared_error: 0.0458\n",
      "Epoch 49/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0380 - loss: 0.1397 - value_out_loss: 0.0423 - value_out_mean_squared_error: 0.0429 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0266 - val_loss: 0.1212 - val_value_out_loss: 0.0352 - val_value_out_mean_squared_error: 0.0354\n",
      "Epoch 50/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0290 - loss: 0.1229 - value_out_loss: 0.0346 - value_out_mean_squared_error: 0.0350 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0245 - val_loss: 0.1115 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 51/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0276 - loss: 0.1159 - value_out_loss: 0.0310 - value_out_mean_squared_error: 0.0311 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0241 - val_loss: 0.1047 - val_value_out_loss: 0.0254 - val_value_out_mean_squared_error: 0.0253\n",
      "Epoch 52/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0273 - loss: 0.1111 - value_out_loss: 0.0300 - value_out_mean_squared_error: 0.0300 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0241 - val_loss: 0.1014 - val_value_out_loss: 0.0260 - val_value_out_mean_squared_error: 0.0256\n",
      "Epoch 53/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0273 - loss: 0.1078 - value_out_loss: 0.0300 - value_out_mean_squared_error: 0.0301 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0244 - val_loss: 0.0999 - val_value_out_loss: 0.0272 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 54/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0272 - loss: 0.1056 - value_out_loss: 0.0302 - value_out_mean_squared_error: 0.0304 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.1002 - val_value_out_loss: 0.0288 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 55/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0270 - loss: 0.1039 - value_out_loss: 0.0304 - value_out_mean_squared_error: 0.0306 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0262 - val_loss: 0.1013 - val_value_out_loss: 0.0301 - val_value_out_mean_squared_error: 0.0297\n",
      "Epoch 56/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0271 - loss: 0.1030 - value_out_loss: 0.0309 - value_out_mean_squared_error: 0.0310 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0968 - val_value_out_loss: 0.0278 - val_value_out_mean_squared_error: 0.0274\n",
      "Epoch 57/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0271 - loss: 0.1015 - value_out_loss: 0.0306 - value_out_mean_squared_error: 0.0308 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0244 - val_loss: 0.0930 - val_value_out_loss: 0.0260 - val_value_out_mean_squared_error: 0.0256\n",
      "Epoch 58/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0267 - loss: 0.0991 - value_out_loss: 0.0301 - value_out_mean_squared_error: 0.0301 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0919 - val_value_out_loss: 0.0260 - val_value_out_mean_squared_error: 0.0258\n",
      "Epoch 59/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0270 - loss: 0.0982 - value_out_loss: 0.0304 - value_out_mean_squared_error: 0.0304 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0243 - val_loss: 0.0900 - val_value_out_loss: 0.0255 - val_value_out_mean_squared_error: 0.0255\n",
      "Epoch 60/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0268 - loss: 0.0961 - value_out_loss: 0.0298 - value_out_mean_squared_error: 0.0298 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0243 - val_loss: 0.0886 - val_value_out_loss: 0.0253 - val_value_out_mean_squared_error: 0.0253\n",
      "Epoch 61/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0943 - value_out_loss: 0.0293 - value_out_mean_squared_error: 0.0293 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0242 - val_loss: 0.0872 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0251\n",
      "Epoch 62/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0930 - value_out_loss: 0.0290 - value_out_mean_squared_error: 0.0290 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0240 - val_loss: 0.0860 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0249\n",
      "Epoch 63/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0919 - value_out_loss: 0.0288 - value_out_mean_squared_error: 0.0288 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0239 - val_loss: 0.0848 - val_value_out_loss: 0.0247 - val_value_out_mean_squared_error: 0.0247\n",
      "Epoch 64/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0911 - value_out_loss: 0.0288 - value_out_mean_squared_error: 0.0288 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0239 - val_loss: 0.0838 - val_value_out_loss: 0.0246 - val_value_out_mean_squared_error: 0.0245\n",
      "Epoch 65/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0903 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.0830 - val_value_out_loss: 0.0246 - val_value_out_mean_squared_error: 0.0245\n",
      "Epoch 66/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0898 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.0823 - val_value_out_loss: 0.0247 - val_value_out_mean_squared_error: 0.0246\n",
      "Epoch 67/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0891 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.0818 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0248\n",
      "Epoch 68/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0887 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0814 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0249\n",
      "Epoch 69/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0879 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0808 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0250\n",
      "Epoch 70/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0877 - value_out_loss: 0.0293 - value_out_mean_squared_error: 0.0293 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0805 - val_value_out_loss: 0.0253 - val_value_out_mean_squared_error: 0.0251\n",
      "Epoch 71/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0264 - loss: 0.0870 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0293 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0797 - val_value_out_loss: 0.0250 - val_value_out_mean_squared_error: 0.0249\n",
      "Epoch 72/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0264 - loss: 0.0865 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0791 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0248\n",
      "Epoch 73/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0863 - value_out_loss: 0.0293 - value_out_mean_squared_error: 0.0294 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0785 - val_value_out_loss: 0.0248 - val_value_out_mean_squared_error: 0.0246\n",
      "Epoch 74/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0264 - loss: 0.0856 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0780 - val_value_out_loss: 0.0246 - val_value_out_mean_squared_error: 0.0245\n",
      "Epoch 75/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0857 - value_out_loss: 0.0295 - value_out_mean_squared_error: 0.0295 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0782 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0249\n",
      "Epoch 76/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0265 - loss: 0.0855 - value_out_loss: 0.0295 - value_out_mean_squared_error: 0.0295 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0234 - val_loss: 0.0773 - val_value_out_loss: 0.0245 - val_value_out_mean_squared_error: 0.0244\n",
      "Epoch 77/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0262 - loss: 0.0841 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0235 - val_loss: 0.0768 - val_value_out_loss: 0.0245 - val_value_out_mean_squared_error: 0.0244\n",
      "Epoch 78/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0268 - loss: 0.0849 - value_out_loss: 0.0296 - value_out_mean_squared_error: 0.0296 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0240 - val_loss: 0.0784 - val_value_out_loss: 0.0257 - val_value_out_mean_squared_error: 0.0257\n",
      "Epoch 79/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0266 - loss: 0.0848 - value_out_loss: 0.0295 - value_out_mean_squared_error: 0.0296 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0233 - val_loss: 0.0765 - val_value_out_loss: 0.0245 - val_value_out_mean_squared_error: 0.0244\n",
      "Epoch 80/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0260 - loss: 0.0830 - value_out_loss: 0.0285 - value_out_mean_squared_error: 0.0286 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0233 - val_loss: 0.0759 - val_value_out_loss: 0.0244 - val_value_out_mean_squared_error: 0.0243\n",
      "Epoch 81/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0264 - loss: 0.0834 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0764 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0249\n",
      "Epoch 82/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0263 - loss: 0.0833 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0232 - val_loss: 0.0753 - val_value_out_loss: 0.0244 - val_value_out_mean_squared_error: 0.0242\n",
      "Epoch 83/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0259 - loss: 0.0819 - value_out_loss: 0.0284 - value_out_mean_squared_error: 0.0284 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0233 - val_loss: 0.0749 - val_value_out_loss: 0.0244 - val_value_out_mean_squared_error: 0.0242\n",
      "Epoch 84/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0264 - loss: 0.0826 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0291 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0762 - val_value_out_loss: 0.0253 - val_value_out_mean_squared_error: 0.0252\n",
      "Epoch 85/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0265 - loss: 0.0832 - value_out_loss: 0.0294 - value_out_mean_squared_error: 0.0295 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0232 - val_loss: 0.0754 - val_value_out_loss: 0.0248 - val_value_out_mean_squared_error: 0.0247\n",
      "Epoch 86/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0258 - loss: 0.0815 - value_out_loss: 0.0285 - value_out_mean_squared_error: 0.0285 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0237 - val_loss: 0.0755 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0250\n",
      "Epoch 87/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0265 - loss: 0.0824 - value_out_loss: 0.0294 - value_out_mean_squared_error: 0.0294 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0240 - val_loss: 0.0766 - val_value_out_loss: 0.0261 - val_value_out_mean_squared_error: 0.0260\n",
      "Epoch 88/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0268 - loss: 0.0838 - value_out_loss: 0.0301 - value_out_mean_squared_error: 0.0302 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0235 - val_loss: 0.0765 - val_value_out_loss: 0.0257 - val_value_out_mean_squared_error: 0.0257\n",
      "Epoch 89/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0258 - loss: 0.0818 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0235 - val_loss: 0.0757 - val_value_out_loss: 0.0254 - val_value_out_mean_squared_error: 0.0253\n",
      "Epoch 90/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0266 - loss: 0.0828 - value_out_loss: 0.0296 - value_out_mean_squared_error: 0.0297 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0248 - val_loss: 0.0789 - val_value_out_loss: 0.0273 - val_value_out_mean_squared_error: 0.0274\n",
      "Epoch 91/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0266 - loss: 0.0834 - value_out_loss: 0.0299 - value_out_mean_squared_error: 0.0300 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.0786 - val_value_out_loss: 0.0270 - val_value_out_mean_squared_error: 0.0268\n",
      "Epoch 92/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0264 - loss: 0.0829 - value_out_loss: 0.0295 - value_out_mean_squared_error: 0.0296 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0241 - val_loss: 0.0774 - val_value_out_loss: 0.0262 - val_value_out_mean_squared_error: 0.0262\n",
      "Epoch 93/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0259 - loss: 0.0815 - value_out_loss: 0.0288 - value_out_mean_squared_error: 0.0288 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0231 - val_loss: 0.0742 - val_value_out_loss: 0.0246 - val_value_out_mean_squared_error: 0.0245\n",
      "Epoch 94/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0264 - loss: 0.0821 - value_out_loss: 0.0293 - value_out_mean_squared_error: 0.0294 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0234 - val_loss: 0.0748 - val_value_out_loss: 0.0251 - val_value_out_mean_squared_error: 0.0251\n",
      "Epoch 95/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0257 - loss: 0.0802 - value_out_loss: 0.0284 - value_out_mean_squared_error: 0.0284 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0236 - val_loss: 0.0741 - val_value_out_loss: 0.0249 - val_value_out_mean_squared_error: 0.0248\n",
      "Epoch 96/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0263 - loss: 0.0810 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0237 - val_loss: 0.0751 - val_value_out_loss: 0.0257 - val_value_out_mean_squared_error: 0.0257\n",
      "Epoch 97/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0260 - loss: 0.0805 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0244 - val_loss: 0.0764 - val_value_out_loss: 0.0264 - val_value_out_mean_squared_error: 0.0262\n",
      "Epoch 98/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0261 - loss: 0.0807 - value_out_loss: 0.0289 - value_out_mean_squared_error: 0.0289 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0234 - val_loss: 0.0745 - val_value_out_loss: 0.0252 - val_value_out_mean_squared_error: 0.0252\n",
      "Epoch 99/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0257 - loss: 0.0797 - value_out_loss: 0.0283 - value_out_mean_squared_error: 0.0284 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0238 - val_loss: 0.0745 - val_value_out_loss: 0.0255 - val_value_out_mean_squared_error: 0.0253\n",
      "Epoch 100/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0263 - loss: 0.0809 - value_out_loss: 0.0291 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0241 - val_loss: 0.0764 - val_value_out_loss: 0.0266 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 101/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0261 - loss: 0.0808 - value_out_loss: 0.0290 - value_out_mean_squared_error: 0.0292 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0245 - val_loss: 0.0771 - val_value_out_loss: 0.0271 - val_value_out_mean_squared_error: 0.0268\n",
      "Epoch 102/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0267 - loss: 0.0825 - value_out_loss: 0.0298 - value_out_mean_squared_error: 0.0300 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0250 - val_loss: 0.0797 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 103/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0260 - loss: 0.0817 - value_out_loss: 0.0292 - value_out_mean_squared_error: 0.0293 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0224 - val_loss: 0.0731 - val_value_out_loss: 0.0246 - val_value_out_mean_squared_error: 0.0244\n",
      "Epoch 104/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0256 - loss: 0.0805 - value_out_loss: 0.0288 - value_out_mean_squared_error: 0.0288 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0236 - val_loss: 0.0749 - val_value_out_loss: 0.0256 - val_value_out_mean_squared_error: 0.0255\n",
      "Epoch 105/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0255 - loss: 0.0793 - value_out_loss: 0.0282 - value_out_mean_squared_error: 0.0283 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.0225 - val_loss: 0.0715 - val_value_out_loss: 0.0240 - val_value_out_mean_squared_error: 0.0238\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        # (optional) sanity check the output order\n",
    "        print(\"Output order:\", model.output_names)  # e.g. ['value_out', 'exists_out']\n",
    "        \n",
    "        # --- make value_out sample weights 1D so it matches loss shape [N] ---\n",
    "        value_sw_train = np.asarray(y_exists_train).astype(\"float32\")\n",
    "        value_sw_val   = np.asarray(y_exists_val).astype(\"float32\")\n",
    "        \n",
    "        # If y_exists is (N,16), collapse to (N,)\n",
    "        if value_sw_train.ndim == 2:\n",
    "            value_sw_train = value_sw_train.max(axis=1)   # or .mean(axis=1)\n",
    "        if value_sw_val.ndim == 2:\n",
    "            value_sw_val = value_sw_val.max(axis=1)       # or .mean(axis=1)\n",
    "        \n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            [np.asarray(y_value_train), np.asarray(y_exists_train)],\n",
    "            sample_weight=[\n",
    "                value_sw_train,                                     # NOW (N,)\n",
    "                np.ones((len(y_exists_train),), dtype=\"float32\"),\n",
    "            ],\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                [np.asarray(y_value_val), np.asarray(y_exists_val)],\n",
    "                [\n",
    "                    value_sw_val,                                   # NOW (N,)\n",
    "                    np.ones((len(y_exists_val),), dtype=\"float32\"),\n",
    "                ],\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping, lr_monitor],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_learning_rate.pdf')\n",
    "    plt.show()\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp_linear = tuner_linear_encoding.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model_linear = tuner_linear_encoding.hypermodel.build(best_hp_linear)\n",
    "\n",
    "        lr_monitor_linear_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        history_linear_encoding = model_linear.fit(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping, lr_monitor_linear_encoding],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model_linear\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    plt.plot(history_linear_encoding.history['loss'])\n",
    "    plt.plot(history_linear_encoding.history['val_loss'])\n",
    "    plt.title('Model loss linear encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor_linear_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs linear encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47150b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I needed to restart the kernal and skip the block above to run this block-otherwise i got memory allocation error. \n",
    "#theres probably a better way to do this--like clearing the memory before running this block so you can run both models sequentially\n",
    "\n",
    "if 'Try Both' in ENCODING_TYPE and KERAS_TUNER:\n",
    "    best_hp_onehot = tuner_one_hot_encoding.get_best_hyperparameters(1)[0]\n",
    "    model_onehot = tuner_one_hot_encoding.hypermodel.build(best_hp_onehot)\n",
    "\n",
    "    lr_monitor_one_hot_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "    \n",
    "    history_one_hot_encoding = model_onehot.fit(\n",
    "        np.asarray(X_train_one_hot_encoding),\n",
    "        {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "        callbacks=[early_stopping, lr_monitor_one_hot_encoding],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    plt.plot(history_one_hot_encoding.history['loss'])\n",
    "    plt.plot(history_one_hot_encoding.history['val_loss'])\n",
    "    plt.title('Model loss one hot encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_history.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(lr_monitor_one_hot_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs one hot encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a331d8-70ea-4ea4-8f5b-256472850784",
   "metadata": {},
   "source": [
    "Measure and print metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32ff7d16-5709-41d6-b3f7-e6c9a062b35c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss one_hot encoding mae: 0.11313986778259277\n",
      "   Encoding Type Train Loss Metric  Test Loss\n",
      "one hot Encoding               mae    0.11314\n"
     ]
    }
   ],
   "source": [
    "#take a look at the loss results and save them \n",
    "\n",
    "# clear everything so we start with a blank slate memory wise\n",
    "tf.keras.backend.clear_session()                         #clear tf backend\n",
    "gc.collect()                                             #just collect stray things\n",
    "#tf.config.experimental.reset_memory_stats('GPU:0')       #clear gpus\n",
    "\n",
    "\n",
    "def get_loss(eval_out):\n",
    "    # eval_out can be float, list/tuple/ndarray, or dict\n",
    "    if isinstance(eval_out, dict):\n",
    "        return float(eval_out.get('loss', list(eval_out.values())[0]))\n",
    "    if isinstance(eval_out, (list, tuple, np.ndarray)):\n",
    "        return float(eval_out[0])\n",
    "    return float(eval_out)\n",
    "\n",
    "def mlp_signature(m, prefix=\"mlp\"):\n",
    "    #get the model input sizze first\n",
    "    in_shape = m.input_shape\n",
    "    if isinstance(in_shape, list):     #just get the first one\n",
    "        in_shape = in_shape[0]\n",
    "    dims = [d for d in in_shape[1:] if d is not None]\n",
    "    input_size = int(np.prod(dims)) if dims else \"None\"\n",
    "\n",
    "    # now get the dense laysers in order\n",
    "    dense_units = [l.units for l in m.layers if isinstance(l, Dense)]\n",
    "\n",
    "    parts = [prefix, str(input_size)] + [str(u) for u in dense_units]\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "    \n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    model = load_model(best_model_file, compile=False)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result = model.evaluate(\n",
    "        np.asarray(X_test),\n",
    "        {'value_out': np.asarray(y_value_test), 'exists_out': np.asarray(y_exists_test)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result = get_loss(test_loss_result)\n",
    "    \n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape = mlp_signature(model)\n",
    "\n",
    "    print('Current loss {} encoding {}: {}'.format(encoding, TRAIN_LOSS, test_loss_result))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': f'{ENCODING_TYPE} Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result},\n",
    "        ])\n",
    "\n",
    "else:\n",
    "    # we need to do some fancy allocation of recources if we are going to load both models\n",
    "    # do the first on one GPU\n",
    "    linear_model = load_model(best_model_file_linear, compile=False)\n",
    "    linear_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result_linear_encoding = linear_model.evaluate(\n",
    "        np.asarray(X_test_linear_encoding),\n",
    "        {'value_out': np.asarray(y_value_test_linear_encoding), 'exists_out': np.asarray(y_exists_test_linear_encoding)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result_linear_encoding = get_loss(test_loss_result_linear_encoding)\n",
    "    \n",
    "    # now do on CPU to avoid GPU allocation\n",
    "    with tf.device('/GPU:0'):\n",
    "        onehot_model = load_model(best_model_file_onehot, compile=False)\n",
    "        onehot_model.compile(\n",
    "            optimizer='adam',\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = onehot_model.evaluate(\n",
    "            np.asarray(X_test_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_test_one_hot_encoding), 'exists_out': np.asarray(y_exists_test_one_hot_encoding)},\n",
    "            verbose=0\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = get_loss(test_loss_result_one_hot_encoding)\n",
    "\n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape_one_hot_encoding = mlp_signature(onehot_model)\n",
    "    model_shape_linear_encoding  = mlp_signature(linear_model)\n",
    "    \n",
    "    print('Current loss linear encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_linear_encoding))\n",
    "    print('Current loss one hot encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_one_hot_encoding))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': 'linear Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_linear_encoding},\n",
    "        {'Encoding Type': 'One Hot Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_one_hot_encoding}\n",
    "    ])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv('test_loss_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7812af-2596-44d2-bb25-68741e0506ba",
   "metadata": {},
   "source": [
    "## Compare predictions vs. test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60157266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7f78d_row0_col3, #T_7f78d_row1_col3, #T_7f78d_row2_col3, #T_7f78d_row3_col3, #T_7f78d_row4_col3, #T_7f78d_row5_col3, #T_7f78d_row6_col3, #T_7f78d_row7_col3, #T_7f78d_row8_col3, #T_7f78d_row9_col3, #T_7f78d_row10_col3, #T_7f78d_row11_col3 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7f78d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7f78d_level0_col0\" class=\"col_heading level0 col0\" >data_augmentation</th>\n",
       "      <th id=\"T_7f78d_level0_col1\" class=\"col_heading level0 col1\" >model_shape</th>\n",
       "      <th id=\"T_7f78d_level0_col2\" class=\"col_heading level0 col2\" >encoding_type</th>\n",
       "      <th id=\"T_7f78d_level0_col3\" class=\"col_heading level0 col3\" >test_loss</th>\n",
       "      <th id=\"T_7f78d_level0_col4\" class=\"col_heading level0 col4\" >train_loss</th>\n",
       "      <th id=\"T_7f78d_level0_col5\" class=\"col_heading level0 col5\" >train_dropout_rate</th>\n",
       "      <th id=\"T_7f78d_level0_col6\" class=\"col_heading level0 col6\" >train_early_stop_patience</th>\n",
       "      <th id=\"T_7f78d_level0_col7\" class=\"col_heading level0 col7\" >train_batch_size</th>\n",
       "      <th id=\"T_7f78d_level0_col8\" class=\"col_heading level0 col8\" >train_val_split</th>\n",
       "      <th id=\"T_7f78d_level0_col9\" class=\"col_heading level0 col9\" >lr_initial</th>\n",
       "      <th id=\"T_7f78d_level0_col10\" class=\"col_heading level0 col10\" >lr_decay_step</th>\n",
       "      <th id=\"T_7f78d_level0_col11\" class=\"col_heading level0 col11\" >lr_decay_rate</th>\n",
       "      <th id=\"T_7f78d_level0_col12\" class=\"col_heading level0 col12\" >lr_stair_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7f78d_row0_col0\" class=\"data row0 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row0_col1\" class=\"data row0 col1\" >mlp_2_1500_2800_1300_2100_45</td>\n",
       "      <td id=\"T_7f78d_row0_col2\" class=\"data row0 col2\" >One Hot</td>\n",
       "      <td id=\"T_7f78d_row0_col3\" class=\"data row0 col3\" >0.026580</td>\n",
       "      <td id=\"T_7f78d_row0_col4\" class=\"data row0 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row0_col5\" class=\"data row0 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row0_col6\" class=\"data row0 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row0_col7\" class=\"data row0 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row0_col8\" class=\"data row0 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row0_col9\" class=\"data row0 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row0_col10\" class=\"data row0 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row0_col11\" class=\"data row0 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row0_col12\" class=\"data row0 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7f78d_row1_col0\" class=\"data row1 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row1_col1\" class=\"data row1 col1\" >mlp_2_600_100_2600_5000_45</td>\n",
       "      <td id=\"T_7f78d_row1_col2\" class=\"data row1 col2\" >Linear</td>\n",
       "      <td id=\"T_7f78d_row1_col3\" class=\"data row1 col3\" >0.027197</td>\n",
       "      <td id=\"T_7f78d_row1_col4\" class=\"data row1 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row1_col5\" class=\"data row1 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row1_col6\" class=\"data row1 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row1_col7\" class=\"data row1 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row1_col8\" class=\"data row1 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row1_col9\" class=\"data row1 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row1_col10\" class=\"data row1 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row1_col11\" class=\"data row1 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row1_col12\" class=\"data row1 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7f78d_row2_col0\" class=\"data row2 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row2_col1\" class=\"data row2 col1\" >mlp_2_1500_2800_1300_2100_45</td>\n",
       "      <td id=\"T_7f78d_row2_col2\" class=\"data row2 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row2_col3\" class=\"data row2 col3\" >0.026581</td>\n",
       "      <td id=\"T_7f78d_row2_col4\" class=\"data row2 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row2_col5\" class=\"data row2 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row2_col6\" class=\"data row2 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row2_col7\" class=\"data row2 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row2_col8\" class=\"data row2 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row2_col9\" class=\"data row2 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row2_col10\" class=\"data row2 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row2_col11\" class=\"data row2 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row2_col12\" class=\"data row2 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7f78d_row3_col0\" class=\"data row3 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row3_col1\" class=\"data row3 col1\" >mlp_2_3300_200_4600_1700_45</td>\n",
       "      <td id=\"T_7f78d_row3_col2\" class=\"data row3 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row3_col3\" class=\"data row3 col3\" >0.023184</td>\n",
       "      <td id=\"T_7f78d_row3_col4\" class=\"data row3 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row3_col5\" class=\"data row3 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row3_col6\" class=\"data row3 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row3_col7\" class=\"data row3 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row3_col8\" class=\"data row3 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row3_col9\" class=\"data row3 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row3_col10\" class=\"data row3 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row3_col11\" class=\"data row3 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row3_col12\" class=\"data row3 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7f78d_row4_col0\" class=\"data row4 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row4_col1\" class=\"data row4 col1\" >mlp_2_3300_200_4600_1700_45</td>\n",
       "      <td id=\"T_7f78d_row4_col2\" class=\"data row4 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row4_col3\" class=\"data row4 col3\" >0.023925</td>\n",
       "      <td id=\"T_7f78d_row4_col4\" class=\"data row4 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row4_col5\" class=\"data row4 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row4_col6\" class=\"data row4 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row4_col7\" class=\"data row4 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row4_col8\" class=\"data row4 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row4_col9\" class=\"data row4 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row4_col10\" class=\"data row4 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row4_col11\" class=\"data row4 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row4_col12\" class=\"data row4 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7f78d_row5_col0\" class=\"data row5 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row5_col1\" class=\"data row5 col1\" >mlp_2_700_3800_400_1800_16</td>\n",
       "      <td id=\"T_7f78d_row5_col2\" class=\"data row5 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row5_col3\" class=\"data row5 col3\" >0.045630</td>\n",
       "      <td id=\"T_7f78d_row5_col4\" class=\"data row5 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row5_col5\" class=\"data row5 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row5_col6\" class=\"data row5 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row5_col7\" class=\"data row5 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row5_col8\" class=\"data row5 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row5_col9\" class=\"data row5 col9\" >0.001456</td>\n",
       "      <td id=\"T_7f78d_row5_col10\" class=\"data row5 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row5_col11\" class=\"data row5 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row5_col12\" class=\"data row5 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7f78d_row6_col0\" class=\"data row6 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row6_col1\" class=\"data row6 col1\" >mlp_2_700_3800_400_1800_16</td>\n",
       "      <td id=\"T_7f78d_row6_col2\" class=\"data row6 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row6_col3\" class=\"data row6 col3\" >0.041409</td>\n",
       "      <td id=\"T_7f78d_row6_col4\" class=\"data row6 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row6_col5\" class=\"data row6 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row6_col6\" class=\"data row6 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row6_col7\" class=\"data row6 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row6_col8\" class=\"data row6 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row6_col9\" class=\"data row6 col9\" >0.002648</td>\n",
       "      <td id=\"T_7f78d_row6_col10\" class=\"data row6 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row6_col11\" class=\"data row6 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row6_col12\" class=\"data row6 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7f78d_row7_col0\" class=\"data row7 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row7_col1\" class=\"data row7 col1\" >mlp_2_2000_400_1300_1700_16_16</td>\n",
       "      <td id=\"T_7f78d_row7_col2\" class=\"data row7 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row7_col3\" class=\"data row7 col3\" >0.087074</td>\n",
       "      <td id=\"T_7f78d_row7_col4\" class=\"data row7 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row7_col5\" class=\"data row7 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row7_col6\" class=\"data row7 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row7_col7\" class=\"data row7 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row7_col8\" class=\"data row7 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row7_col9\" class=\"data row7 col9\" >0.002648</td>\n",
       "      <td id=\"T_7f78d_row7_col10\" class=\"data row7 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row7_col11\" class=\"data row7 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row7_col12\" class=\"data row7 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7f78d_row8_col0\" class=\"data row8 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row8_col1\" class=\"data row8 col1\" >mlp_2_2000_400_1300_1700_16_16</td>\n",
       "      <td id=\"T_7f78d_row8_col2\" class=\"data row8 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row8_col3\" class=\"data row8 col3\" >0.080590</td>\n",
       "      <td id=\"T_7f78d_row8_col4\" class=\"data row8 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row8_col5\" class=\"data row8 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row8_col6\" class=\"data row8 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row8_col7\" class=\"data row8 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row8_col8\" class=\"data row8 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row8_col9\" class=\"data row8 col9\" >0.002505</td>\n",
       "      <td id=\"T_7f78d_row8_col10\" class=\"data row8 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row8_col11\" class=\"data row8 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row8_col12\" class=\"data row8 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7f78d_row9_col0\" class=\"data row9 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row9_col1\" class=\"data row9 col1\" >mlp_2_2000_2700_500_4000_16_16</td>\n",
       "      <td id=\"T_7f78d_row9_col2\" class=\"data row9 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row9_col3\" class=\"data row9 col3\" >0.086770</td>\n",
       "      <td id=\"T_7f78d_row9_col4\" class=\"data row9 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_7f78d_row9_col5\" class=\"data row9 col5\" >0.400000</td>\n",
       "      <td id=\"T_7f78d_row9_col6\" class=\"data row9 col6\" >50</td>\n",
       "      <td id=\"T_7f78d_row9_col7\" class=\"data row9 col7\" >32</td>\n",
       "      <td id=\"T_7f78d_row9_col8\" class=\"data row9 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row9_col9\" class=\"data row9 col9\" >0.002505</td>\n",
       "      <td id=\"T_7f78d_row9_col10\" class=\"data row9 col10\" >100</td>\n",
       "      <td id=\"T_7f78d_row9_col11\" class=\"data row9 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row9_col12\" class=\"data row9 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_7f78d_row10_col0\" class=\"data row10 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row10_col1\" class=\"data row10 col1\" >mlp_2_640_550_850_550_1410_16_16</td>\n",
       "      <td id=\"T_7f78d_row10_col2\" class=\"data row10 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row10_col3\" class=\"data row10 col3\" >0.129929</td>\n",
       "      <td id=\"T_7f78d_row10_col4\" class=\"data row10 col4\" >mae</td>\n",
       "      <td id=\"T_7f78d_row10_col5\" class=\"data row10 col5\" >0.000000</td>\n",
       "      <td id=\"T_7f78d_row10_col6\" class=\"data row10 col6\" >60</td>\n",
       "      <td id=\"T_7f78d_row10_col7\" class=\"data row10 col7\" >128</td>\n",
       "      <td id=\"T_7f78d_row10_col8\" class=\"data row10 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row10_col9\" class=\"data row10 col9\" >0.000982</td>\n",
       "      <td id=\"T_7f78d_row10_col10\" class=\"data row10 col10\" >140</td>\n",
       "      <td id=\"T_7f78d_row10_col11\" class=\"data row10 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row10_col12\" class=\"data row10 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f78d_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_7f78d_row11_col0\" class=\"data row11 col0\" >True</td>\n",
       "      <td id=\"T_7f78d_row11_col1\" class=\"data row11 col1\" >mlp_2_500_1400_820_430_800_16_16</td>\n",
       "      <td id=\"T_7f78d_row11_col2\" class=\"data row11 col2\" >one hot</td>\n",
       "      <td id=\"T_7f78d_row11_col3\" class=\"data row11 col3\" >0.113140</td>\n",
       "      <td id=\"T_7f78d_row11_col4\" class=\"data row11 col4\" >mae</td>\n",
       "      <td id=\"T_7f78d_row11_col5\" class=\"data row11 col5\" >0.000000</td>\n",
       "      <td id=\"T_7f78d_row11_col6\" class=\"data row11 col6\" >60</td>\n",
       "      <td id=\"T_7f78d_row11_col7\" class=\"data row11 col7\" >128</td>\n",
       "      <td id=\"T_7f78d_row11_col8\" class=\"data row11 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_7f78d_row11_col9\" class=\"data row11 col9\" >0.000982</td>\n",
       "      <td id=\"T_7f78d_row11_col10\" class=\"data row11 col10\" >140</td>\n",
       "      <td id=\"T_7f78d_row11_col11\" class=\"data row11 col11\" >0.990000</td>\n",
       "      <td id=\"T_7f78d_row11_col12\" class=\"data row11 col12\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1704519540>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape,\n",
    "        ENCODING_TYPE,\n",
    "        test_loss_result,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df = df.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "\n",
    "else:\n",
    "    #---------------------------------------------------one hot---------------------------------------\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_one_hot_encoding,\n",
    "        'One Hot',\n",
    "        test_loss_result_one_hot_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "            \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_one_hot_encoding = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_one_hot_encoding = df_one_hot_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    #---------------------------------------------------linear---------------------------------------\n",
    "    csv_data_linear_encoding = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_linear_encoding,\n",
    "        'linear',\n",
    "        test_loss_result_linear_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file_linear_encoding = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    with open(csv_file_linear_encoding, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data_linear_encoding)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_linear_encoding = pd.read_csv(csv_file_linear_encoding)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_linear_encoding = df_linear_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df_linear_encoding)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ea88851-ed24-42d4-b36c-e79175af6847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decide which model file & test set to use\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    chosen_path = best_model_file\n",
    "    X_test_cur = np.asarray(X_test)\n",
    "    y_value_test_cur = np.asarray(y_value_test)\n",
    "    y_exists_test_cur = np.asarray(y_exists_test)\n",
    "else:\n",
    "    if test_loss_result_linear_encoding < test_loss_result_one_hot_encoding:\n",
    "        chosen_path = best_model_file_linear\n",
    "        X_test_cur = np.asarray(X_test_linear_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_linear_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_linear_encoding)\n",
    "        y_encoding_format_name = 'linear'\n",
    "    else:\n",
    "        chosen_path = best_model_file_onehot\n",
    "        X_test_cur = np.asarray(X_test_one_hot_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_one_hot_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_one_hot_encoding)\n",
    "        y_encoding_format_name = 'one_hot'\n",
    "\n",
    "# clear everything again, then load & predict on one cpu device to avoid the memory thing again\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    chosen_model = load_model(chosen_path, compile=False)\n",
    "    pred = chosen_model.predict(X_test_cur, verbose=0)\n",
    "\n",
    "# Unpack model outputs into proper numeric arrays\n",
    "if isinstance(pred, dict):\n",
    "    y_value_pred = np.asarray(pred['value_out'])\n",
    "    y_exists_pred = np.asarray(pred['exists_out'])\n",
    "else:\n",
    "    y_value_pred, y_exists_pred = pred\n",
    "    y_value_pred = np.asarray(y_value_pred)\n",
    "    y_exists_pred = np.asarray(y_exists_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6ffa127-c6a4-4a52-8a29-4c08ae0cca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_one_hot.csv\n",
      "\n",
      " Sample 0  X: cavity_frequency=0.0208384, kappa=0.16982\n",
      "                                                          param  exists      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.403941  0.410374   0.006433 4.138131e-05\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000  0.096151   0.096151 9.244988e-03\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000 -0.000990   0.000990 9.802800e-07\n",
      "                          design_options.claw_opts.cross_length     1.0 0.000000 -0.002308   0.002308 5.328428e-06\n",
      "                           design_options.claw_opts.cross_width     1.0 0.000000 -0.001339   0.001339 1.792721e-06\n",
      "                             design_options.claw_opts.cross_gap     1.0 0.000000 -0.001735   0.001735 3.010716e-06\n",
      "                           design_options.cpw_opts.total_length     1.0 0.428571  0.350626   0.077945 6.075500e-03\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.731347   0.268653 7.217455e-02\n",
      "                      design_options.cpw_opts.meander.asymmetry     1.0 0.956522  0.758340   0.198182 3.927605e-02\n",
      "                       design_options.cplr_opts.coupling_length     1.0 0.700000  0.624378   0.075622 5.718620e-03\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 1.000000  0.731247   0.268753 7.222804e-02\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000 -0.003151        NaN          NaN\n",
      "                                               coupler_type_CLT     1.0 1.000000  0.996688   0.003312 1.096889e-05\n",
      "                                              coupler_type_NCap     1.0 0.000000  0.000678   0.000678 4.594429e-07\n",
      "                                            resonator_type_half     1.0 0.000000 -0.000664   0.000664 4.408112e-07\n",
      "                                         resonator_type_quarter     1.0 1.000000  0.997698   0.002302 5.300809e-06\n",
      "\n",
      " Sample 1  X: cavity_frequency=0.147811, kappa=0.00035887\n",
      "                                                          param  exists      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.236453  0.135448   0.101005 1.020195e-02\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000  0.004799   0.004799 2.302612e-05\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000 -0.008992   0.008992 8.085478e-05\n",
      "                          design_options.claw_opts.cross_length     1.0 1.000000  1.000286   0.000286 8.158190e-08\n",
      "                           design_options.claw_opts.cross_width     1.0 1.000000  1.001468   0.001468 2.155557e-06\n",
      "                             design_options.claw_opts.cross_gap     1.0 1.000000  1.001490   0.001490 2.220446e-06\n",
      "                           design_options.cpw_opts.total_length     1.0 0.714286  0.693113   0.021173 4.482851e-04\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.980300   0.019700 3.880920e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0 0.652174  0.643607        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0 0.000000 -0.009648        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 0.500000  0.482750   0.017250 2.975636e-04\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000 -0.000984        NaN          NaN\n",
      "                                               coupler_type_CLT     1.0 0.000000 -0.003728   0.003728 1.389467e-05\n",
      "                                              coupler_type_NCap     1.0 1.000000  1.003162   0.003162 9.996149e-06\n",
      "                                            resonator_type_half     1.0 1.000000  0.999731   0.000269 7.251914e-08\n",
      "                                         resonator_type_quarter     1.0 0.000000 -0.004260   0.004260 1.814890e-05\n",
      "\n",
      " Sample 2  X: cavity_frequency=0.255023, kappa=0.00060377\n",
      "                                                          param  exists      ref      pred  abs_error  sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.019704  0.133062   0.113357  0.012850\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000  0.005588   0.005588  0.000031\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000  0.017559   0.017559  0.000308\n",
      "                          design_options.claw_opts.cross_length     1.0 1.000000  1.005037   0.005037  0.000025\n",
      "                           design_options.claw_opts.cross_width     1.0 1.000000  1.006477   0.006477  0.000042\n",
      "                             design_options.claw_opts.cross_gap     1.0 1.000000  1.006275   0.006275  0.000039\n",
      "                           design_options.cpw_opts.total_length     1.0 0.500000  0.545277   0.045277  0.002050\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.985886   0.014114  0.000199\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0 0.652174  0.642867        NaN       NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0 0.000000 -0.009446        NaN       NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 0.500000  0.483967   0.016033  0.000257\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000 -0.001119        NaN       NaN\n",
      "                                               coupler_type_CLT     1.0 0.000000 -0.007631   0.007631  0.000058\n",
      "                                              coupler_type_NCap     1.0 1.000000  1.007576   0.007576  0.000057\n",
      "                                            resonator_type_half     1.0 1.000000  1.004521   0.004521  0.000020\n",
      "                                         resonator_type_quarter     1.0 0.000000 -0.007816   0.007816  0.000061\n",
      "\n",
      "Global error stats (defined parameters only):\n",
      "  min abs_error: 1.4543533325195312e-05\n",
      "  median abs_error: 0.013299010694026947\n",
      "  max abs_error: 0.9176910668611525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nHere onehot/linear encoding and the mlp which maps categorical data to 1s and 0s is probably \\nthrowing off the global average. These will be rounded in the future and will probably always \\nround to the right number to reconstruct the correct category-- but for now it might throw off \\nthe overall average error. In the future we might want to just have it consider the non categorical \\ndata when finding an overall average and reporting that number.\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets look at a specfic case to see how the model predicts things\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    y_encoding_format_name = encoding\n",
    "    \n",
    "filename = f'y_characteristics_{y_encoding_format_name}_encoding.csv'\n",
    "with open(filename, 'r') as f:\n",
    "    headers = f.readline().strip().split(',')\n",
    "\n",
    "X_test_cur = np.asarray(X_test_cur)\n",
    "y_value_test_cur = np.asarray(y_value_test_cur)\n",
    "y_exists_test_cur = np.asarray(y_exists_test_cur)\n",
    "y_value_pred = np.asarray(y_value_pred)\n",
    "\n",
    "n_samples, n_params = y_value_test_cur.shape\n",
    "#change nsamples if you dont want to look at everything\n",
    "n_samples = 3\n",
    "\n",
    "# raw errors\n",
    "sq_errors = (y_value_test_cur - y_value_pred) ** 2\n",
    "abs_errors = np.abs(y_value_test_cur - y_value_pred)\n",
    "\n",
    "# mask out parameters that are \"not defined\" according to the ground-truth exists flag\n",
    "sq_errors_masked = np.where(y_exists_test_cur == 1.0, sq_errors, np.nan)\n",
    "abs_errors_masked = np.where(y_exists_test_cur == 1.0, abs_errors, np.nan)\n",
    "\n",
    "# make a nice dataframe so the output is comprehensible\n",
    "rows = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_cur[i, 0], X_test_cur[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref\": y_value_test_cur[i, j],\n",
    "            \"pred\": y_value_pred[i, j],\n",
    "            \"abs_error\": abs_errors_masked[i, j],\n",
    "            \"sq_error\": sq_errors_masked[i, j],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "#save it incase we want to do stuff with this in the future\n",
    "out_csv = Path(f\"predictions_and_errors_{y_encoding_format_name}.csv\")\n",
    "df.to_csv(out_csv, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv.resolve()}\\n\")\n",
    "\n",
    "# print it out nicely \n",
    "for i in range(n_samples):\n",
    "    sub = df[df[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref\", \"pred\", \"abs_error\", \"sq_error\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i}  \"\n",
    "        f\"X: cavity_frequency={X_test_cur[i,0]:.6g}, kappa={X_test_cur[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print() \n",
    "\n",
    "# (Optional) quick global stats (only over defined parameters)\n",
    "print(\"Global error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_masked)))\n",
    "\n",
    "''' \n",
    "Here onehot/linear encoding and the mlp which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304c67f-9838-491f-869c-e51d86748217",
   "metadata": {},
   "source": [
    "### Unscaled test vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e05f774-e63a-4325-86eb-c091a1c286d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_unscaled_one_hot.csv\n",
      "\n",
      " Sample 0 (Unscaled)  X: cavity_frequency=5.24699e+09, kappa=168252\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000275   2.782647e-04        3.264662e-06       1.065802e-11\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004   4.667290e-06        5.672899e-07       3.218178e-13\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500  -1.500495e-03        4.950110e-07       2.450359e-13\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000000  -5.540013e-07        5.540013e-07       3.069174e-13\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000000  -4.016776e-08        4.016776e-08       1.613449e-15\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000000  -5.205424e-08        5.205424e-08       2.709644e-15\n",
      "                           design_options.cpw_opts.total_length     1.0      0.004700   4.154381e-03        5.456187e-04       2.976997e-07\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100   8.656734e-05        1.343266e-05       1.804363e-10\n",
      "                      design_options.cpw_opts.meander.asymmetry     1.0      0.000117   4.069696e-05        7.596971e-05       5.771397e-09\n",
      "                       design_options.cplr_opts.coupling_length     1.0      0.000350   3.121892e-04        3.781078e-05       1.429655e-09\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000100   7.312473e-05        2.687527e-05       7.222803e-10\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000  -3.151229e-03                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      1.000000   9.966881e-01        3.311932e-03       1.096889e-05\n",
      "                                              coupler_type_NCap     1.0      0.000000   6.778222e-04        6.778222e-04       4.594429e-07\n",
      "                                            resonator_type_half     1.0      0.000000  -6.639361e-04        6.639361e-04       4.408112e-07\n",
      "                                         resonator_type_quarter     1.0      1.000000   9.976977e-01        2.302349e-03       5.300809e-06\n",
      "\n",
      " Sample 1 (Unscaled)  X: cavity_frequency=8.36575e+09, kappa=768.707\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000190       0.000139        5.125989e-05       2.627576e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004       0.000004        2.831150e-08       8.015412e-16\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500      -0.001504        4.495973e-06       2.021377e-11\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000240       0.000240        6.854801e-08       4.698830e-15\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000030       0.000030        4.404607e-08       1.940056e-15\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000030       0.000030        4.470273e-08       1.998334e-15\n",
      "                           design_options.cpw_opts.total_length     1.0      0.006700       0.006552        1.482090e-04       2.196591e-08\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100       0.000099        9.849998e-07       9.702247e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0      0.000000      -0.000003                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0      0.000000      -0.000005                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000050       0.000048        1.725003e-06       2.975637e-12\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000      -0.000984                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      0.000000      -0.003728        3.727555e-03       1.389467e-05\n",
      "                                              coupler_type_NCap     1.0      1.000000       1.003162        3.161669e-03       9.996149e-06\n",
      "                                            resonator_type_half     1.0      1.000000       0.999731        2.692938e-04       7.251914e-08\n",
      "                                         resonator_type_quarter     1.0      0.000000      -0.004260        4.260153e-03       1.814890e-05\n",
      "\n",
      " Sample 2 (Unscaled)  X: cavity_frequency=1.09991e+10, kappa=1010.75\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000080       0.000138        5.752883e-05       3.309566e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004       0.000004        3.297084e-08       1.087077e-15\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500      -0.001491        8.779565e-06       7.708076e-11\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000240       0.000241        1.208894e-06       1.461425e-12\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000030       0.000030        1.943201e-07       3.776029e-14\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000030       0.000030        1.882556e-07       3.544015e-14\n",
      "                           design_options.cpw_opts.total_length     1.0      0.005200       0.005517        3.169370e-04       1.004491e-07\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100       0.000099        7.056831e-07       4.979886e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0      0.000000      -0.000004                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0      0.000000      -0.000005                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000050       0.000048        1.603331e-06       2.570671e-12\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000      -0.001119                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      0.000000      -0.007631        7.630572e-03       5.822562e-05\n",
      "                                              coupler_type_NCap     1.0      1.000000       1.007576        7.575989e-03       5.739561e-05\n",
      "                                            resonator_type_half     1.0      1.000000       1.004521        4.520774e-03       2.043740e-05\n",
      "                                         resonator_type_quarter     1.0      0.000000      -0.007816        7.816464e-03       6.109710e-05\n",
      "\n",
      "Global unscaled error stats (defined parameters only):\n",
      "  min abs_error: 4.325620750478265e-09\n",
      "  median abs_error: 3.0371641418896632e-05\n",
      "  max abs_error: 0.1201522946357727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably \\nthrowing off the global average. These will be rounded in the future and will probably always \\nround to the right number to reconstruct the correct category-- but for now it might throw off \\nthe overall average error. In the future we might want to just have it consider the non-categorical \\ndata when finding an overall average and reporting that number.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unscale everything and look at errors again. \n",
    "#You can compare the unscaled actual values to the ml_00...py notebook to convice yourself that unscaling worked\n",
    "\n",
    "with open('X_names', 'r') as f:\n",
    "    X_index_names = f.read().splitlines()\n",
    "\n",
    "# unscaling x\n",
    "X_test_unscaled = np.asarray(X_test_cur.copy())\n",
    "for i in range(X_test_unscaled.shape[0]):\n",
    "    for j in range(X_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_X_{X_index_names[j]}.save')\n",
    "        X_test_unscaled[i, j] = scaler.inverse_transform([[X_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y (value head only)\n",
    "y_value_test_unscaled = np.asarray(y_value_test_cur.copy())\n",
    "for i in range(y_value_test_unscaled.shape[0]):\n",
    "    for j in range(y_value_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_test_unscaled[i, j] = scaler.inverse_transform([[y_value_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y predictions (value head only)\n",
    "y_value_pred_unscaled = np.asarray(y_value_pred.copy())\n",
    "for i in range(y_value_pred_unscaled.shape[0]):\n",
    "    for j in range(y_value_pred_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_pred_unscaled[i, j] = scaler.inverse_transform([[y_value_pred_unscaled[i, j]]])[0][0]\n",
    "\n",
    "n_samples, n_params = y_value_test_unscaled.shape\n",
    "n_samples = 3 \n",
    "\n",
    "# find how good or bad we did (the errors)\n",
    "sq_errors_unscaled = (y_value_test_unscaled - y_value_pred_unscaled) ** 2\n",
    "abs_errors_unscaled = np.abs(y_value_test_unscaled - y_value_pred_unscaled)\n",
    "\n",
    "# mask out parameters that are not defined according to ground-truth exists flag\n",
    "sq_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, sq_errors_unscaled, np.nan)\n",
    "abs_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, abs_errors_unscaled, np.nan)\n",
    "\n",
    "# making a nice fancy dataframe, we like fancy things\n",
    "rows_unscaled = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_unscaled[i, 0], X_test_unscaled[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows_unscaled.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref_unscaled\": y_value_test_unscaled[i, j],\n",
    "            \"pred_unscaled\": y_value_pred_unscaled[i, j],\n",
    "            \"abs_error_unscaled\": abs_errors_unscaled_masked[i, j],\n",
    "            \"sq_error_unscaled\": sq_errors_unscaled_masked[i, j],\n",
    "        })\n",
    "\n",
    "df_unscaled = pd.DataFrame(rows_unscaled)\n",
    "\n",
    "# save csv of unscaled results uncase we lose this notebook due to github blowing up, ya never know\n",
    "out_csv_unscaled = Path(f\"predictions_and_errors_unscaled_{y_encoding_format_name}.csv\")\n",
    "df_unscaled.to_csv(out_csv_unscaled, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv_unscaled.resolve()}\\n\")\n",
    "\n",
    "# print out stuff so you can see it here if you are to lazy like me to open a csv\n",
    "for i in range(n_samples):\n",
    "    sub = df_unscaled[df_unscaled[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref_unscaled\", \"pred_unscaled\", \"abs_error_unscaled\", \"sq_error_unscaled\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i} (Unscaled)  \"\n",
    "        f\"X: cavity_frequency={X_test_unscaled[i,0]:.6g}, kappa={X_test_unscaled[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# look at overall stats, see below comment for a caviat \n",
    "print(\"Global unscaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_unscaled_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_unscaled_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_unscaled_masked)))\n",
    "\n",
    "'''\n",
    "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non-categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da89f-f7e8-4672-b054-bcf439f5b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a76783-7ab4-4458-b944-4ddb2526ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f91622-6756-4bdb-b440-2a0b844fa80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b20419-4bce-427c-afe3-58004c5c0439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6f856-dfb6-4216-a01d-11ec59931913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b4acc-f517-4f14-95be-46d0c00c78f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72d605-bb06-44e7-ba56-d920a7716ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81094893-d64f-4900-952a-c3c5ea8b7f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d4152-ebf4-4922-ab41-8fbfb1bc15be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
