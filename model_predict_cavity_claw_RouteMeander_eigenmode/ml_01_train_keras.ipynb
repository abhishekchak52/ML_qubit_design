{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b8e1e",
   "metadata": {},
   "source": [
    "# Model Training (cavity_claw_RouteMeander_eigenmode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7659a-fe1b-4fdf-8c09-a398e498373b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9418886-6a3f-4473-ae89-53bab6428eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter file is where the hyperparameters are set. \n",
    "# It's reccomended to look at that file first, its interesting and you can set stuff there\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17135-58ce-45e4-9c16-1d1b76f34ea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa89948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, joblib\n",
    "\n",
    "# Disable some console warnings so you can be free of them printing. \n",
    "# Comment the next two lines if you are a professional and like looking at warnings.\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "os.environ.pop(\"TF_XLA_FLAGS\", None)      # disable XLA \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # show warnings/errors while debugging\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf, gc\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float32\") # make the backend use float32 which will be the same as the data--helps speed it up\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b35ed7bf-9c4f-41d4-8652-1fe11dd8c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# Input seed value. If this value is the same, the random number generator \n",
    "# will generate the same set of random values every time. We like reproducibility:)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the seed value for reproducibility in tensorflow\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9e65e-f247-4388-a274-6041e8cdcc27",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17dc079f-6430-41bc-8342-0cc5ffbe4a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6476790750289084998\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1130758144\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17252277058733958061\n",
      "physical_device_desc: \"device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768503562.697781   54746 gpu_device.cc:2020] Created device /device:GPU:0 with 1078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Look at what you are working with. If you dont have a nice GPU I highly reccomend finding one\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad03d-ae5d-4bc6-b055-3e8579849c5d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0b8c-6699-4caf-b257-abc4f8e49b99",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "667c238f-0e0f-4e4c-b185-f76d1ca261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the nice data you saved from the previous notebook, or downloaded from the drive\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        encoding = ENCODING_TYPE.replace(' ','_')\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec9efd-ee93-429d-95b4-4e6efef296db",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcb45684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (851, 2)\n",
      "X_val.shape: (182, 2)\n",
      "y_value_train.shape: (851, 16)\n",
      "y_value_val.shape: (182, 16)\n",
      "y_exists_train.shape: (851, 16)\n",
      "y_exists_val.shape: (182, 16)\n",
      "y_value_train[0]: [0.1773399  0.         0.         1.         1.         1.\n",
      " 0.35714286 1.         0.65217391 0.         0.5        0.\n",
      " 0.         1.         1.         0.        ]\n",
      "y_exists_train[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "y_exists_val[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Look at the shapes of training and test sets in case you want to orient yourself\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    print('X_train.shape:', X_train.shape)\n",
    "    print('X_val.shape:', X_val.shape)\n",
    "    print('y_value_train.shape:', y_value_train.shape)\n",
    "    print('y_value_val.shape:', y_value_val.shape)\n",
    "    print('y_exists_train.shape:', y_exists_train.shape)\n",
    "    print('y_exists_val.shape:', y_exists_val.shape)\n",
    "    print('y_value_train[0]:', y_value_train[0])\n",
    "    print('y_exists_train[0]:', y_exists_train[0])\n",
    "    print('y_exists_val[0]:', y_exists_val[0])\n",
    "\n",
    "else:\n",
    "    print('X_train_linear_encoding.shape:', X_train_linear_encoding.shape)\n",
    "    print('X_val_linear_encoding.shape:', X_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding.shape:', y_value_train_linear_encoding.shape)\n",
    "    print('y_value_val_linear_encoding.shape:', y_value_val_linear_encoding.shape)\n",
    "    print('y_exists_train_linear_encoding.shape:', y_exists_train_linear_encoding.shape)\n",
    "    print('y_exists_val_linear_encoding.shape:', y_exists_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding[0]:', y_value_train_linear_encoding[0])\n",
    "    print('y_exists_train_linear_encoding[0]:', y_exists_train_linear_encoding[0])\n",
    "\n",
    "    print('X_train_one_hot_encoding.shape:', X_train_one_hot_encoding.shape)\n",
    "    print('X_val_one_hot_encoding.shape:', X_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding.shape:', y_value_train_one_hot_encoding.shape)\n",
    "    print('y_value_val_one_hot_encoding.shape:', y_value_val_one_hot_encoding.shape)\n",
    "    print('y_exists_train_one_hot_encoding.shape:', y_exists_train_one_hot_encoding.shape)\n",
    "    print('y_exists_val_one_hot_encoding.shape:', y_exists_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding[0]:', y_value_train_one_hot_encoding[0])\n",
    "    print('y_exists_train_one_hot_encoding[0]:', y_exists_train_one_hot_encoding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8e90f9a-14a8-41e2-ad9a-cfe4e3000d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33514963, 0.00078676],\n",
       "       [0.01809174, 0.15265725],\n",
       "       [0.01032841, 0.14763822],\n",
       "       ...,\n",
       "       [0.05754841, 0.25609945],\n",
       "       [0.57781303, 0.0013409 ],\n",
       "       [0.06168676, 0.26742149]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    display(X_train) #can check this in previous script as well after loading to make sure it matches\n",
    "else:\n",
    "    display(X_train_one_hot_encoding)\n",
    "    display(X_train_linear_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95debf17-6de3-49fc-9064-b01c985c3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Train set shape x:                851, 69.98%\n",
      "Validation set shape x:           182, 14.97%\n",
      "Test set shape x:                 183, 15.05%\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Train set shape y_value:          851, 69.98%\n",
      "Validation set shape y_value:     182, 14.97%\n",
      "Test set shape y_value:           183, 15.05%\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Look at how it was split and decide if you like the split\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    total = len(X_train) + len(X_test) + len(X_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x:                {}, {:.2f}%'.format(len(X_train), (len(X_train) * 100.) / total))\n",
    "    print('Validation set shape x:           {}, {:.2f}%'.format(len(X_val), (len(X_val) * 100.) / total))\n",
    "    print('Test set shape x:                 {}, {:.2f}%'.format(len(X_test), (len(X_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train) + len(y_value_test) + len(y_value_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value:          {}, {:.2f}%'.format(len(y_value_train), (len(y_value_train) * 100.) / total))\n",
    "    print('Validation set shape y_value:     {}, {:.2f}%'.format(len(y_value_val), (len(y_value_val) * 100.) / total))\n",
    "    print('Test set shape y_value:           {}, {:.2f}%'.format(len(y_value_test), (len(y_value_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "else:\n",
    "    total = len(X_train_one_hot_encoding) + len(X_test_one_hot_encoding) + len(X_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x one_hot_encoding:      {}, {:.2f}%'.format(len(X_train_one_hot_encoding), (len(X_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape x one_hot_encoding: {}, {:.2f}%'.format(len(X_val_one_hot_encoding), (len(X_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape x one_hot_encoding:       {}, {:.2f}%'.format(len(X_test_one_hot_encoding), (len(X_test_one_hot_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_one_hot_encoding) + len(y_value_test_one_hot_encoding) + len(y_value_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value one_hot_encoding:      {}, {:.2f}%'.format(len(y_value_train_one_hot_encoding), (len(y_value_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value one_hot_encoding: {}, {:.2f}%'.format(len(y_value_val_one_hot_encoding), (len(y_value_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value one_hot_encoding:       {}, {:.2f}%'.format(len(y_value_test_one_hot_encoding), (len(y_value_test_one_hot_encoding) * 100.) / total))\n",
    "\n",
    "    total = len(X_train_linear_encoding) + len(X_test_linear_encoding) + len(X_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x linear_encoding:      {}, {:.2f}%'.format(len(X_train_linear_encoding), (len(X_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape x linear_encoding: {}, {:.2f}%'.format(len(X_val_linear_encoding), (len(X_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape x linear_encoding:       {}, {:.2f}%'.format(len(X_test_linear_encoding), (len(X_test_linear_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_linear_encoding) + len(y_value_test_linear_encoding) + len(y_value_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value linear_encoding:      {}, {:.2f}%'.format(len(y_value_train_linear_encoding), (len(y_value_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value linear_encoding: {}, {:.2f}%'.format(len(y_value_val_linear_encoding), (len(y_value_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value linear_encoding:       {}, {:.2f}%'.format(len(y_value_test_linear_encoding), (len(y_value_test_linear_encoding) * 100.) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f6e25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78b32e05-b5df-4647-8dae-6ee5f8cddcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAEiCAYAAAClaFmwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARxBJREFUeJzt3XdYFFfbBvB7pSwgRQVpooAI2CtGxViwkNhieU00agRLXktMNGqMxhghGmskJrHGV0GjqNGoMcZGVIixYo89wYIFVLCigJTz/eHHhGWXNizsLnv/rmuvy505M/PMzvL47Mw5MwohhAARERERkQwVdB0AERERERkuFpNEREREJBuLSSIiIiKSjcUkEREREcnGYpKIiIiIZGMxSURERESysZgkIiIiItlYTBIRERGRbCwmiYiIiEg2oygme/fuDUtLSzx+/DjfNgMHDoSZmRnu3btX5PUqFAqEhIRI76Ojo6FQKBAdHV3ossHBwfDw8CjytnJbsmQJIiIi1KbfuHEDCoVC47yysGfPHgQGBsLV1RVKpRKurq5o37495syZI2t9kZGRWLhwoXaD1LKQkBAoFAqVafkdH216+PAh+vfvD0dHRygUCvTq1atUt0ekr5jfy4au87uHhwe6d+8ua1tU+oyimBw2bBjS0tIQGRmpcf6TJ0+wdetWdO/eHU5OTrK307RpUxw5cgRNmzaVvY6iyC/ZuLi44MiRI+jWrVupbl+TZcuW4c0334StrS0WLVqEPXv2YO7cuahTpw42b94sa52GUEwOHz4cR44cUZlWFsXkjBkzsHXrVnzzzTc4cuQI5s2bV6rbI9JXzO+lz1jzOxWdqa4DKAtdunSBq6srVq1ahdGjR6vNX79+PVJTUzFs2LASbcfW1hYtW7Ys0TpKQqlU6mz7s2fPRtu2bdUSy3vvvYfs7GydxFQW3Nzc4ObmVubbPX/+PLy8vDBw4MAC22VlZSEzMxNKpbKMIiMqW8zvpc9Y8zsVnVGcmTQxMUFQUBBOnjyJv/76S21+eHg4XFxc0KVLFzx48ACjR49G3bp1YW1tDUdHR3To0AEHDx4sdDv5XQaJiIiAr68vlEol6tSpgzVr1mhcPjQ0FC1atECVKlVga2uLpk2bYuXKlRBCSG08PDxw4cIFxMTEQKFQQKFQSJdT8rsM8ueff6Jjx46wsbGBlZUV/P398dtvv6nFqFAocODAAYwaNQoODg6wt7dHnz59cPfu3UL3PTk5GS4uLhrnVaig+jUTQmDJkiVo3LgxLC0tUblyZfTt2xfXrl2T2rRv3x6//fYbbt68Ke1n3svJmkRGRqJVq1awtraGtbU1GjdujJUrV0rzo6Ki0LNnT7i5ucHCwgK1atXCiBEjkJSUJLXZtm0bFAoF9u3bp7b+pUuXQqFQ4Ny5cwDUL3Pnd3xSUlJQqVIljBgxQm2dN27cgImJCebPn1/o/uUc499//x2XLl2SthEdHS3NmzdvHmbOnAlPT08olUocOHAAAHDixAm89dZbqFKlCiwsLNCkSRP89NNPats4evQoWrduDQsLC7i6umLKlClYsWIFFAoFbty4IbXLexkw92cQHBysMi0xMREjRoyAm5sbzM3N4enpidDQUGRmZqrt29dff42wsDB4enrC2toarVq1wtGjR9W2c+zYMfTo0QP29vawsLCAl5cXxo0bBwA4ePAgFAoF1q9fr7bcmjVroFAoEBsbW+jnTfqP+d148nteS5YsgampKaZPnw4ART6+uXPlV199hRo1asDCwgJ+fn5qeT8nx58+fRp9+vSBra0t7OzsMGjQIDx48ECl7caNGxEYGAgXFxdYWlqiTp06mDx5Mp4/f17sfTM4wkj8/fffQqFQiHHjxqlMv3DhggAgJk+eLIQQ4vLly2LUqFFiw4YNIjo6WuzYsUMMGzZMVKhQQRw4cEBlWQBi+vTp0vsDBw4IACrtwsPDBQDRs2dP8euvv4q1a9eKWrVqierVqwt3d3eV9QUHB4uVK1eKqKgoERUVJWbMmCEsLS1FaGio1ObUqVOiZs2aokmTJuLIkSPiyJEj4tSpU0IIIa5fvy4AiPDwcKl9dHS0MDMzE82aNRMbN24U27ZtE4GBgUKhUIgNGzaoxVmzZk3x4Ycfij179oj//e9/onLlyiIgIKDQz7dTp07C1NRUTJ8+XZw5c0ZkZmbm2/b9998XZmZmYsKECWL37t0iMjJS1K5dWzg5OYnExETpuLRu3Vo4OztL+3nkyJECY5g2bZoAIPr06SM2bdok9u7dK8LCwsS0adOkNkuXLhWzZ88W27dvFzExMWL16tWiUaNGwtfXV7x8+VIIIURGRoZwdHQUAwcOVNvGa6+9Jpo2bSq9nz59usj9Z1TQ8fn4449FxYoVxePHj1XW+cknnwgLCwuRlJRU4P4JIURaWpo4cuSIaNKkiahZs6a0jSdPnkjHv1q1aiIgIEBs3rxZ7N27V1y/fl3s379fmJubizZt2oiNGzeK3bt3i+DgYLXvy4ULF4SVlZWoW7euWL9+vfjll1/EG2+8IWrUqCEAiOvXr0tt837/c7i7u4ugoCDpfUJCgvR9X758ufj999/FjBkzhFKpFMHBwVK7nPg9PDzEm2++KbZt2ya2bdsmGjRoICpXrqzyue3evVuYmZmJhg0bioiICLF//36xatUq0b9/f6lNkyZNROvWrdXia968uWjevHmhnzUZDub38p/f3d3dRbdu3YQQQmRnZ4sJEyYIMzMzlc+jqMc357OsXr26eP3118XPP/8sNm3aJJo3by7MzMzE4cOHpbY5Od7d3V188sknYs+ePSIsLExUrFhRNGnSRPp/QwghZsyYIb755hvx22+/iejoaLFs2TLh6elZpM/Y0BlNMSmEEO3atRMODg4qB3/ChAkCgLh69arGZTIzM0VGRobo2LGj6N27t8q8wpJNVlaWcHV1FU2bNhXZ2dlSuxs3bggzMzO1ZJNbVlaWyMjIEF9++aWwt7dXWb5evXqiXbt2astoSjYtW7YUjo6O4tmzZyr7VL9+feHm5iatNyfZjB49WmWd8+bNEwBEQkJCvrEKIcQ///wj6tevLwAIAMLS0lJ07NhRLFq0SOXzPnLkiAAgFixYoLL8rVu3hKWlpZg0aZI0rVu3bgV+Rrldu3ZNmJiYaCwA85OdnS0yMjLEzZs3BQDxyy+/SPPGjx8vLC0tVQqYixcvCgDi+++/l6blLSaFyP/4xMXFiQoVKohvvvlGmpaamirs7e3FkCFDihy3EK++y/Xq1VOZlnP8vby8VD5zIYSoXbu2aNKkicjIyFCZ3r17d+Hi4iKysrKEEEL069dPWFpaSklfiFffl9q1a8suJkeMGCGsra3FzZs3Vdp9/fXXAoC4cOGCSvwNGjRQ+c/q+PHjAoBYv369NM3Ly0t4eXmJ1NTUfD+jnO/06dOn1da1evXqfJcjw8T8/u8+lbf8LsS/xeSLFy/Ef/7zH2FnZyd+//33ApfJ7/jmfJaurq4qOeTp06eiSpUqolOnTtK0nBz/8ccfq6x73bp1AoBYu3atxm3n/P8SExMjAIizZ88WeV8NkVFc5s4xbNgwJCUlYfv27QCAzMxMrF27Fm3atIG3t7fUbtmyZWjatCksLCxgamoKMzMz7Nu3D5cuXSrW9q5cuYK7d+9iwIABKqfw3d3d4e/vr9Z+//796NSpE+zs7GBiYgIzMzN88cUXSE5Oxv3794u9v8+fP8exY8fQt29fWFtbS9NNTEzw3nvv4fbt27hy5YrKMm+99ZbK+4YNGwIAbt68WeC2vLy8cPbsWcTExCA0NBSdOnVCbGwsxowZg1atWiEtLQ0AsGPHDigUCgwaNAiZmZnSy9nZGY0aNSrSSElNoqKikJWVhQ8++KDAdvfv38fIkSNRvXp16di6u7sDgMrxHTp0KFJTU7Fx40ZpWnh4OJRKJQYMGCArxpo1a6J79+5YsmSJdGkrMjISycnJGDNmjKx1avLWW2/BzMxMev/PP//g8uXLUv/K3J97165dkZCQIH0PDhw4gI4dO6oMVDAxMUG/fv1kx7Njxw4EBATA1dVVZdtdunQBAMTExKi079atG0xMTKT3eb+DV69eRVxcHIYNGwYLC4t8t/vuu+/C0dERixcvlqZ9//33qFq1aon2h/QT8/sr5TG/50hOTkaHDh1w/Phx6fJ+XsU5vn369FHJITY2NujRowf++OMPZGVlqbTN2z/9nXfegampqdSNCACuXbuGAQMGwNnZWTrG7dq1A4Bif78MjVEVk3379oWdnR3Cw8MBADt37sS9e/dUOmaHhYVh1KhRaNGiBX7++WccPXoUsbGxePPNN5Gamlqs7SUnJwMAnJ2d1eblnXb8+HEEBgYCAFasWIFDhw4hNjYWU6dOBYBibxsAHj16BCGExr4urq6uKjHmsLe3V3mfM3CjKNuvUKEC2rZtiy+++ALbt2/H3bt30a9fP5w8eRKrVq0CANy7dw9CCDg5OcHMzEzldfToUZW+i8WR03eloMEw2dnZCAwMxJYtWzBp0iTs27cPx48fl/rj5d7HevXqoXnz5tJ3JSsrC2vXrkXPnj1RpUoVWTECwNixY/H3338jKioKALB48WK0atVKqyNE8x7vnNuhTJw4Ue0zzxmwkPO5JycnF+n7Whz37t3Dr7/+qrbtevXqqWw7R2HfwaIc65zlRowYgcjISDx+/BgPHjzATz/9hOHDh3NAUjnE/P6v8pbfc1y9ehXHjh1Dly5dUL9+fbX5xT2++R27ly9fIiUlpcC2pqamsLe3lz7jlJQUtGnTBseOHcPMmTMRHR2N2NhYbNmyBYC8Y2xIjGI0dw5LS0u8++67WLFiBRISErBq1SrY2Njg7bffltqsXbsW7du3x9KlS1WWffbsWbG3l/OHm5iYqDYv77QNGzbAzMwMO3bsUPmltG3btmJvN0flypVRoUIFJCQkqM3L6XTt4OAge/2FqVixIqZMmYKNGzfi/Pnz0vYUCgUOHjyo8T90uf/JV61aFQBw+/ZtVK9eXWOb8+fP4+zZs4iIiEBQUJA0/Z9//tHYfsiQIRg9ejQuXbqEa9euISEhAUOGDJEVX44OHTqgfv36WLRoEaytrXHq1CmsXbu2ROvMK29H9pxjPGXKFPTp00fjMr6+vgBefWeL8n0FXh2r9PR0tel5/wNzcHBAw4YN8dVXX2ncds5/fEWV+1gXZtSoUZgzZw5WrVqFtLQ0ZGZmYuTIkcXaHhkG5vd/lbf8nqNVq1Z4++23pR8IS5cuVRkAVNzjm9+xMzc3VznbmzO9WrVq0vvMzEwkJydL34P9+/fj7t27iI6Ols5GAijw/qfliVGdmQReXQrJysrC/PnzsXPnTvTv3x9WVlbSfIVCofaFP3funNq9BIvC19cXLi4uWL9+vcqIvZs3b+Lw4cMqbRUKBUxNTVUu76WmpuLHH39UW69SqSzSr5yKFSuiRYsW2LJli0r77OxsrF27Fm5ubvDx8Sn2fmmiKaEB/57azykYunfvDiEE7ty5Az8/P7VXgwYNpGWLup8AEBgYCBMTE7UkkltOkZX3+C5fvlxj+3fffRcWFhaIiIhAREQEqlWrJp1dKEhhcX/00Uf47bffMGXKFDg5Oan8Z1cafH194e3tjbNnz2r8zP38/GBjYwMACAgIwL59+1Ru7pyVlaVyuT+Hh4eHNKo9x/79+9V+0Xfv3l26lZGmbRe3mPTx8YGXlxdWrVqlsZjNzcXFBW+//TaWLFmCZcuWoUePHqhRo0axtkeGg/m9fOb33IKCgrBhwwaEh4dj8ODBKpeji3t8t2zZIl2iB14Vnb/++ivatGmjcqwAYN26dSrvf/rpJ2RmZqJ9+/bStnP2K7f8/n8pb4zqzCQA+Pn5oWHDhli4cCGEEGr3HuvevTtmzJiB6dOno127drhy5Qq+/PJLeHp6qtzGpCgqVKiAGTNmYPjw4ejduzfef/99PH78GCEhIWqnzLt164awsDAMGDAA//3vf5GcnIyvv/5a4y+5Bg0aYMOGDdi4cSNq1qwJCwsLlT/S3GbPno3OnTsjICAAEydOhLm5OZYsWYLz589j/fr1sm7HoEm9evXQsWNHdOnSBV5eXkhLS8OxY8ewYMECODk5SZ9z69at8d///hdDhgzBiRMn0LZtW1SsWBEJCQn4888/0aBBA4waNUrazy1btmDp0qVo1qwZKlSoAD8/P43b9/DwwGeffYYZM2YgNTUV7777Luzs7HDx4kUkJSUhNDQUtWvXhpeXFyZPngwhBKpUqYJff/1VuuScV6VKldC7d29ERETg8ePHmDhxotptMDQp7PgMGjQIU6ZMwR9//IHPP/8c5ubmxf24i2358uXo0qUL3njjDQQHB6NatWp4+PAhLl26hFOnTmHTpk0AgM8//xzbt29Hhw4d8MUXX8DKygqLFy/WeGuL9957D9OmTcMXX3yBdu3a4eLFi1i0aBHs7OxU2n355ZeIioqCv78/PvroI/j6+iItLQ03btzAzp07sWzZsmLfq3Px4sXo0aMHWrZsiY8//hg1atRAfHw89uzZo5b0x44dixYtWgCAdAmUyifm9/KZ3/Pq27cvrKys0LdvX6SmpmL9+vUwNzcv9vE1MTFB586dMX78eGRnZ2Pu3Ll4+vQpQkND1dpu2bIFpqam6Ny5My5cuIBp06ahUaNGeOeddwAA/v7+qFy5MkaOHInp06fDzMwM69atw9mzZ+V+7IZFN+N+dOvbb78VAETdunXV5qWnp4uJEyeKatWqCQsLC9G0aVOxbds2ERQUpDbyDEW4dYQQQvzvf/8T3t7ewtzcXPj4+IhVq1ZpXN+qVauEr6+vUCqVombNmmL27Nli5cqVaqNob9y4IQIDA4WNjY10ywIhNI/2E0KIgwcPig4dOoiKFSsKS0tL0bJlS/Hrr7+qtMkZ7RcbG6syPb99ymv58uWiT58+ombNmsLKykqYm5sLLy8vMXLkSHHr1i219qtWrRItWrSQYvLy8hKDBw8WJ06ckNo8fPhQ9O3bV1SqVEkoFAq1UdOarFmzRjRv3lxYWFgIa2tr0aRJE5XP4+LFi6Jz587CxsZGVK5cWbz99tsiPj4+35HJe/fulUYwahoRqmk0d37HJ7fg4GBhamoqbt++Xeg+aVLQaO758+drXObs2bPinXfeEY6OjsLMzEw4OzuLDh06iGXLlqm0O3TokGjZsqVQKpXC2dlZfPLJJ+KHH35Q+x6mp6eLSZMmierVqwtLS0vRrl07cebMGbXR3EII8eDBA/HRRx8JT09PYWZmJqpUqSKaNWsmpk6dKlJSUgqNX9PxOXLkiOjSpYuws7MTSqVSeHl5qY24zOHh4SHq1KmjcR6VL8zv5TO/5741UO74ra2txZtvvilevHhR5OOb81nOnTtXhIaGCjc3N2Fubi6aNGki9uzZo7KNnBx/8uRJ0aNHD2FtbS1sbGzEu+++K+7du6fS9vDhw6JVq1bCyspKVK1aVQwfPlycOnVK43ErbxRC5Do/T0Sl7uXLl/Dw8MDrr7+u8abh+igiIgJDhgzB9evXZT9zWFfOnTuHRo0aYfHixRqfkEJExuXGjRvw9PTE/PnzMXHixALbhoSEIDQ0FA8ePCjVPqiGzugucxPpyoMHD3DlyhWEh4fj3r17mDx5sq5DKtfi4uJw8+ZNfPbZZ3BxcVF7Kg8REWmH0Q3AIdKV3377DW3atMGuXbuwZMkSjbcDyn1vNk0vPge36GbMmIHOnTsjJSUFmzZtUhmIQURE2sPL3ER6pLAO80FBQWrP5iUiItIlXuYm0iOxsbEFzmefHSIi0jc8M0lEREREsrHPJBERERHJVu4vc2dnZ+Pu3buwsbHR2g1cicjwCSHw7NkzuLq6Fulm9OUZ8yQRaVLUPFnui8m7d+/m+6xmIqJbt24V+wk85Q3zJBEVpLA8We6LyZxnDt+6dQu2trY6joaI9MXTp09RvXp1KUcYM+ZJItKkqHmy3BeTOZdsbG1tmSSJSA0v6zJPElHBCsuTxt1RiIiIiIhKhMUkEREREcnGYpKIiIiIZGMxSURERESysZgkIiIiItlYTBIRERGRbOX+1kClIT4+HklJSfnOd3BwQI0aNcowIiKissU8SEQ5WEwWU3x8PHxr10Fa6ot821hYWuHK5UtMpERULjEPElFuLCaLKSkpCWmpL2DffQLM7NUfP5aRfAvJOxYgKSmJSZSIyiXmQSLKjcWkTGb21aF0rqXrMIiIdIZ5kIgADsAhIiIiohJgMUlEREREsrGYJCIiIiLZWEwSERERkWwsJomIiIhINhaTRERERCQbi0kiIiIiko33mdSgoMeEXbp0qYyjISIiItJfLCbzKMpjwoiIiIjoFRaTeRT2mLDUayfw5OBaHURGREREpH9YTOYjv8eEZSTf0kE0RERERPqJA3CIiIiISDYWk0REREQkGy9zl5KCRn07ODigRo0aZRgNERERUelgMallWSmPAIUCgwYNyreNhaUVrly+xIKSiIiIDB6LSS3LTk8BhMh3NHhG8i0k71iApKQkFpNERERk8FhMlpL8RoMTERERlSccgENEREREsrGYJCIiIiLZWEwSERERkWwsJomIiIhINp0Wk0uXLkXDhg1ha2sLW1tbtGrVCrt27ZLmCyEQEhICV1dXWFpaon379rhw4YIOIyYiIiKi3HRaTLq5uWHOnDk4ceIETpw4gQ4dOqBnz55SwThv3jyEhYVh0aJFiI2NhbOzMzp37oxnz57pMmwiIiIi+n86LSZ79OiBrl27wsfHBz4+Pvjqq69gbW2No0ePQgiBhQsXYurUqejTpw/q16+P1atX48WLF4iMjNRl2ERERET0//Smz2RWVhY2bNiA58+fo1WrVrh+/ToSExMRGBgotVEqlWjXrh0OHz6c73rS09Px9OlTlRcRERERlQ6dF5N//fUXrK2toVQqMXLkSGzduhV169ZFYmIiAMDJyUmlvZOTkzRPk9mzZ8POzk56Va+u/hQaIiIiItIOnReTvr6+OHPmDI4ePYpRo0YhKCgIFy9elOYrFAqV9kIItWm5TZkyBU+ePJFet27dKrXYiYiIiIydzh+naG5ujlq1Xj120M/PD7Gxsfj222/x6aefAgASExPh4uIitb9//77a2crclEollEpl6QZNRERERAD04MxkXkIIpKenw9PTE87OzoiKipLmvXz5EjExMfD399dhhEREZevOnTsYNGgQ7O3tYWVlhcaNG+PkyZPSfN5GjYh0SadnJj/77DN06dIF1atXx7Nnz7BhwwZER0dj9+7dUCgUGDduHGbNmgVvb294e3tj1qxZsLKywoABA3QZNhFRmXn06BFat26NgIAA7Nq1C46OjoiLi0OlSpWkNjm3UYuIiICPjw9mzpyJzp0748qVK7CxsdFd8ERkFHRaTN67dw/vvfceEhISYGdnh4YNG2L37t3o3LkzAGDSpElITU3F6NGj8ejRI7Ro0QJ79+5lciQiozF37lxUr14d4eHh0jQPDw/p33lvowYAq1evhpOTEyIjIzFixIiyDpmIjIxOL3OvXLkSN27cQHp6Ou7fv4/ff/9dKiSBV4NvQkJCkJCQgLS0NMTExKB+/fo6jJiIqGxt374dfn5+ePvtt+Ho6IgmTZpgxYoV0nw5t1HjLdSISJv0rs8kERH969q1a1i6dCm8vb2xZ88ejBw5Eh999BHWrFkDALJuo8ZbqBGRNrGYJCLSY9nZ2WjatClmzZqFJk2aYMSIEXj//fexdOlSlXbFuY0ab6FGRNrEYpKISI+5uLigbt26KtPq1KmD+Ph4AICzszMAqJ2FLOg2akqlEra2tiovIiK5WEwSEemx1q1b48qVKyrTrl69Cnd3dwDgbdSISOd0ftNyIiLK38cffwx/f3/MmjUL77zzDo4fP44ffvgBP/zwAwDwNmpEpHMsJomI9Fjz5s2xdetWTJkyBV9++SU8PT2xcOFCDBw4UGrD26gRkS6xmCQi0nPdu3dH9+7d852fcxu1kJCQsguKiOj/sc8kEREREcnGYpKIiIiIZGMxSURERESysZgkIiIiItlYTBIRERGRbCwmiYiIiEg2FpNEREREJBuLSSIiIiKSjcUkEREREcnGYpKIiIiIZGMxSURERESysZgkIiIiItlYTBIRERGRbCwmiYiIiEg2FpNEREREJBuLSSIiIiKSjcUkEREREcnGYpKIiIiIZJNVTF6/fl3bcRARlSvMk0RkLGQVk7Vq1UJAQADWrl2LtLQ0bcdERGTwmCeJyFjIKibPnj2LJk2aYMKECXB2dsaIESNw/PhxbcdGRGSwmCeJyFjIKibr16+PsLAw3LlzB+Hh4UhMTMTrr7+OevXqISwsDA8ePNB2nEREBoV5koiMRYkG4JiamqJ379746aefMHfuXMTFxWHixIlwc3PD4MGDkZCQoK04iYgMEvMkEZV3JSomT5w4gdGjR8PFxQVhYWGYOHEi4uLisH//fty5cwc9e/bUVpxERAaJeZKIyjtTOQuFhYUhPDwcV65cQdeuXbFmzRp07doVFSq8qk09PT2xfPly1K5dW6vBEhEZCuZJIjIWsorJpUuXYujQoRgyZAicnZ01tqlRowZWrlxZouCIiAwV8yQRGQtZxeTff/9daBtzc3MEBQXJWT0RkcFjniQiYyGrz2R4eDg2bdqkNn3Tpk1YvXp1iYMiIjJ0zJNEZCxkFZNz5syBg4OD2nRHR0fMmjWrxEERERk65kkiMhayismbN2/C09NTbbq7uzvi4+NLHBQRkaFjniQiYyGrz6SjoyPOnTsHDw8Plelnz56Fvb29NuIq9y5dupTvPAcHB9SoUaMMoyEibWOeJCJjIauY7N+/Pz766CPY2Nigbdu2AICYmBiMHTsW/fv312qA5U1WyiNAocCgQYPybWNhaYUrly+xoCQyYMyTRGQsZBWTM2fOxM2bN9GxY0eYmr5aRXZ2NgYPHsy+QIXITk8BhIB99wkws6+uNj8j+RaSdyxAUlISi0kiA8Y8SUTGQlYxaW5ujo0bN2LGjBk4e/YsLC0t0aBBA7i7u2s7vnLLzL46lM61dB0GEZUS5kkiMhayiskcPj4+8PHx0VYsRETlDvMkEZV3sorJrKwsREREYN++fbh//z6ys7NV5u/fv18rwRERGSrmSSIyFrKKybFjxyIiIgLdunVD/fr1oVAotB0XEZFBY54kImMhq5jcsGEDfvrpJ3Tt2lXb8RARlQvMk0RkLGTdtNzc3By1apV88Mjs2bPRvHlz2NjYwNHREb169cKVK1dU2gghEBISAldXV1haWqJ9+/a4cOFCibdNRFSatJUniYj0naxicsKECfj2228hhCjRxmNiYvDBBx/g6NGjiIqKQmZmJgIDA/H8+XOpzbx58xAWFoZFixYhNjYWzs7O6Ny5M549e1aibRMRlSZt5UkiIn0n6zL3n3/+iQMHDmDXrl2oV68ezMzMVOZv2bKlSOvZvXu3yvvw8HA4Ojri5MmTaNu2LYQQWLhwIaZOnYo+ffoAAFavXg0nJydERkZixIgRcsInIip12sqTRET6TlYxWalSJfTu3VvbseDJkycAgCpVqgAArl+/jsTERAQGBkptlEol2rVrh8OHD2ssJtPT05Geni69f/r0qdbjJCIqTGnlSSIifSOrmAwPD9d2HBBCYPz48Xj99ddRv359AEBiYiIAwMnJSaWtk5MTbt68qXE9s2fPRmhoqNbjIyIqjtLIk7Nnz8Znn32GsWPHYuHChQBe5c7Q0FD88MMPePToEVq0aIHFixejXr16Wt8+EZEmsvpMAkBmZiZ+//13LF++XOq/ePfuXaSkpMha35gxY3Du3DmsX79ebV7eW2oIIfK9zcaUKVPw5MkT6XXr1i1Z8RARlZQ282RsbCx++OEHNGzYUGU6+5UTka7JKiZv3ryJBg0aoGfPnvjggw/w4MEDAK+S2sSJE4u9vg8//BDbt2/HgQMH4ObmJk13dnYG8O8Zyhz3799XO1uZQ6lUwtbWVuVFRFTWtJknU1JSMHDgQKxYsQKVK1eWpuftV16/fn2sXr0aL168QGRkpFb3h4goP7KKybFjx8LPzw+PHj2CpaWlNL13797Yt29fkdcjhMCYMWOwZcsW7N+/H56enirzPT094ezsjKioKGnay5cvERMTA39/fzmhExGVCW3lSQD44IMP0K1bN3Tq1EllemH9yomIyoLs0dyHDh2Cubm5ynR3d3fcuXOnyOv54IMPEBkZiV9++QU2NjbSGUg7OztYWlpCoVBg3LhxmDVrFry9veHt7Y1Zs2bBysoKAwYMkBM6EVGZ0Fae3LBhA06dOoXY2Fi1eXL6lQMcqEhE2iWrmMzOzkZWVpba9Nu3b8PGxqbI61m6dCkAoH379irTw8PDERwcDACYNGkSUlNTMXr0aKlz+d69e4u1HSKisqaNPHnr1i2MHTsWe/fuhYWFRb7titOvHOBARSLSLlmXuTt37iyNJAReJbKUlBRMnz69WI8OE0JofOUUkjnrDgkJQUJCAtLS0hATEyON9iYi0lfayJMnT57E/fv30axZM5iamsLU1BQxMTH47rvvYGpqKp2RLE6/coADFYlIu2Sdmfzmm28QEBCAunXrIi0tDQMGDMDff/8NBwcHjaOxiYiMjTbyZMeOHfHXX3+pTBsyZAhq166NTz/9FDVr1pT6lTdp0gTAv/3K586dm+96lUollEql/J0jIspFVjHp6uqKM2fOYP369Th16hSys7MxbNgwDBw4UKWjORGRsdJGnrSxsVG7ElOxYkXY29tL09mvnIh0TVYxCQCWlpYYOnQohg4dqs14iIjKjbLIk+xXTkS6JquYXLNmTYHzBw8eLCsYIqLyorTyZHR0tMr7nH7lISEhstZHRFRSsorJsWPHqrzPyMjAixcvYG5uDisrKxaTRGT0mCeJyFjIGs396NEjlVdKSgquXLmC119/nQNwiIjAPElExkP2s7nz8vb2xpw5c9R+jRMR0SvMk0RUHmmtmAQAExMT3L17V5urJCIqV5gniai8kdVncvv27SrvhRBISEjAokWL0Lp1a60ERkRkyJgnichYyCome/XqpfJeoVCgatWq6NChAxYsWKCNuIiIDBrzJBEZC9nP5iYiovwxTxKRsdBqn0kiIiIiMi6yzkyOHz++yG3DwsLkbIKIyKAxTxKRsZBVTJ4+fRqnTp1CZmYmfH19AQBXr16FiYkJmjZtKrVTKBTaiZKIyMAwTxKRsZBVTPbo0QM2NjZYvXo1KleuDODVDXqHDBmCNm3aYMKECVoNkojI0DBPEpGxkNVncsGCBZg9e7aUIAGgcuXKmDlzJkcpEhGBeZKIjIesYvLp06e4d++e2vT79+/j2bNnJQ6KiMjQMU8SkbGQVUz27t0bQ4YMwebNm3H79m3cvn0bmzdvxrBhw9CnTx9tx0hEZHCYJ4nIWMjqM7ls2TJMnDgRgwYNQkZGxqsVmZpi2LBhmD9/vlYDJCIyRMyTRGQsZBWTVlZWWLJkCebPn4+4uDgIIVCrVi1UrFhR2/ERERkk5kkiMhYluml5QkICEhIS4OPjg4oVK0IIoa24iIjKBeZJIirvZBWTycnJ6NixI3x8fNC1a1ckJCQAAIYPH87bXRARgXmSiIyHrGLy448/hpmZGeLj42FlZSVN79evH3bv3q214IiIDBXzJBEZC1l9Jvfu3Ys9e/bAzc1NZbq3tzdu3ryplcCIiAwZ8yQRGQtZZyafP3+u8ks7R1JSEpRKZYmDIiIydMyTRGQsZBWTbdu2xZo1a6T3CoUC2dnZmD9/PgICArQWHBGRoWKeJCJjIesy9/z589G+fXucOHECL1++xKRJk3DhwgU8fPgQhw4d0naMREQGh3mSiIyFrDOTdevWxblz5/Daa6+hc+fOeP78Ofr06YPTp0/Dy8tL2zESERkc5kkiMhbFPjOZkZGBwMBALF++HKGhoaURExGRQWOeJCJjUuwzk2ZmZjh//jwUCkVpxENEZPCYJ4nImMi6zD148GCsXLlS27EQEZUbzJNEZCxkDcB5+fIl/ve//yEqKgp+fn5qz5oNCwvTSnBERIaKeZKIjEWxislr167Bw8MD58+fR9OmTQEAV69eVWnDyzpEZMyYJ4nI2BSrmPT29kZCQgIOHDgA4NVjwb777js4OTmVSnBERIaGeZKIjE2x+kwKIVTe79q1C8+fP9dqQEREhox5koiMjawBODnyJk0iIlLFPElE5V2xikmFQqHW14d9f4iI/sU8SUTGplh9JoUQCA4OhlKpBACkpaVh5MiRaqMUt2zZor0IiYgMCPMkERmbYhWTQUFBKu8HDRqk1WCIiAwd8yQRGZtiFZPh4eGlFQcRUbnAPElExqZEA3CIiIiIyLixmCQiIiIi2VhMEhEREZFsLCaJiIiISDYWk0REREQkm06LyT/++AM9evSAq6srFAoFtm3bpjJfCIGQkBC4urrC0tIS7du3x4ULF3QTLBERERGp0Wkx+fz5czRq1AiLFi3SOH/evHkICwvDokWLEBsbC2dnZ3Tu3BnPnj0r40iJiIiISBOdFpNdunTBzJkz0adPH7V5QggsXLgQU6dORZ8+fVC/fn2sXr0aL168QGRkpA6iJSIqe7Nnz0bz5s1hY2MDR0dH9OrVC1euXFFpw6s4RKRLettn8vr160hMTERgYKA0TalUol27djh8+HC+y6Wnp+Pp06cqLyIiQxUTE4MPPvgAR48eRVRUFDIzMxEYGIjnz59LbXgVh4h0SW+LycTERACAk5OTynQnJydpniazZ8+GnZ2d9KpevXqpxklEVJp2796N4OBg1KtXD40aNUJ4eDji4+Nx8uRJALyKQ0S6p7fFZA6FQqHyXgihNi23KVOm4MmTJ9Lr1q1bpR0iEVGZefLkCQCgSpUqAORfxSEi0pZiPZu7LDk7OwN4dYbSxcVFmn7//n21s5W5KZVKKJXKUo+PiKisCSEwfvx4vP7666hfvz6Agq/i3Lx5U+N60tPTkZ6eLr1ndyAiKgm9PTPp6ekJZ2dnREVFSdNevnyJmJgY+Pv76zAyIiLdGDNmDM6dO4f169erzSvOVRx2ByIibdLpmcmUlBT8888/0vvr16/jzJkzqFKlCmrUqIFx48Zh1qxZ8Pb2hre3N2bNmgUrKysMGDBAh1ETEZW9Dz/8ENu3b8cff/wBNzc3abqcqzhTpkzB+PHjpfdPnz7Vu4IyPj4eSUlJ+c53cHBAjRo1Sm15Iio6nRaTJ06cQEBAgPQ+J7kFBQUhIiICkyZNQmpqKkaPHo1Hjx6hRYsW2Lt3L2xsbHQVsl5gkiQyHkIIfPjhh9i6dSuio6Ph6empMj/3VZwmTZoA+Pcqzty5czWuU9+7A8XHx8O3dh2kpb7It42FpRWuXL6kMdeVdHkiKh6dFpPt27eHECLf+QqFAiEhIQgJCSm7oPQckySRcfnggw8QGRmJX375BTY2NlIfSTs7O1haWkKhUJS7qzhJSUlIS30B++4TYGavfsY0I/kWkncsQFJSksY8V9Lliah49HYADmnGJElkXJYuXQrg1Y/v3MLDwxEcHAwA5fYqjpl9dSida+lseSIqGhaTBopJksg4FHT1Jgev4hCRLuntaG4iIiIi0n8sJomIiIhINl7m1lOXLl0q1nQiIiIiXWAxqWeyUh4BCgUGDRqk61CIiIiICsViUs9kp6cAQuQ7Wjv12gk8ObhWB5ERERERqWMxqafyG62dkXxLB9EQERERacYBOEREREQkG4tJIiIiIpKNxSQRERERycZikoiIiIhkYzFJRERERLKxmCQiIiIi2XhrICIiMkh8UhiRfmAxSUREBoVPCiPSLywmiYioVBR0htDBwQE1atSQtV5tPSmstOIjMjYsJomISKuKcubQwtIKVy5fKlHBJvdJYWUVH5GxYDFJRERaVdiZw4zkW0jesQBJSUk6Kdb0PT4iQ8NikoiISkV+Zw71hb7HR2QoeGsgIiIiIpKNZybLqZJ0LI+Pj0dSUpLs5QtT2usnIiKissNispwpacfy+Ph4+Naug7TUF7KWL0xpr5+IiIjKFovJcqakHcuTkpKQlvqi1Dqml/b6iYiIqGyxmCynStqxvLQ7prPjOxERUfnAAThEREREJBvPTBopPtO2dOj74CJ9j4+IiAwPi0kjw2falh59H1yk7/GR8eGPWqLygcWkkdHWM21Jnb4PLtL3+Mh48EctUfnCYtJIyX2mLRVO3wcX6Xt8VP7xRy1R+cJikoiIdII/aonKB47mJiIiIiLZeGaSyp2CRixztDIREZF2sZikcqWwEcscrUxERKRdLCapXCloxDJHKxMREWkfi0kqlzhimYiIqGxwAA4RERERycYzk6R1BQ2AKeqTLQpqV9JBNCVZtzb2rST4OEQiItI3LCZJq4ryyL6CFOXJGHIH0ZR03SXdt5Li4xCJiArHH91lj8UkaVVhj+wr7MkWhT0ZoySDaEq67pLuW0nxcYhERAXjj27dYDFJpaKkT7YozQE0JV23rp/awcFFRESa8Ue3brCYJCIi0qA0+25T6eKP7rLFYpKIiCiX0uy7TVQesZgkWfL7xV4WI5r1YfukG+xYT2WhqP2rDx48iDp16mhch66/iyX9W9HlY2kLiz09PR1KpVLjPG38H8A8U3wsJqlYivKLvTxvn3SHHeuprOV3qVTfz1yW9G9Fl4+lLdJdMxQVAJGt9W0XdfvMM+oMophcsmQJ5s+fj4SEBNSrVw8LFy5EmzZtdB2WUSrsF3tpj2jW9fZJd9ixvmDMk2WnNO86oQ0l/VvR5WNpi3rXjNL6P4B5Rh69LyY3btyIcePGYcmSJWjdujWWL1+OLl264OLFizyQOqSvI5rLavukO+xYr455UjdK8l0szcvQOZd6S+vOFbm3oUlBl6GBol0mLizHl/T/gMK6ShX22enz4CxdXKbX+2IyLCwMw4YNw/DhwwEACxcuxJ49e7B06VLMnj1bx9EREeke86RhKe3L0KWpSF2NCrkMrcvLxCXtKlXeuzjIpdfF5MuXL3Hy5ElMnjxZZXpgYCAOHz6so6iIiPQH86ThKc3L0EDpdvcpalcjfb1MXNKuUuW9i4Ncel1MJiUlISsrC05OTirTnZyckJiYqHGZ9PR0pKenS++fPHkCAHj69GmRtpmSkvJqPYn/IPtlmtr8nFPonG948wtd9uFtAMDJkyel70FuV65cKVlshawfACpUqIDsbM2/6AvdfknjL2F8pT2/qPGnpKQU6e89p40QotC2+ox5Ug/nF/FvMTsjXePy2RnpJVpeZL7USnwF5dHCtl3SfSvtYyf7sytk+cL2DyibPFlYfFrPk0KP3blzRwAQhw8fVpk+c+ZM4evrq3GZ6dOnCwB88cUXX0V63bp1qyzSWalhnuSLL75K+1VYntTrM5MODg4wMTFR+3V9//59tV/hOaZMmYLx48dL77Ozs/Hw4UPY29tDoVAUus2nT5+ievXquHXrFmxtbUu2AzrA+HXHkGMHjC9+IQSePXsGV1fXMoiu9DBPlhz3R79xf3SnqHlSr4tJc3NzNGvWDFFRUejdu7c0PSoqCj179tS4jFKpVBtFVqlSpWJv29bWVu8PckEYv+4YcuyAccVvZ2dXytGUPuZJ7eH+6Dfuj24UJU/qdTEJAOPHj8d7770HPz8/tGrVCj/88APi4+MxcuRIXYdGRKQXmCeJSJf0vpjs168fkpOT8eWXXyIhIQH169fHzp074e7uruvQiIj0AvMkEemS3heTADB69GiMHj26TLalVCoxffr0Am+4qs8Yv+4YcuwA4zd0zJPycX/0G/dH/ymEMPD7YhARERGRzlTQdQBEREREZLhYTBIRERGRbCwmiYiIiEg2oywmlyxZAk9PT1hYWKBZs2Y4ePBgge1jYmLQrFkzWFhYoGbNmli2bFkZRapZceLfsmULOnfujKpVq8LW1hatWrXCnj17yjBaVcX97HMcOnQIpqamaNy4cekGWIjixp+eno6pU6fC3d0dSqUSXl5eWLVqVRlFq6648a9btw6NGjWClZUVXFxcMGTIECQnJ5dRtP/6448/0KNHD7i6ukKhUGDbtm2FLqNvf7eGxtDzZF6GnDc1MfRcmpuh59W8DDXPlohWnudlQDZs2CDMzMzEihUrxMWLF8XYsWNFxYoVxc2bNzW2v3btmrCyshJjx44VFy9eFCtWrBBmZmZi8+bNZRz5K8WNf+zYsWLu3Lni+PHj4urVq2LKlCnCzMxMnDp1qowjL37sOR4/fixq1qwpAgMDRaNGjcomWA3kxP/WW2+JFi1aiKioKHH9+nVx7NgxcejQoTKM+l/Fjf/gwYOiQoUK4ttvvxXXrl0TBw8eFPXq1RO9evUq48iF2Llzp5g6dar4+eefBQCxdevWAtvr29+toTH0PJmXIedNTQw9l+Zm6Hk1L0POsyVhdMXka6+9JkaOHKkyrXbt2mLy5Mka20+aNEnUrl1bZdqIESNEy5YtSy3GghQ3fk3q1q0rQkNDtR1aoeTG3q9fP/H555+L6dOn6zQBFjf+Xbt2CTs7O5GcnFwW4RWquPHPnz9f1KxZU2Xad999J9zc3EotxqIoSjGpb3+3hsbQ82Rehpw3NTH0XJqboefVvMpLni0uo7rM/fLlS5w8eRKBgYEq0wMDA3H48GGNyxw5ckSt/RtvvIETJ04gIyOj1GLVRE78eWVnZ+PZs2eoUqVKaYSYL7mxh4eHIy4uDtOnTy/tEAskJ/7t27fDz88P8+bNQ7Vq1eDj44OJEyciNTW1LEJWISd+f39/3L59Gzt37oQQAvfu3cPmzZvRrVu3sgi5RPTp79bQGHqezMuQ86Ymhp5LczP0vJqXseXZ3AzipuXakpSUhKysLDg5OalMd3JyQmJiosZlEhMTNbbPzMxEUlISXFxcSi3evOTEn9eCBQvw/PlzvPPOO6URYr7kxP73339j8uTJOHjwIExNdftVlRP/tWvX8Oeff8LCwgJbt25FUlISRo8ejYcPH5Z5/x458fv7+2PdunXo168f0tLSkJmZibfeegvff/99WYRcIvr0d2toDD1P5mXIeVMTQ8+luRl6Xs3L2PJsbkZ1ZjKHQqFQeS+EUJtWWHtN08tKcePPsX79eoSEhGDjxo1wdHQsrfAKVNTYs7KyMGDAAISGhsLHx6eswitUcT777OxsKBQKrFu3Dq+99hq6du2KsLAwRERE6OxXdHHiv3jxIj766CN88cUXOHnyJHbv3o3r168bzPOe9e3v1tAYep7My5DzpiaGnktzM/S8mpcx5dkc+vMTpQw4ODjAxMRE7RfC/fv31X5J5HB2dtbY3tTUFPb29qUWqyZy4s+xceNGDBs2DJs2bUKnTp1KM0yNihv7s2fPcOLECZw+fRpjxowB8CqJCCFgamqKvXv3okOHDmUSOyDvs3dxcUG1atVgZ2cnTatTpw6EELh9+za8vb1LNebc5MQ/e/ZstG7dGp988gkAoGHDhqhYsSLatGmDmTNn6vXZPX36uzU0hp4n8zLkvKmJoefS3Aw9r+ZlbHk2N6M6M2lubo5mzZohKipKZXpUVBT8/f01LtOqVSu19nv37oWfnx/MzMxKLVZN5MQPvPplHRwcjMjISJ31wyhu7La2tvjrr79w5swZ6TVy5Ej4+vrizJkzaNGiRVmFDkDeZ9+6dWvcvXsXKSkp0rSrV6+iQoUKcHNzK9V485IT/4sXL1ChgmqKMDExAfDvWSd9pU9/t4bG0PNkXoacNzUx9Fyam6Hn1byMLc+qKNPhPnogZ9j+ypUrxcWLF8W4ceNExYoVxY0bN4QQQkyePFm89957UvucW158/PHH4uLFi2LlypV6cWugosYfGRkpTE1NxeLFi0VCQoL0evz4sd7HnpeuRyAWN/5nz54JNzc30bdvX3HhwgURExMjvL29xfDhww0i/vDwcGFqaiqWLFki4uLixJ9//in8/PzEa6+9VuaxP3v2TJw+fVqcPn1aABBhYWHi9OnT0u029P3v1tAYep7My5DzpiaGnktzM/S8mpch59mSMLpiUgghFi9eLNzd3YW5ublo2rSpiImJkeYFBQWJdu3aqbSPjo4WTZo0Eebm5sLDw0MsXbq0jCNWVZz427VrJwCovYKCgso+cFH8zz43fUiAxY3/0qVLolOnTsLS0lK4ubmJ8ePHixcvXpRx1P8qbvzfffedqFu3rrC0tBQuLi5i4MCB4vbt22UctRAHDhwo8HtsCH+3hsbQ82Rehpw3NTH0XJqboefVvAw1z5aEQghDOo9KRERERPrEqPpMEhEREZF2sZgkIiIiItlYTBIRERGRbCwmiYiIiEg2FpNEREREJBuLSSIiIiKSjcUkEREREcnGYpKIiIiIZGMxSWUiOjoaCoUCjx8/LtXthISEwMnJCQqFAtu2bSvVbRER6YP27dtj3Lhxug6DjBiLSSoT/v7+SEhIgJ2dHQAgIiIClSpV0uo2Ll26hNDQUCxfvhwJCQno0qWLVtdPRERE6kx1HQAZB3Nzczg7O5fqNuLi4gAAPXv2hEKh0Njm5cuXMDc3L9U4iIiIjAnPTJIkOzsbc+fORa1ataBUKlGjRg189dVXAIBPP/0UPj4+sLKyQs2aNTFt2jRkZGQAAK5cuQKFQoHLly+rrC8sLAweHh4QQqhc5o6OjsaQIUPw5MkTKBQKKBQKhISE4Msvv0SDBg3U4mrWrBm++OKLAmMPCQlBjx49AAAVKlSQisng4GD06tULs2fPhqurK3x8fAAAd+7cQb9+/VC5cmXY29ujZ8+euHHjhrS+rKwsjB8/HpUqVYK9vT0mTZqEoKAg9OrVS2rj4eGBhQsXqsTRuHFjhISESO+fPHmC//73v3B0dIStrS06dOiAs2fPqsTduHFj/Pjjj/Dw8ICdnR369++PZ8+eFem4dOjQAWPGjFGJITk5GUqlEvv37y/wMyOi8mn37t2ws7PDmjVrsHbtWvj5+cHGxgbOzs4YMGAA7t+/L7XNyc2//fYbGjVqBAsLC7Ro0QJ//fWX1CbnStK2bdvg4+MDCwsLdO7cGbdu3ZLaxMXFoWfPnnBycoK1tTWaN2+O33//vUz3m3SHxSRJpkyZgrlz52LatGm4ePEiIiMj4eTkBACwsbFBREQELl68iG+//RYrVqzAN998AwDw9fVFs2bNsG7dOpX1RUZGYsCAAWpnCf39/bFw4ULY2toiISEBCQkJmDhxIoYOHYqLFy8iNjZWanvu3DmcPn0awcHBBcY+ceJEhIeHA4C0zhz79u3DpUuXEBUVhR07duDFixcICAiAtbU1/vjjD/z555+wtrbGm2++iZcvXwIAFixYgFWrVmHlypX4888/8fDhQ2zdurVYn6cQAt26dUNiYiJ27tyJkydPomnTpujYsSMePnwotYuLi8O2bduwY8cO7NixAzExMZgzZ440v6DjMnz4cERGRiI9PV1qv27dOri6uiIgIKBY8RKR4duwYQPeeecdrFmzBoMHD8bLly8xY8YMnD17Ftu2bcP169c15tNPPvkEX3/9NWJjY+Ho6Ii33npLOmEAAC9evMBXX32F1atX49ChQ3j69Cn69+8vzU9JSUHXrl3x+++/4/Tp03jjjTfQo0cPxMfHl8Vuk64JIiHE06dPhVKpFCtWrChS+3nz5olmzZpJ78PCwkTNmjWl91euXBEAxIULF4QQQhw4cEAAEI8ePRJCCBEeHi7s7OzU1tulSxcxatQo6f24ceNE+/btixTT1q1bRd6vdFBQkHBychLp6enStJUrVwpfX1+RnZ0tTUtPTxeWlpZiz549QgghXFxcxJw5c6T5GRkZws3NTfTs2VOa5u7uLr755huV7TVq1EhMnz5dCCHEvn37hK2trUhLS1Np4+XlJZYvXy6EEGL69OnCyspKPH36VJr/ySefiBYtWgghCj8uaWlpokqVKmLjxo3StMaNG4uQkBCN7Ymo/GnXrp0YO3asWLx4sbCzsxP79+/Pt+3x48cFAPHs2TMhxL+5ecOGDVKb5ORkYWlpKeWV8PBwAUAcPXpUanPp0iUBQBw7dizfbdWtW1d8//33Jd09MgA8M0kAXg1eSU9PR8eOHTXO37x5M15//XU4OzvD2toa06ZNU/nF2b9/f9y8eRNHjx4F8OrsWOPGjVG3bt1ixfH+++9j/fr1SEtLQ0ZGBtatW4ehQ4fK3zEADRo0UOknefLkSfzzzz+wsbGBtbU1rK2tUaVKFaSlpSEuLg5PnjxBQkICWrVqJS1jamoKPz+/Ym335MmTSElJgb29vbQda2trXL9+XerfCby6XG5jYyO9d3FxkS5DFXZclEolBg0ahFWrVgEAzpw5g7NnzxZ6JpeIypeff/4Z48aNw969e1WuSpw+fRo9e/aEu7s7bGxs0L59ewBQO2OYO99VqVIFvr6+uHTpkjQtbw6sXbs2KlWqJLV5/vw5Jk2ahLp166JSpUqwtrbG5cuXeWbSSHAADgEALC0t85139OhR9O/fH6GhoXjjjTdgZ2eHDRs2YMGCBVIbFxcXBAQEIDIyEi1btsT69esxYsSIYsfRo0cPKJVKbN26FUqlEunp6fjPf/4ja59yVKxYUeV9dna2xsvyAFC1atUir7dChQoQQqhMy31ZKDs7Gy4uLoiOjlZbNvdIdjMzM5V5CoUC2dnZAAo+LjmGDx+Oxo0b4/bt21i1ahU6duwId3f3Iu8HERm+xo0b49SpUwgPD0fz5s2hUCjw/PlzBAYGIjAwEGvXrkXVqlURHx+PN954Q+rSU5C8XZQ0DWzMmfbJJ59gz549+Prrr1GrVi1YWlqib9++RdoOGT4WkwQA8Pb2hqWlJfbt24fhw4erzDt06BDc3d0xdepUadrNmzfV1jFw4EB8+umnePfddxEXF6fSnyYvc3NzZGVlqU03NTVFUFAQwsPDoVQq0b9/f1hZWZVgz9Q1bdoUGzdulAbFaOLi4oKjR4+ibdu2AIDMzEypz2OOqlWrqvTNfPr0Ka5fv66yncTERJiamsLDw0NWrAUdlxwNGjSAn58fVqxYgcjISHz//feytkVEhsvLywsLFixA+/btYWJigkWLFuHy5ctISkrCnDlzUL16dQDAiRMnNC5/9OhR1KhRAwDw6NEjXL16FbVr15bmZ2Zm4sSJE3jttdcAvBp4+fjxY6nNwYMHERwcjN69ewN41Ycy96BGKt94mZsAABYWFvj0008xadIkrFmzBnFxcTh69ChWrlyJWrVqIT4+Hhs2bEBcXBy+++47jYNR+vTpg6dPn2LUqFEICAhAtWrV8t2eh4cHUlJSsG/fPiQlJeHFixfSvOHDh2P//v3YtWtXiS9xazJw4EA4ODigZ8+eOHjwIK5fv46YmBiMHTsWt2/fBgCMHTsWc+bMwdatW3H58mWMHj1a7YbrHTp0wI8//oiDBw/i/PnzCAoKgomJiTS/U6dOaNWqFXr16oU9e/bgxo0bOHz4MD7//PN8E3peBR2X3IYPH445c+YgKytLSuZEZFx8fHxw4MAB6ZJ3jRo1YG5uju+//x7Xrl3D9u3bMWPGDI3Lfvnll9i3bx/Onz+P4OBgODg4qNy9wszMDB9++CGOHTuGU6dOYciQIWjZsqVUXNaqVQtbtmyRutoMGDBAusJC5R+LSZJMmzYNEyZMwBdffIE6deqgX79+uH//Pnr27ImPP/4YY8aMQePGjXH48GFMmzZNbXlbW1v06NEDZ8+excCBAwvclr+/P0aOHIl+/fqhatWqmDdvnjTP29sb/v7+8PX1RYsWLbS+n1ZWVvjjjz9Qo0YN9OnTB3Xq1MHQoUORmpoqnamcMGECBg8ejODgYLRq1Qo2NjZqRdqUKVPQtm1bdO/eHV27dkWvXr3g5eUlzVcoFNi5cyfatm2LoUOHwsfHB/3798eNGzek0dhFkd9xye3dd9+FqakpBgwYAAsLixJ8OkRkyHx9fbF//36sX78ec+bMQUREBDZt2oS6detizpw5+PrrrzUuN2fOHIwdOxbNmjVDQkICtm/frtLX3MrKCp9++ikGDBiAVq1awdLSEhs2bJDmf/PNN6hcuTL8/f3Ro0cPvPHGGypXcqh8U4i8nb6IdEwIgdq1a2PEiBEYP368rsORBAcH4/Hjx3r5mMZbt27Bw8MDsbGxTOBEVGTR0dEICAjAo0eP8n0qWUREBMaNG1fqj8Mlw8U+k6RX7t+/jx9//BF37tzBkCFDdB2O3svIyEBCQgImT56Mli1bspAkIqIyx2KS9IqTkxMcHBzwww8/oHLlyirzrK2t811u165daNOmTWmHp3cOHTqEgIAA+Pj4YPPmzboOh4iIjBAvc5PB+Oeff/KdV61atSLdRoeIiIi0i8UkEREREcnG0dxEREREJBuLSSIiIiKSjcUkEREREcnGYpKIiIiIZGMxSURERESysZgkIiIiItlYTBIRERGRbCwmiYiIiEi2/wMnoy68dDL9sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bin the data and look at how its distributed, probably the more random/spread out the better \n",
    "# for training, but this will improve as the database fills out\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    #--------------------Training Set---------------------\n",
    "    save_encoding = ENCODING_TYPE.replace(' ','_')\n",
    "    \n",
    "    num_cols = X_train.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/training_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/validation_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/test_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "else: #just plot linear encoding for now to not get plot overwhelm\n",
    "    #--------------------Training Set---------------------\n",
    "    num_cols = X_train_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/training_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/validation_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/test_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e8215af-8030-4399-bbc5-b235f2ca3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(np.ceil(len(X_train) / TRAIN_BATCH_SIZE))\n",
    "LR_DECAY_STEPS = steps_per_epoch * 20   # decay every ~10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecc581",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251cf19c",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4f8c5",
   "metadata": {},
   "source": [
    "Create a classical multi-layer perceptron for regression. Taking some inspiration from [Deep learning-based I-V Global Parameter Extraction for BSIM-CMG](https://www.sciencedirect.com/science/article/pii/S003811012300179X), Solid-State Electronics, Vol. 209, November 2023.\n",
    "\n",
    "The above publication predicted parameters for BSIM, which is a physics model for advanced transistors that is complicated and might be a similar complexity to the physics we are trying to target/map with these SC qubit hamiltonian values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945bd67-9923-4f7c-8e32-56672a6c3a4a",
   "metadata": {},
   "source": [
    "Reccomended to download a third party app like \"Sleep control Center\" or \"Amphetamine\" to prevent computer from sleeping during the many hour/day long training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4f485-e3da-4663-832c-3bc917660e45",
   "metadata": {},
   "source": [
    "### Create Model by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce671ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # n output neurons for n parameters (value and exists heads both use this size)\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Multilayer perceptron (MLP)\n",
    "        model_shape = f'mlp_{len(X_test[0])}_'\n",
    "        # inner layer sizes\n",
    "        model_shape += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        print(len(y_value_train[0]))\n",
    "        model_shape += f'_{len(y_value_train[0])}'\n",
    "    else:\n",
    "        # Multilayer perceptron (MLP) for both encodings\n",
    "        model_shape_one_hot_encoding = f'mlp_{len(X_test_one_hot_encoding[0])}_'\n",
    "        model_shape_linear_encoding = f'mlp_{len(X_test_linear_encoding[0])}_'\n",
    "        model_shape_one_hot_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        model_shape_linear_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "\n",
    "        print('one hot:', len(y_value_train_one_hot_encoding[0]))\n",
    "        model_shape_one_hot_encoding += f'_{len(y_value_train_one_hot_encoding[0])}'\n",
    "        print('linear:', len(y_value_train_linear_encoding[0]))\n",
    "        model_shape_linear_encoding += f'_{len(y_value_train_linear_encoding[0])}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85ba881d-a212-402c-86d8-ed5ab2bed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        #initialize a model, which lets us build a stack of layers\n",
    "        inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "        x = inputs\n",
    "\n",
    "        #iterate over the configuration of neurons for each hidden layer specified in NEURONS_PER_LAYER\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            # add a fully connected (dense) hidden layer with specified number of neurons\n",
    "            # the LeCun uniform initializer is used when initializing weights, this makes the model more stable\n",
    "            # l2 regularization is used in each layer to penalizing large weights, which prevents overfitting\n",
    "            x = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "\n",
    "            # apply a Leaky ReLU activation function to the outputs of the dense layer\n",
    "            # this introduces non-linearities, allowing the network to learn complex functions\n",
    "            #leaky ReLU is chosen over standard ReLU to help mitigate the \"dying ReLU\" problem:\n",
    "            #     - this problem is when neurons using the ReLU activation function output zero for all inputs and stop learning\n",
    "            #     - can be mitigated by using variations like Leaky ReLU or proper initialization\n",
    "            x = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x)\n",
    "            \n",
    "            # add a dropout layer to reduce overfitting -- randomly drops a set fraction (like 30%) of outputs from the layer\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x)\n",
    "        \n",
    "        # add the output layers consisting of # neurons, corresponding to the # target variables we aim to predict.\n",
    "        # value_out predicts the numerical parameter values; exists_out predicts if each parameter is defined (0/1).\n",
    "        value_out = Dense(len(y_value_train[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x)\n",
    "        exists_out = Dense(len(y_value_train[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x)\n",
    "\n",
    "        model = tf.keras.Model(\n",
    "            inputs=inputs,\n",
    "            outputs={'value_out': value_out, 'exists_out': exists_out},\n",
    "            name='mlp_multi_output'\n",
    "        )\n",
    "\n",
    "    \n",
    "    else:\n",
    "        # One-hot encoding model\n",
    "        inputs_one_hot = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "        x_oh = inputs_one_hot\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_oh = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_oh)\n",
    "            x_oh = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_oh)\n",
    "            x_oh = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_oh)\n",
    "        value_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        exists_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        model_one_hot_encoding = tf.keras.Model(\n",
    "            inputs=inputs_one_hot,\n",
    "            outputs={'value_out': value_out_oh, 'exists_out': exists_out_oh},\n",
    "            name='mlp_multi_output_one_hot'\n",
    "        )\n",
    "\n",
    "        # Linear encoding model\n",
    "        inputs_lin = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "        x_lin = inputs_lin\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_lin = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_lin)\n",
    "            x_lin = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_lin)\n",
    "            x_lin = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_lin)\n",
    "        value_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        exists_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        model_linear_encoding = tf.keras.Model(\n",
    "            inputs=inputs_lin,\n",
    "            outputs={'value_out': value_out_lin, 'exists_out': exists_out_lin},\n",
    "            name='mlp_multi_output_linear'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0181fd2-e4ee-4e41-aaae-4603c1a853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # The exponential decay learning rate schedule gradually reduces the learning rate, fine-tuning the learning process for better convergence\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LR_INITIAL,\n",
    "        decay_steps=LR_DECAY_STEPS,\n",
    "        decay_rate=LR_DECAY_RATE,\n",
    "        staircase=LR_STAIRCASE\n",
    "    )\n",
    "    \n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Set model to minimize loss specified by TRAIN_LOSS, and also to report the loss during training\n",
    "        model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "    else:\n",
    "        # Linear encoding model\n",
    "        model_linear_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "        # One-hot encoding model\n",
    "        model_one_hot_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44e3657d-d0ac-40e6-9829-694436270bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    !mkdir -p model\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model_file = 'model/{}_best_model.keras'.format(model_shape)\n",
    "        last_model_file = 'model/{}_last_model.keras'.format(model_shape)\n",
    "    else:\n",
    "        best_model_file_one_hot_encoding = 'model/{}_best_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "        last_model_file_one_hot_encoding = 'model/{}_last_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "    \n",
    "        best_model_file_linear_encoding = 'model/{}_best_model_linear_encoding.keras'.format(model_shape_linear_encoding)\n",
    "        last_model_file_linear_encoding = 'model/{}_last_model_linear_encoding.keras'.format(model_shape_linear_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49516260-5078-4162-ab99-cdb45f9f9827",
   "metadata": {},
   "source": [
    "Enable training (`train_and_save`) to overwrite the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c95e4501-3aea-4053-9788-30b4532d7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2957910-f200-4e9f-91c3-6e7ed0926ceb",
   "metadata": {},
   "source": [
    "We use Adam optimizer, minimize the Mean Squared Logarithmic Error, and early stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a00680-7b7f-4877-babb-481f0682b7b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96b4fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Set up monitors and plots for later tracking purposes\n",
    "\n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    class TrainingPlot(tf.keras.callbacks.Callback):\n",
    "         \n",
    "        # This function is called when the training begins\n",
    "        def on_train_begin(self, logs={}):\n",
    "            # Initialize the lists for holding the logs, losses \n",
    "            self.losses = []\n",
    "            self.val_losses = []\n",
    "            self.logs = []\n",
    "        \n",
    "        # This function is called at the end of each epoch\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            \n",
    "            # Append the logs, losses  to the lists\n",
    "            self.logs.append(logs)\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            \n",
    "            # Before plotting ensure at least 2 epochs have passed\n",
    "            if len(self.losses) > 1:\n",
    "                \n",
    "                # Clear the previous plot\n",
    "                clear_output(wait=True)\n",
    "                N = np.arange(0, len(self.losses))\n",
    "                \n",
    "                # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "                plt.figure()\n",
    "                plt.plot(N, self.losses, label = \"train_loss\")\n",
    "                plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "                plt.title(\"Training Loss [Epoch {}]\".format(epoch))\n",
    "                plt.xlabel(\"Epoch #\")\n",
    "                plt.ylabel(\"Loss/Accuracy\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "           \n",
    "\n",
    "class LearningRateMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.learning_rates = []\n",
    "\n",
    "    #we have to do some checking for versions here or else we will get an Adam error when using this monitor\n",
    "    def _current_lr(self, optimizer):\n",
    "        # look and see if you get \"lr\" ir \"learning_rate\" depending on the version\n",
    "        lr = getattr(optimizer, \"lr\", None) or getattr(optimizer, \"learning_rate\", None)\n",
    "\n",
    "        # if this is a shecdule then evaluate it at current iteration step\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            return float(lr(optimizer.iterations).numpy())\n",
    "\n",
    "        # if not a schedule, its a scalar/variable/tensor\n",
    "        return float(tf.keras.backend.get_value(lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            lr_val = self._current_lr(self.model.optimizer)\n",
    "        except Exception:\n",
    "            # for anything else fallback\n",
    "            lr_val = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.learning_rates.append(lr_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef223c28-cc33-4721-b049-be7023eb13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 0 ns, total: 9 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "history = None  \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if train_and_save: \n",
    "        # Set up early stopping to prevent overfitting by halting training when validation loss stops improving\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_value_out_loss',                      # Monitor validation loss for stopping criteria \n",
    "            mode='min',                              # Stop when the monitored quantity has stopped decreasing\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,  # Number of epochs to wait after last improvement\n",
    "            verbose=1                                # Enable logging when early stopping happens\n",
    "        )\n",
    "    \n",
    "        # Train the model on the training data and validate on a portion of it\n",
    "        if 'Try Both' not in ENCODING_TYPE:\n",
    "            plot_callback = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            # sample weights: use exists mask for value_out, ones for exists_out\n",
    "            value_sample_weight_train = np.asarray(y_exists_train)\n",
    "            value_sample_weight_val = np.asarray(y_exists_val)  # not used directly but handy to keep\n",
    "            exists_sample_weight_train = np.ones_like(value_sample_weight_train)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                filepath=best_model_file,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "   \n",
    "            history = model.fit(\n",
    "                np.asarray(X_train),\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_value_train),\n",
    "                    \"exists_out\": np.asarray(y_exists_train),\n",
    "                },\n",
    "                sample_weight={\n",
    "                    # Mask value loss wherever the param doesn't exist\n",
    "                    \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),\n",
    "                    # Always train the existence head\n",
    "                    \"exists_out\": np.ones_like(np.asarray(y_exists_train), dtype=\"float32\"),\n",
    "                },\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val),\n",
    "                    {\n",
    "                        \"value_out\": np.asarray(y_value_val),\n",
    "                        \"exists_out\": np.asarray(y_exists_val),\n",
    "                    },\n",
    "                    {\n",
    "                        \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                        \"exists_out\": np.ones_like(np.asarray(y_exists_val), dtype=\"float32\"),\n",
    "                    },\n",
    "                ),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                callbacks=[early_stopping, model_checkpoint, plot_callback, lr_monitor],\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "            model.save(last_model_file)  # Save the final model when done training!\n",
    "        \n",
    "        else:\n",
    "            #-----------------------------------------linear--------------------------------------------\n",
    "            plot_callback_linear_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_linear_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_linear = np.asarray(y_exists_train_linear_encoding)\n",
    "            value_sample_weight_val_linear = np.asarray(y_exists_val_linear_encoding)\n",
    "            exists_sample_weight_train_linear = np.ones_like(value_sample_weight_train_linear)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_linear_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_linear_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_linear_encoding = model_linear_encoding.fit(\n",
    "                np.asarray(X_train_linear_encoding),\n",
    "                [\n",
    "                    np.asarray(y_value_train_linear_encoding),\n",
    "                    np.asarray(y_exists_train_linear_encoding)\n",
    "                ],\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_linear_encoding),\n",
    "                    [\n",
    "                        np.asarray(y_value_val_linear_encoding),\n",
    "                        np.asarray(y_exists_val_linear_encoding)\n",
    "                    ]\n",
    "                ),\n",
    "                sample_weight=[\n",
    "                    np.asarray(y_exists_train_linear_encoding).astype(\"float32\"),                   # value mask (n,16)\n",
    "                    np.ones_like(np.asarray(y_exists_train_linear_encoding), dtype=\"float32\")       # exists weights (n,16)\n",
    "                ]\n",
    "                ,\n",
    "                callbacks=[early_stopping, model_checkpoint_linear_encoding, plot_callback_linear_encoding, lr_monitor_linear_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "            model_linear_encoding.save(last_model_file_linear_encoding)  # Save the final model when done training!\n",
    "            \n",
    "            #-----------------------------------------one hot--------------------------------------------\n",
    "            plot_callback_one_hot_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_one_hot_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_oh = np.asarray(y_exists_train_one_hot_encoding)\n",
    "            value_sample_weight_val_oh = np.asarray(y_exists_val_one_hot_encoding)\n",
    "            exists_sample_weight_train_oh = np.ones_like(value_sample_weight_train_oh)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_one_hot_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_one_hot_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_one_hot_encoding = model_one_hot_encoding.fit(\n",
    "                np.asarray(X_train_one_hot_encoding),\n",
    "                {\n",
    "                    'value_out': np.asarray(y_value_train_one_hot_encoding),\n",
    "                    'exists_out': np.asarray(y_exists_train_one_hot_encoding)\n",
    "                },\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_one_hot_encoding),\n",
    "                    {\n",
    "                        'value_out': np.asarray(y_value_val_one_hot_encoding),\n",
    "                        'exists_out': np.asarray(y_exists_val_one_hot_encoding)\n",
    "                    }\n",
    "                ),\n",
    "                callbacks=[early_stopping, model_checkpoint_one_hot_encoding, plot_callback_one_hot_encoding, lr_monitor_one_hot_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            model_one_hot_encoding.save(last_model_file_one_hot_encoding)  # Save the final model when done training!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4074c-a8ef-4a69-a8cd-5714edb90166",
   "metadata": {},
   "source": [
    "Load the saved best model and use it from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2447145e-91b5-4070-aefe-38f8e6bc33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        model = load_model(best_model_file, custom_objects={})\n",
    "    else:\n",
    "        model_one_hot_encoding = load_model(best_model_file_one_hot_encoding, custom_objects={})\n",
    "        model_linear_encoding = load_model(best_model_file_linear_encoding, custom_objects={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002f4a5-df05-4ff2-be6d-24f8027ca4ea",
   "metadata": {},
   "source": [
    "### Sweep total number of parameters to find the right range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03c72fea-fbf1-48fc-8e8d-7353f631e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    \n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def train_one_config(neurons_per_layer, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=X_train.shape[1],\n",
    "            output_dim=y_value_train.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # returns (batch,)\n",
    "        \n",
    "        def elementwise_mae(y_true, y_pred):\n",
    "            # returns (batch, output_dim) so your (batch, output_dim) mask works correctly\n",
    "            return tf.abs(y_true - y_pred)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\n",
    "                \"value_out\": elementwise_mae,\n",
    "                \"exists_out\": bce,\n",
    "            },\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            # If your Keras supports it, this helps avoid XLA weirdness:\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor= 'val_value_out_loss', \n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        Xtr = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr = np.asarray(y_value_train)\n",
    "        ye_tr = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "        \n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr.astype(\"float32\"),                  # (batch, 16) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\"),   # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va.astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        best_val_loss = float(np.min(history.history[\"val_loss\"]))\n",
    "        best_epoch = int(np.argmin(history.history[\"val_loss\"]) + 1)\n",
    "\n",
    "        return {\n",
    "            \"neurons_per_layer\": tuple(neurons_per_layer),\n",
    "            \"depth\": len(neurons_per_layer),\n",
    "            \"width\": int(neurons_per_layer[0]),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"best_epoch\": best_epoch,\n",
    "        }\n",
    "    configs = []\n",
    "    for depth in [1, 2, 3, 4, 5]:\n",
    "        for width in [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 5000, 6000]:\n",
    "            configs.append([width] * depth)\n",
    "    for depth in [1, 2]:\n",
    "        for width in [2048, 4096]:\n",
    "            configs.append([width] * depth)\n",
    "\n",
    "    # remove duplicates if any\n",
    "    configs = [list(x) for x in {tuple(c) for c in configs}]\n",
    "\n",
    "    results = []\n",
    "    for cfg in sorted(configs, key=lambda c: (len(c), c[0])):\n",
    "        out = train_one_config(cfg, seed=0)\n",
    "        results.append(out)\n",
    "        print(out)\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(\"total_params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "584b9bf8-f2b1-45cd-811f-e0ab2981101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    # save the data\n",
    "\n",
    "    from datetime import datetime\n",
    "    \n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = \"sweep_outputs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(out_dir, f\"sweep_results_{run_id}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d3c698f-d105-46fb-84a6-60ad839aa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    plt.figure()\n",
    "    plt.scatter(df[\"total_params\"], df[\"best_val_loss\"])\n",
    "    plt.xscale(\"log\")  # will be helpful if params grow fast\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size\")\n",
    "    plt.savefig('plots/params_vs_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    plt.figure()\n",
    "    sc = plt.scatter(\n",
    "        df2[\"total_params\"],\n",
    "        df2[\"best_val_loss\"],\n",
    "        c=df2[\"depth\"],\n",
    "        s=20 + 10*np.log2(df2[\"width\"]),\n",
    "    )\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size (color=depth, size=width)\")\n",
    "    plt.colorbar(sc, label=\"Depth\")\n",
    "    plt.savefig(\"plots/params_vs_loss_width_color_coded.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48f20c5e-2bb5-4847-a8ee-da10db0e828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    df.to_csv(\"sweep_results.csv\", index=False)\n",
    "\n",
    "    old = pd.read_csv(\"sweep_results.csv\")\n",
    "    combined = pd.concat([old, df], ignore_index=True).drop_duplicates(\n",
    "        subset=[\"neurons_per_layer\"], keep=\"last\"\n",
    "    )\n",
    "    combined.to_csv(\"sweep_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202f375-0326-4767-96f0-9a5252e5799f",
   "metadata": {},
   "source": [
    "### Sweep amount of data used in training to determine if data amount is limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d64c0f2f-1316-4e29-b09c-6d99ce882cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "\n",
    "    FIXED_DEPTH = 5\n",
    "    FIXED_WIDTH = 64\n",
    "    FIXED_NEURONS = [FIXED_WIDTH] * FIXED_DEPTH\n",
    "\n",
    "    TRAIN_FRACTIONS = np.linspace(0.3, 1.0, 20)\n",
    "\n",
    "    # avg over many seeds for error bars\n",
    "    SWEEP_SEEDS = [0, 1, 2, 3, 4]\n",
    "\n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE,\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def elementwise_mae(y_true, y_pred):\n",
    "        return tf.abs(y_true - y_pred)  \n",
    "\n",
    "    def make_subset(X, y_value, y_exists, frac, seed):\n",
    "        assert 0 < frac <= 1.0\n",
    "        n = len(X)\n",
    "        m = max(1, int(np.floor(frac * n)))\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(n, size=m, replace=False)\n",
    "        return X[idx], y_value[idx], y_exists[idx], m\n",
    "\n",
    "    def train_one_fraction(neurons_per_layer, train_frac, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Full arrays\n",
    "        Xtr_full = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr_full = np.asarray(y_value_train)\n",
    "        ye_tr_full = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "\n",
    "        Xtr, yv_tr, ye_tr, n_sub = make_subset(Xtr_full, yv_tr_full, ye_tr_full, train_frac, seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=Xtr.shape[1],\n",
    "            output_dim=yv_tr.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\"value_out\": elementwise_mae, \"exists_out\": bce},\n",
    "            loss_weights={\"value_out\": 1.0, \"exists_out\": 1.0},\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr,                                # (batch, output_dim) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\") # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va,                              # (val_batch, output_dim) mask\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # grab best epoch by val_loss\n",
    "        val_loss_hist = np.asarray(history.history[\"val_loss\"], dtype=float)\n",
    "        best_i = int(np.argmin(val_loss_hist))\n",
    "        best_epoch = best_i + 1\n",
    "\n",
    "        out = {\n",
    "            \"train_frac\": float(train_frac),\n",
    "            \"train_n\": int(n_sub),\n",
    "            \"seed\": int(seed),\n",
    "            \"neurons_per_layer\": str(list(neurons_per_layer)),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": float(val_loss_hist[best_i]),\n",
    "            \"best_val_value_out_loss\": float(np.asarray(history.history.get(\"val_value_out_loss\"))[best_i]),\n",
    "            \"best_val_exists_out_loss\": float(np.asarray(history.history.get(\"val_exists_out_loss\"))[best_i]),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "        }\n",
    "        return out\n",
    "\n",
    "    results = []\n",
    "    for frac in TRAIN_FRACTIONS:\n",
    "        for seed in SWEEP_SEEDS:\n",
    "            out = train_one_fraction(FIXED_NEURONS, train_frac=frac, seed=seed)\n",
    "            results.append(out)\n",
    "            print(out)\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values([\"train_frac\", \"seed\"]).reset_index(drop=True)\n",
    "\n",
    "    summary = (\n",
    "        df.groupby([\"train_frac\", \"train_n\", \"total_params\"], as_index=False)\n",
    "          .agg(\n",
    "              best_val_loss_mean=(\"best_val_loss\", \"mean\"),\n",
    "              best_val_loss_std=(\"best_val_loss\", \"std\"),\n",
    "              best_epoch_mean=(\"best_epoch\", \"mean\"),\n",
    "              best_val_value_out_loss_mean=(\"best_val_value_out_loss\", \"mean\"),\n",
    "              best_val_exists_out_loss_mean=(\"best_val_exists_out_loss\", \"mean\"),\n",
    "          )\n",
    "          .sort_values(\"train_frac\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # save to csv\n",
    "    run_id = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = os.path.join(\"sweeps\", f\"data_fraction_sweep_{run_id}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_path = os.path.join(out_dir, \"sweep_raw.csv\")\n",
    "    summary_path = os.path.join(out_dir, \"sweep_summary.csv\")\n",
    "    meta_path = os.path.join(out_dir, \"metadata.json\")\n",
    "    fig_path = os.path.join(out_dir, \"val_loss_vs_train_fraction.png\")\n",
    "\n",
    "    df.to_csv(df_path, index=False)\n",
    "    summary.to_csv(summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b458abc-b03a-4910-9dfd-d92637c4cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "    def _jsonify(o):\n",
    "        if isinstance(o, np.ndarray): return o.tolist()\n",
    "        if isinstance(o, (np.integer,)): return int(o)\n",
    "        if isinstance(o, (np.floating,)): return float(o)\n",
    "        return o\n",
    "\n",
    "    metadata = {\n",
    "        \"run_id\": run_id,\n",
    "        \"fixed_depth\": FIXED_DEPTH,\n",
    "        \"fixed_width\": FIXED_WIDTH,\n",
    "        \"fixed_neurons\": FIXED_NEURONS,\n",
    "        \"train_fractions\": TRAIN_FRACTIONS,\n",
    "        \"seeds\": SWEEP_SEEDS,\n",
    "        \"batch_size\": int(TRAIN_BATCH_SIZE),\n",
    "        \"early_stopping_patience\": int(TRAIN_EARLY_STOPPING_PATIENCE),\n",
    "        \"notes\": \"Subset sampling only on TRAIN split. value_out loss is masked using y_exists via sample_weight.\",\n",
    "    }\n",
    "\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2, default=_jsonify)\n",
    "\n",
    "    plt.figure()\n",
    "    y = summary[\"best_val_loss_mean\"].to_numpy()\n",
    "    x = summary[\"train_frac\"].to_numpy()\n",
    "    if len(SWEEP_SEEDS) > 1:\n",
    "        yerr = summary[\"best_val_loss_std\"].fillna(0.0).to_numpy()\n",
    "        plt.errorbar(x, y, yerr=yerr, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss (mean  std)\")\n",
    "    else:\n",
    "        plt.plot(x, y, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss\")\n",
    "\n",
    "    plt.xlabel(\"Training data fraction\")\n",
    "    plt.title(f\"Val loss vs training fraction (depth={FIXED_DEPTH}, width={FIXED_WIDTH})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nSaved:\\n- {df_path}\\n- {summary_path}\\n- {meta_path}\\n- {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d39c98-db42-48fe-9e64-8c153c978203",
   "metadata": {},
   "source": [
    "### Keras Tuner to Find Best Hyperparameters and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe2de3-ba0a-4103-bfd1-466d73bd9b8c",
   "metadata": {},
   "source": [
    "Run this if you want to use keras tuner to make the model rather than doing it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d804553-ae82-4f8f-9182-806c7f22b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras_tuner import HyperModel, RandomSearch\n",
    "    from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "081aa70b-c54e-48af-b895-5e9ddd2746cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        def build_hypermodel(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            # multi-output heads: value_out (regression) and exists_out (existence classification)\n",
    "            value_out = Dense(len(y_value_train[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "        \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "        \n",
    "            model.compile(optimizer=tf.optimizers.Adam(learning_rate=lr_schedule), \n",
    "                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model\n",
    "    else:\n",
    "        def build_hypermodel_one_hot_encoding(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------one hot-------------------------------------------\n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_one_hot_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_one_hot_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_one_hot_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_one_hot_encoding.compile(optimizer=optimizer, \n",
    "                                           loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                           loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                           metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_one_hot_encoding\n",
    "\n",
    "        def build_hypermodel_linear_encoding(hp):\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=400, max_value=1500, step=10) for i in range(5)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------linear------------------------------------------- \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_linear_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_linear_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_linear_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            #----------------------------------------------continue-------------------------------------------\n",
    "\n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_linear_encoding.compile(optimizer=optimizer, \n",
    "                                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_linear_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cfea157-b0b4-4148-8d0a-e37c877877a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras/hyper_tuning_one_hot_encoding/mlp_tuning_one_hot_encoding/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        tuner = RandomSearch(\n",
    "            build_hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + f'/hyper_tuning_{encoding}_encoding',\n",
    "            project_name=f'mlp_tuning_{encoding}_encoding'\n",
    "        )\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # Start tuning linear encoding\n",
    "        tuner_linear_encoding = RandomSearch(\n",
    "            build_hypermodel_linear_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_linear_encoding',\n",
    "            project_name='mlp_tuning_linear_encoding'\n",
    "        )\n",
    "\n",
    "        # Start tuning one hot encoding\n",
    "        tuner_one_hot_encoding = RandomSearch(\n",
    "            build_hypermodel_one_hot_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_one_hot_encoding',\n",
    "            project_name='mlp_tuning_one_hot_encoding'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c11608cb-5b05-45af-af22-0bcab2827734",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    # Setup Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_value_out_loss',\n",
    "        mode='min',\n",
    "        patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15440869-6be6-4005-9db4-3b37695adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Perform hyperparameter tuning\n",
    "        tuner.search(\n",
    "            np.asarray(X_train),\n",
    "            {'value_out': np.asarray(y_value_train), 'exists_out': np.asarray(y_exists_train)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val), {'value_out': np.asarray(y_value_val), 'exists_out': np.asarray(y_exists_val)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # one-hot encoding branch\n",
    "        tuner_one_hot_encoding.search(\n",
    "            np.asarray(X_train_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # linear encoding branch\n",
    "        tuner_linear_encoding.search(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "598b1b58-8413-4573-a02d-fe8363165edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivias/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 29 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file= f'model/best_keras_model_{encoding}_encoding.keras'\n",
    "\n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        best_model.save(best_model_file)\n",
    "\n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_model = load_model(best_model_file, compile=False)\n",
    "    else:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file_linear = 'model/best_keras_model_linear_encoding.keras'\n",
    "        best_model_file_onehot = 'model/best_keras_model_one_hot_encoding.keras'\n",
    "        \n",
    "        best_linear_model = tuner_linear_encoding.get_best_models(1)[0]\n",
    "        best_onehot_model = tuner_one_hot_encoding.get_best_models(1)[0]\n",
    "        \n",
    "        best_linear_model.save(best_model_file_linear)\n",
    "        best_onehot_model.save(best_model_file_onehot)\n",
    "        \n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_linear_model = load_model(best_model_file_linear, compile=False)\n",
    "            loaded_onehot_model = load_model(best_model_file_onehot, compile=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291953b-7ce8-498d-88ce-20974516af77",
   "metadata": {},
   "source": [
    "### View the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "137d2a50-a4ef-4ccc-8cb9-04e380f0fcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " fc0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span>  input1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " leaky_relu0          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">352,550</span>  dropout0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">468,350</span>  dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu2          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">468,050</span>  dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " fc4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">776,910</span>  dropout3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " leaky_relu4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  fc4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                           \n",
       "\n",
       " dropout4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  leaky_relu4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " value_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">22,576</span>  dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       " exists_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">22,576</span>  dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input1 (\u001b[38;5;33mInputLayer\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
       "\n",
       " fc0 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)             \u001b[38;5;34m1,920\u001b[0m  input1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " leaky_relu0          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout0 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc1 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)           \u001b[38;5;34m352,550\u001b[0m  dropout0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout1 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc2 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)           \u001b[38;5;34m468,350\u001b[0m  dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu2          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout2 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc3 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)           \u001b[38;5;34m468,050\u001b[0m  dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  fc3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout3 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  leaky_relu3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " fc4 (\u001b[38;5;33mDense\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)          \u001b[38;5;34m776,910\u001b[0m  dropout3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " leaky_relu4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)                \u001b[38;5;34m0\u001b[0m  fc4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                           \n",
       "\n",
       " dropout4 (\u001b[38;5;33mDropout\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)                \u001b[38;5;34m0\u001b[0m  leaky_relu4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " value_out (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m22,576\u001b[0m  dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n",
       " exists_out (\u001b[38;5;33mDense\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m22,576\u001b[0m  dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112,932</span> (8.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,112,932\u001b[0m (8.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112,932</span> (8.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,112,932\u001b[0m (8.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model.summary()\n",
    "    else:\n",
    "        best_onehot_model.summary()\n",
    "        best_linear_model.summary()\n",
    "        \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        print(\"\\n---- Model Summary ----\")\n",
    "        model.summary()\n",
    "    else:\n",
    "        print(\"\\n---- Linear Encoding Model Summary ----\")\n",
    "        model_linear_encoding.summary()\n",
    "        \n",
    "        print(\"\\n---- One-Hot Encoding Model Summary ----\")\n",
    "        model_one_hot_encoding.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f05d0a25-2890-4ddc-b888-57b849fa2a0f",
   "metadata": {},
   "source": [
    "if KERAS_TUNER:\n",
    "    keras2ascii(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57cb40-ca2c-4ac7-905c-e13beaf71a51",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5556f8-c81b-4522-b7be-d847b6f20452",
   "metadata": {},
   "source": [
    "Although we may plot and print many metrics, we focus only on **Mean Squared Error (MSE).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc9acc-ad33-4df3-ac56-8ed3913ce16d",
   "metadata": {},
   "source": [
    "Plot training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "523cc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a721cc-cc18-4bc6-96b9-520b736e2382",
   "metadata": {},
   "source": [
    "### Visualize gradients for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d64ca5e-a7e8-49fe-8734-becc35d4998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        class GradientNormLogger(tf.keras.callbacks.Callback):\n",
    "            \"\"\"\n",
    "            Logs gradient norms on a fixed probe batch at epoch end.\n",
    "            Works for:\n",
    "              - single-output models (y_true array)\n",
    "              - multi-output dict models (e.g., {\"value_out\":..., \"exists_out\":...})\n",
    "            Supports passing sample_weight (incl. per-output dict), which is required for masked losses.\n",
    "            \"\"\"\n",
    "            def __init__(\n",
    "                self,\n",
    "                x_probe,\n",
    "                y_probe,\n",
    "                sample_weight_probe=None,\n",
    "                layer_name_prefixes=(\"fc\", \"value_out\", \"exists_out\"),\n",
    "                log_every=1,\n",
    "                verbose=1\n",
    "            ):\n",
    "                super().__init__()\n",
    "                self.x_probe = tf.convert_to_tensor(x_probe)\n",
    "                self.y_probe = y_probe  # keep as-is; we will convert lazily (dict vs array)\n",
    "                self.sample_weight_probe = sample_weight_probe\n",
    "                self.layer_name_prefixes = tuple(layer_name_prefixes)\n",
    "                self.log_every = int(log_every)\n",
    "                self.verbose = int(verbose)\n",
    "                self.records = []\n",
    "        \n",
    "            def _to_tensor_tree(self, obj):\n",
    "                # converts arrays (or dict of arrays) to tensors\n",
    "                if obj is None:\n",
    "                    return None\n",
    "                if isinstance(obj, dict):\n",
    "                    return {k: tf.convert_to_tensor(v) for k, v in obj.items()}\n",
    "                return tf.convert_to_tensor(obj)\n",
    "        \n",
    "            def _want_var(self, var_name: str) -> bool:\n",
    "                # var_name like \"fc0/kernel:0\", \"value_out/bias:0\", etc.\n",
    "                base = var_name.split(\":\")[0]\n",
    "                return any(base.startswith(pfx) for pfx in self.layer_name_prefixes)\n",
    "        \n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                logs = logs or {}\n",
    "                if (epoch + 1) % self.log_every != 0:\n",
    "                    return\n",
    "        \n",
    "                y_probe_t = self._to_tensor_tree(self.y_probe)\n",
    "                sw_probe_t = self._to_tensor_tree(self.sample_weight_probe)\n",
    "        \n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = self.model(self.x_probe, training=True)\n",
    "                    # IMPORTANT: use compiled_loss the same way training does\n",
    "                    loss = self.model.compiled_loss(\n",
    "                        y_probe_t,\n",
    "                        y_pred,\n",
    "                        sample_weight=sw_probe_t,\n",
    "                        regularization_losses=self.model.losses\n",
    "                    )\n",
    "        \n",
    "                grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        \n",
    "                rec = {\"epoch\": int(epoch + 1), \"probe_loss\": float(loss.numpy())}\n",
    "        \n",
    "                per_layer = {}\n",
    "                for w, g in zip(self.model.trainable_weights, grads):\n",
    "                    if g is None:\n",
    "                        continue\n",
    "        \n",
    "                    wname = w.name  # includes :0\n",
    "                    if not self._want_var(wname):\n",
    "                        continue\n",
    "        \n",
    "                    wbase = wname.split(\":\")[0]\n",
    "                    g_norm = float(tf.linalg.global_norm([g]).numpy().item())\n",
    "                    rec[f\"grad_norm__{wbase}\"] = g_norm\n",
    "        \n",
    "                    layer_key = wbase.split(\"/\")[0]\n",
    "                    per_layer.setdefault(layer_key, []).append(g_norm)\n",
    "        \n",
    "                for layer_key, norms in per_layer.items():\n",
    "                    rec[f\"grad_mean__{layer_key}\"] = float(np.mean(norms))\n",
    "                    rec[f\"grad_max__{layer_key}\"] = float(np.max(norms))\n",
    "        \n",
    "                g_all = [g for g in grads if g is not None]\n",
    "                rec[\"grad_global_norm\"] = float(tf.linalg.global_norm(g_all).numpy().item()) if g_all else float(\"nan\")\n",
    "        \n",
    "                self.records.append(rec)\n",
    "        \n",
    "                # push scalars into History\n",
    "                for k, v in rec.items():\n",
    "                    if k != \"epoch\":\n",
    "                        logs[k] = v\n",
    "        \n",
    "                if self.verbose:\n",
    "                    msg = f\"[Grad] epoch={rec['epoch']} probe_loss={rec['probe_loss']:.6g} global={rec['grad_global_norm']:.3g}\"\n",
    "                    # show a couple common layers if present\n",
    "                    for lk in (\"fc0\", \"value_out\", \"exists_out\"):\n",
    "                        mk = f\"grad_mean__{lk}\"\n",
    "                        xk = f\"grad_max__{lk}\"\n",
    "                        if mk in rec:\n",
    "                            msg += f\" | {lk}:mean={rec[mk]:.3g} max={rec[xk]:.3g}\"\n",
    "                    print(msg)\n",
    "        \n",
    "            def to_csv(self, path: str):\n",
    "                import csv, os\n",
    "                os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "                if not self.records:\n",
    "                    return\n",
    "                keys = sorted({k for r in self.records for k in r.keys()})\n",
    "                with open(path, \"w\", newline=\"\") as f:\n",
    "                    w = csv.DictWriter(f, fieldnames=keys)\n",
    "                    w.writeheader()\n",
    "                    w.writerows(self.records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9969df9e-8593-4cb0-9051-2a085a051d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        probe_n = min(256, len(X_train))\n",
    "\n",
    "        x_probe = np.asarray(X_train[:probe_n])\n",
    "\n",
    "        # y_true dict for the notebook model\n",
    "        y_probe = {\n",
    "            \"value_out\": np.asarray(y_value_train[:probe_n]),\n",
    "            \"exists_out\": np.asarray(y_exists_train[:probe_n]).astype(\"float32\"),\n",
    "        }\n",
    "\n",
    "        # sample_weight dict: mask value_out by exists_out, neutral weight for exists_out\n",
    "        sw_probe = {\n",
    "            \"value_out\": y_probe[\"exists_out\"],  # (probe_n, output_dim)\n",
    "            \"exists_out\": np.ones((probe_n,), dtype=\"float32\"),\n",
    "        }\n",
    "\n",
    "        grad_logger = GradientNormLogger(\n",
    "            x_probe=x_probe,\n",
    "            y_probe=y_probe,\n",
    "            sample_weight_probe=sw_probe,\n",
    "            layer_name_prefixes=(\"fc0\", \"value_out\", \"exists_out\"),  # adjust as you like\n",
    "            log_every=1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()\n",
    "\n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            {\"value_out\": np.asarray(y_value_train), \"exists_out\": np.asarray(y_exists_train).astype(\"float32\")},\n",
    "            sample_weight={\n",
    "                \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),\n",
    "                \"exists_out\": np.ones((len(X_train),), dtype=\"float32\"),\n",
    "            },\n",
    "            epochs=400,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                {\"value_out\": np.asarray(y_value_val), \"exists_out\": np.asarray(y_exists_val).astype(\"float32\")},\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(X_val),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            callbacks=[early_stopping, lr_monitor, grad_logger],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grad_logger.to_csv(f\"plots/{encoding}_gradients.csv\")\n",
    "\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc30d21b-458b-4518-bdae-04f505e45c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        dfg = pd.DataFrame(grad_logger.records)\n",
    "        \n",
    "        # Plot global grad norm\n",
    "        plt.figure()\n",
    "        plt.plot(dfg[\"epoch\"], dfg[\"grad_global_norm\"])\n",
    "        plt.yscale(\"log\")  # very helpful to see vanishing/exploding\n",
    "        plt.title(\"Gradient tracking for a single batch across epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Gradient magnitude (log scale)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"plots/{encoding}_grad_global_norm.pdf\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot fc0 and output mean norms if present\n",
    "        for lk in [\"fc0\", \"output\"]:\n",
    "            col = f\"grad_mean__{lk}\"\n",
    "            if col in dfg.columns:\n",
    "                plt.figure()\n",
    "                plt.plot(dfg[\"epoch\"], dfg[col])\n",
    "                plt.yscale(\"log\")\n",
    "                plt.title(f\"Gradient Mean Norm: {lk} (probe batch)\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Mean grad norm (log scale)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"plots/{encoding}_grad_mean_{lk}.pdf\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa8eb5-11a2-4ca0-832f-e0cfb057a75a",
   "metadata": {},
   "source": [
    "### Look at the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "347263a8-570e-4a04-bbae-3ea0662e4012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output order: ListWrapper(['value_out', 'exists_out'])\n",
      "Epoch 1/400\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - exists_out_accuracy: 0.0156 - exists_out_loss: 0.6845 - loss: 5.0822 - value_out_loss: 0.3763 - value_out_mean_squared_error: 0.3763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768503898.859842   55370 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - exists_out_accuracy: 0.0212 - exists_out_loss: 0.4682 - loss: 4.3381 - value_out_loss: 0.3493 - value_out_mean_squared_error: 0.3536 - val_exists_out_accuracy: 0.0055 - val_exists_out_loss: 0.1786 - val_loss: 3.3310 - val_value_out_loss: 0.3172 - val_value_out_mean_squared_error: 0.3226\n",
      "Epoch 2/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0176 - exists_out_loss: 0.1451 - loss: 2.8759 - value_out_loss: 0.2443 - value_out_mean_squared_error: 0.2483 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.1113 - val_loss: 2.2978 - val_value_out_loss: 0.1394 - val_value_out_mean_squared_error: 0.1419\n",
      "Epoch 3/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0059 - exists_out_loss: 0.0991 - loss: 2.0594 - value_out_loss: 0.1294 - value_out_mean_squared_error: 0.1314 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0549 - val_loss: 1.6944 - val_value_out_loss: 0.0724 - val_value_out_mean_squared_error: 0.0728\n",
      "Epoch 4/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - exists_out_accuracy: 0.0059 - exists_out_loss: 0.0492 - loss: 1.5771 - value_out_loss: 0.0863 - value_out_mean_squared_error: 0.0872 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0388 - val_loss: 1.3686 - val_value_out_loss: 0.0455 - val_value_out_mean_squared_error: 0.0462\n",
      "Epoch 5/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0381 - loss: 1.3033 - value_out_loss: 0.0627 - value_out_mean_squared_error: 0.0627 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0373 - val_loss: 1.1796 - val_value_out_loss: 0.0463 - val_value_out_mean_squared_error: 0.0463\n",
      "Epoch 6/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0118 - exists_out_loss: 0.0348 - loss: 1.1241 - value_out_loss: 0.0537 - value_out_mean_squared_error: 0.0540 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0315 - val_loss: 1.0189 - val_value_out_loss: 0.0345 - val_value_out_mean_squared_error: 0.0346\n",
      "Epoch 7/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0082 - exists_out_loss: 0.0338 - loss: 0.9852 - value_out_loss: 0.0472 - value_out_mean_squared_error: 0.0473 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0305 - val_loss: 0.9024 - val_value_out_loss: 0.0339 - val_value_out_mean_squared_error: 0.0340\n",
      "Epoch 8/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0059 - exists_out_loss: 0.0328 - loss: 0.8771 - value_out_loss: 0.0456 - value_out_mean_squared_error: 0.0458 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0307 - val_loss: 0.8098 - val_value_out_loss: 0.0340 - val_value_out_mean_squared_error: 0.0340\n",
      "Epoch 9/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0118 - exists_out_loss: 0.0325 - loss: 0.7913 - value_out_loss: 0.0452 - value_out_mean_squared_error: 0.0454 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0308 - val_loss: 0.7352 - val_value_out_loss: 0.0338 - val_value_out_mean_squared_error: 0.0339\n",
      "Epoch 10/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0094 - exists_out_loss: 0.0329 - loss: 0.7229 - value_out_loss: 0.0451 - value_out_mean_squared_error: 0.0452 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0302 - val_loss: 0.6744 - val_value_out_loss: 0.0342 - val_value_out_mean_squared_error: 0.0342\n",
      "Epoch 11/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0094 - exists_out_loss: 0.0320 - loss: 0.6641 - value_out_loss: 0.0434 - value_out_mean_squared_error: 0.0435 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0295 - val_loss: 0.6228 - val_value_out_loss: 0.0341 - val_value_out_mean_squared_error: 0.0340\n",
      "Epoch 12/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0094 - exists_out_loss: 0.0320 - loss: 0.6160 - value_out_loss: 0.0431 - value_out_mean_squared_error: 0.0432 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0302 - val_loss: 0.5783 - val_value_out_loss: 0.0323 - val_value_out_mean_squared_error: 0.0324\n",
      "Epoch 13/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0094 - exists_out_loss: 0.0321 - loss: 0.5739 - value_out_loss: 0.0416 - value_out_mean_squared_error: 0.0417 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0293 - val_loss: 0.5394 - val_value_out_loss: 0.0314 - val_value_out_mean_squared_error: 0.0315\n",
      "Epoch 14/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0094 - exists_out_loss: 0.0313 - loss: 0.5372 - value_out_loss: 0.0412 - value_out_mean_squared_error: 0.0413 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0291 - val_loss: 0.5064 - val_value_out_loss: 0.0319 - val_value_out_mean_squared_error: 0.0319\n",
      "Epoch 15/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0071 - exists_out_loss: 0.0307 - loss: 0.5042 - value_out_loss: 0.0405 - value_out_mean_squared_error: 0.0405 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0294 - val_loss: 0.4768 - val_value_out_loss: 0.0318 - val_value_out_mean_squared_error: 0.0318\n",
      "Epoch 16/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0082 - exists_out_loss: 0.0310 - loss: 0.4751 - value_out_loss: 0.0397 - value_out_mean_squared_error: 0.0398 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0293 - val_loss: 0.4486 - val_value_out_loss: 0.0304 - val_value_out_mean_squared_error: 0.0305\n",
      "Epoch 17/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0082 - exists_out_loss: 0.0309 - loss: 0.4490 - value_out_loss: 0.0394 - value_out_mean_squared_error: 0.0395 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0288 - val_loss: 0.4241 - val_value_out_loss: 0.0304 - val_value_out_mean_squared_error: 0.0304\n",
      "Epoch 18/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0306 - loss: 0.4259 - value_out_loss: 0.0396 - value_out_mean_squared_error: 0.0397 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0284 - val_loss: 0.4020 - val_value_out_loss: 0.0304 - val_value_out_mean_squared_error: 0.0304\n",
      "Epoch 19/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0106 - exists_out_loss: 0.0302 - loss: 0.4039 - value_out_loss: 0.0387 - value_out_mean_squared_error: 0.0389 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0283 - val_loss: 0.3814 - val_value_out_loss: 0.0298 - val_value_out_mean_squared_error: 0.0298\n",
      "Epoch 20/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - exists_out_accuracy: 0.0082 - exists_out_loss: 0.0306 - loss: 0.3848 - value_out_loss: 0.0388 - value_out_mean_squared_error: 0.0388 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0285 - val_loss: 0.3630 - val_value_out_loss: 0.0296 - val_value_out_mean_squared_error: 0.0297\n",
      "Epoch 21/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0165 - exists_out_loss: 0.0306 - loss: 0.3682 - value_out_loss: 0.0394 - value_out_mean_squared_error: 0.0395 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0286 - val_loss: 0.3475 - val_value_out_loss: 0.0298 - val_value_out_mean_squared_error: 0.0299\n",
      "Epoch 22/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0106 - exists_out_loss: 0.0303 - loss: 0.3513 - value_out_loss: 0.0383 - value_out_mean_squared_error: 0.0383 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0278 - val_loss: 0.3306 - val_value_out_loss: 0.0289 - val_value_out_mean_squared_error: 0.0289\n",
      "Epoch 23/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0298 - loss: 0.3356 - value_out_loss: 0.0378 - value_out_mean_squared_error: 0.0380 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0272 - val_loss: 0.3175 - val_value_out_loss: 0.0309 - val_value_out_mean_squared_error: 0.0308\n",
      "Epoch 24/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0299 - loss: 0.3223 - value_out_loss: 0.0388 - value_out_mean_squared_error: 0.0389 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0281 - val_loss: 0.3032 - val_value_out_loss: 0.0297 - val_value_out_mean_squared_error: 0.0298\n",
      "Epoch 25/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0296 - loss: 0.3068 - value_out_loss: 0.0371 - value_out_mean_squared_error: 0.0372 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0272 - val_loss: 0.2890 - val_value_out_loss: 0.0290 - val_value_out_mean_squared_error: 0.0291\n",
      "Epoch 26/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0294 - loss: 0.2933 - value_out_loss: 0.0365 - value_out_mean_squared_error: 0.0365 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0272 - val_loss: 0.2768 - val_value_out_loss: 0.0292 - val_value_out_mean_squared_error: 0.0293\n",
      "Epoch 27/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0305 - loss: 0.2842 - value_out_loss: 0.0378 - value_out_mean_squared_error: 0.0380 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0275 - val_loss: 0.2659 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0284\n",
      "Epoch 28/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0292 - loss: 0.2725 - value_out_loss: 0.0374 - value_out_mean_squared_error: 0.0374 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0269 - val_loss: 0.2568 - val_value_out_loss: 0.0293 - val_value_out_mean_squared_error: 0.0294\n",
      "Epoch 29/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0291 - loss: 0.2618 - value_out_loss: 0.0367 - value_out_mean_squared_error: 0.0368 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0272 - val_loss: 0.2463 - val_value_out_loss: 0.0291 - val_value_out_mean_squared_error: 0.0292\n",
      "Epoch 30/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0059 - exists_out_loss: 0.0294 - loss: 0.2512 - value_out_loss: 0.0360 - value_out_mean_squared_error: 0.0361 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0269 - val_loss: 0.2363 - val_value_out_loss: 0.0291 - val_value_out_mean_squared_error: 0.0292\n",
      "Epoch 31/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0291 - loss: 0.2419 - value_out_loss: 0.0364 - value_out_mean_squared_error: 0.0364 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0263 - val_loss: 0.2264 - val_value_out_loss: 0.0283 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 32/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0291 - loss: 0.2335 - value_out_loss: 0.0364 - value_out_mean_squared_error: 0.0364 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0276 - val_loss: 0.2202 - val_value_out_loss: 0.0291 - val_value_out_mean_squared_error: 0.0290\n",
      "Epoch 33/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0291 - loss: 0.2267 - value_out_loss: 0.0369 - value_out_mean_squared_error: 0.0370 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0275 - val_loss: 0.2132 - val_value_out_loss: 0.0292 - val_value_out_mean_squared_error: 0.0292\n",
      "Epoch 34/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0290 - loss: 0.2191 - value_out_loss: 0.0369 - value_out_mean_squared_error: 0.0370 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0269 - val_loss: 0.2066 - val_value_out_loss: 0.0305 - val_value_out_mean_squared_error: 0.0306\n",
      "Epoch 35/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0288 - loss: 0.2111 - value_out_loss: 0.0365 - value_out_mean_squared_error: 0.0365 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0275 - val_loss: 0.1995 - val_value_out_loss: 0.0301 - val_value_out_mean_squared_error: 0.0303\n",
      "Epoch 36/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0293 - loss: 0.2048 - value_out_loss: 0.0362 - value_out_mean_squared_error: 0.0364 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0263 - val_loss: 0.1897 - val_value_out_loss: 0.0274 - val_value_out_mean_squared_error: 0.0276\n",
      "Epoch 37/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0290 - loss: 0.1982 - value_out_loss: 0.0361 - value_out_mean_squared_error: 0.0362 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0263 - val_loss: 0.1848 - val_value_out_loss: 0.0290 - val_value_out_mean_squared_error: 0.0289\n",
      "Epoch 38/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0284 - loss: 0.1910 - value_out_loss: 0.0358 - value_out_mean_squared_error: 0.0358 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0260 - val_loss: 0.1782 - val_value_out_loss: 0.0288 - val_value_out_mean_squared_error: 0.0289\n",
      "Epoch 39/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0285 - loss: 0.1843 - value_out_loss: 0.0352 - value_out_mean_squared_error: 0.0352 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0263 - val_loss: 0.1722 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0286\n",
      "Epoch 40/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0071 - exists_out_loss: 0.0289 - loss: 0.1799 - value_out_loss: 0.0356 - value_out_mean_squared_error: 0.0359 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0258 - val_loss: 0.1663 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 41/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0291 - loss: 0.1766 - value_out_loss: 0.0365 - value_out_mean_squared_error: 0.0366 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0255 - val_loss: 0.1625 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0280\n",
      "Epoch 42/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0284 - loss: 0.1721 - value_out_loss: 0.0367 - value_out_mean_squared_error: 0.0368 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.1580 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 43/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0082 - exists_out_loss: 0.0284 - loss: 0.1661 - value_out_loss: 0.0349 - value_out_mean_squared_error: 0.0352 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.1520 - val_value_out_loss: 0.0272 - val_value_out_mean_squared_error: 0.0272\n",
      "Epoch 44/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0280 - loss: 0.1597 - value_out_loss: 0.0339 - value_out_mean_squared_error: 0.0341 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.1471 - val_value_out_loss: 0.0269 - val_value_out_mean_squared_error: 0.0269\n",
      "Epoch 45/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0282 - loss: 0.1559 - value_out_loss: 0.0344 - value_out_mean_squared_error: 0.0345 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.1423 - val_value_out_loss: 0.0267 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 46/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0288 - loss: 0.1535 - value_out_loss: 0.0352 - value_out_mean_squared_error: 0.0352 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0261 - val_loss: 0.1427 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 47/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0291 - loss: 0.1523 - value_out_loss: 0.0361 - value_out_mean_squared_error: 0.0362 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.1383 - val_value_out_loss: 0.0278 - val_value_out_mean_squared_error: 0.0278\n",
      "Epoch 48/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0279 - loss: 0.1475 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0348 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.1358 - val_value_out_loss: 0.0278 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 49/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0281 - loss: 0.1438 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0348 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0262 - val_loss: 0.1330 - val_value_out_loss: 0.0285 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 50/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0320 - loss: 0.1478 - value_out_loss: 0.0388 - value_out_mean_squared_error: 0.0390 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.1346 - val_value_out_loss: 0.0333 - val_value_out_mean_squared_error: 0.0334\n",
      "Epoch 51/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0279 - loss: 0.1408 - value_out_loss: 0.0371 - value_out_mean_squared_error: 0.0373 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.1300 - val_value_out_loss: 0.0303 - val_value_out_mean_squared_error: 0.0303\n",
      "Epoch 52/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0286 - loss: 0.1380 - value_out_loss: 0.0359 - value_out_mean_squared_error: 0.0361 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.1235 - val_value_out_loss: 0.0275 - val_value_out_mean_squared_error: 0.0274\n",
      "Epoch 53/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0281 - loss: 0.1324 - value_out_loss: 0.0343 - value_out_mean_squared_error: 0.0345 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.1197 - val_value_out_loss: 0.0270 - val_value_out_mean_squared_error: 0.0269\n",
      "Epoch 54/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0282 - loss: 0.1297 - value_out_loss: 0.0349 - value_out_mean_squared_error: 0.0350 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.1166 - val_value_out_loss: 0.0270 - val_value_out_mean_squared_error: 0.0269\n",
      "Epoch 55/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0281 - loss: 0.1269 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0250 - val_loss: 0.1148 - val_value_out_loss: 0.0275 - val_value_out_mean_squared_error: 0.0275\n",
      "Epoch 56/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0298 - loss: 0.1275 - value_out_loss: 0.0361 - value_out_mean_squared_error: 0.0362 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.1126 - val_value_out_loss: 0.0270 - val_value_out_mean_squared_error: 0.0270\n",
      "Epoch 57/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0278 - loss: 0.1216 - value_out_loss: 0.0337 - value_out_mean_squared_error: 0.0337 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.1110 - val_value_out_loss: 0.0271 - val_value_out_mean_squared_error: 0.0271\n",
      "Epoch 58/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0294 - loss: 0.1234 - value_out_loss: 0.0358 - value_out_mean_squared_error: 0.0358 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.1097 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 59/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0282 - loss: 0.1201 - value_out_loss: 0.0354 - value_out_mean_squared_error: 0.0354 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.1092 - val_value_out_loss: 0.0285 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 60/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0283 - loss: 0.1193 - value_out_loss: 0.0356 - value_out_mean_squared_error: 0.0355 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0259 - val_loss: 0.1107 - val_value_out_loss: 0.0295 - val_value_out_mean_squared_error: 0.0296\n",
      "Epoch 61/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0288 - loss: 0.1196 - value_out_loss: 0.0361 - value_out_mean_squared_error: 0.0362 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.1079 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 62/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0309 - loss: 0.1241 - value_out_loss: 0.0393 - value_out_mean_squared_error: 0.0396 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.1112 - val_value_out_loss: 0.0329 - val_value_out_mean_squared_error: 0.0328\n",
      "Epoch 63/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0291 - loss: 0.1207 - value_out_loss: 0.0383 - value_out_mean_squared_error: 0.0386 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0257 - val_loss: 0.1097 - val_value_out_loss: 0.0312 - val_value_out_mean_squared_error: 0.0314\n",
      "Epoch 64/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0059 - exists_out_loss: 0.0283 - loss: 0.1158 - value_out_loss: 0.0353 - value_out_mean_squared_error: 0.0354 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0250 - val_loss: 0.1044 - val_value_out_loss: 0.0286 - val_value_out_mean_squared_error: 0.0287\n",
      "Epoch 65/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0279 - loss: 0.1114 - value_out_loss: 0.0337 - value_out_mean_squared_error: 0.0338 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0245 - val_loss: 0.0991 - val_value_out_loss: 0.0268 - val_value_out_mean_squared_error: 0.0267\n",
      "Epoch 66/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0280 - loss: 0.1093 - value_out_loss: 0.0344 - value_out_mean_squared_error: 0.0344 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0245 - val_loss: 0.0976 - val_value_out_loss: 0.0274 - val_value_out_mean_squared_error: 0.0273\n",
      "Epoch 67/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0285 - loss: 0.1086 - value_out_loss: 0.0349 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0968 - val_value_out_loss: 0.0276 - val_value_out_mean_squared_error: 0.0277\n",
      "Epoch 68/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0277 - loss: 0.1058 - value_out_loss: 0.0342 - value_out_mean_squared_error: 0.0342 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.0960 - val_value_out_loss: 0.0278 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 69/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0281 - loss: 0.1056 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0260 - val_loss: 0.0974 - val_value_out_loss: 0.0288 - val_value_out_mean_squared_error: 0.0289\n",
      "Epoch 70/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0292 - loss: 0.1079 - value_out_loss: 0.0364 - value_out_mean_squared_error: 0.0364 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0259 - val_loss: 0.1017 - val_value_out_loss: 0.0330 - val_value_out_mean_squared_error: 0.0331\n",
      "Epoch 71/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0307 - loss: 0.1124 - value_out_loss: 0.0378 - value_out_mean_squared_error: 0.0382 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0990 - val_value_out_loss: 0.0292 - val_value_out_mean_squared_error: 0.0295\n",
      "Epoch 72/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0299 - loss: 0.1112 - value_out_loss: 0.0368 - value_out_mean_squared_error: 0.0369 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0258 - val_loss: 0.0994 - val_value_out_loss: 0.0287 - val_value_out_mean_squared_error: 0.0290\n",
      "Epoch 73/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0288 - loss: 0.1083 - value_out_loss: 0.0358 - value_out_mean_squared_error: 0.0358 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0961 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 74/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0290 - loss: 0.1072 - value_out_loss: 0.0361 - value_out_mean_squared_error: 0.0363 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.0940 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0282\n",
      "Epoch 75/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0282 - loss: 0.1034 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0924 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0280\n",
      "Epoch 76/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0277 - loss: 0.0997 - value_out_loss: 0.0334 - value_out_mean_squared_error: 0.0335 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.0898 - val_value_out_loss: 0.0274 - val_value_out_mean_squared_error: 0.0274\n",
      "Epoch 77/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0281 - loss: 0.1000 - value_out_loss: 0.0345 - value_out_mean_squared_error: 0.0346 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0908 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0284\n",
      "Epoch 78/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0301 - loss: 0.1031 - value_out_loss: 0.0364 - value_out_mean_squared_error: 0.0365 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0905 - val_value_out_loss: 0.0292 - val_value_out_mean_squared_error: 0.0292\n",
      "Epoch 79/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0279 - loss: 0.0977 - value_out_loss: 0.0337 - value_out_mean_squared_error: 0.0339 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.0887 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 80/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0287 - loss: 0.0993 - value_out_loss: 0.0351 - value_out_mean_squared_error: 0.0352 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0896 - val_value_out_loss: 0.0283 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 81/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0282 - loss: 0.0984 - value_out_loss: 0.0346 - value_out_mean_squared_error: 0.0346 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0891 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0282\n",
      "Epoch 82/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0290 - loss: 0.0998 - value_out_loss: 0.0354 - value_out_mean_squared_error: 0.0356 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0245 - val_loss: 0.0872 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0281\n",
      "Epoch 83/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0280 - loss: 0.0972 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0348 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0871 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 84/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0284 - loss: 0.0973 - value_out_loss: 0.0349 - value_out_mean_squared_error: 0.0351 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0874 - val_value_out_loss: 0.0289 - val_value_out_mean_squared_error: 0.0289\n",
      "Epoch 85/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0281 - loss: 0.0966 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.0861 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0281\n",
      "Epoch 86/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0286 - loss: 0.0961 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0347 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0256 - val_loss: 0.0871 - val_value_out_loss: 0.0286 - val_value_out_mean_squared_error: 0.0287\n",
      "Epoch 87/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0287 - loss: 0.0965 - value_out_loss: 0.0350 - value_out_mean_squared_error: 0.0351 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0286 - val_loss: 0.0932 - val_value_out_loss: 0.0313 - val_value_out_mean_squared_error: 0.0315\n",
      "Epoch 88/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0299 - loss: 0.1002 - value_out_loss: 0.0370 - value_out_mean_squared_error: 0.0372 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0865 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 89/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0285 - loss: 0.0981 - value_out_loss: 0.0355 - value_out_mean_squared_error: 0.0357 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.0868 - val_value_out_loss: 0.0282 - val_value_out_mean_squared_error: 0.0282\n",
      "Epoch 90/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0282 - loss: 0.0963 - value_out_loss: 0.0351 - value_out_mean_squared_error: 0.0351 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0874 - val_value_out_loss: 0.0300 - val_value_out_mean_squared_error: 0.0301\n",
      "Epoch 91/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0282 - loss: 0.0942 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0347 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0252 - val_loss: 0.0839 - val_value_out_loss: 0.0281 - val_value_out_mean_squared_error: 0.0282\n",
      "Epoch 92/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0283 - loss: 0.0935 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0257 - val_loss: 0.0844 - val_value_out_loss: 0.0284 - val_value_out_mean_squared_error: 0.0283\n",
      "Epoch 93/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0283 - loss: 0.0935 - value_out_loss: 0.0347 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.0834 - val_value_out_loss: 0.0281 - val_value_out_mean_squared_error: 0.0282\n",
      "Epoch 94/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0288 - loss: 0.0946 - value_out_loss: 0.0352 - value_out_mean_squared_error: 0.0353 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0246 - val_loss: 0.0827 - val_value_out_loss: 0.0276 - val_value_out_mean_squared_error: 0.0276\n",
      "Epoch 95/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0282 - loss: 0.0930 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0248 - val_loss: 0.0823 - val_value_out_loss: 0.0278 - val_value_out_mean_squared_error: 0.0278\n",
      "Epoch 96/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0283 - loss: 0.0919 - value_out_loss: 0.0344 - value_out_mean_squared_error: 0.0345 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0256 - val_loss: 0.0831 - val_value_out_loss: 0.0285 - val_value_out_mean_squared_error: 0.0285\n",
      "Epoch 97/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0035 - exists_out_loss: 0.0286 - loss: 0.0923 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0349 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.0818 - val_value_out_loss: 0.0279 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 98/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0280 - loss: 0.0914 - value_out_loss: 0.0344 - value_out_mean_squared_error: 0.0344 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0848 - val_value_out_loss: 0.0302 - val_value_out_mean_squared_error: 0.0303\n",
      "Epoch 99/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0286 - loss: 0.0924 - value_out_loss: 0.0348 - value_out_mean_squared_error: 0.0348 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.0826 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0281\n",
      "Epoch 100/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0024 - exists_out_loss: 0.0284 - loss: 0.0919 - value_out_loss: 0.0345 - value_out_mean_squared_error: 0.0346 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0249 - val_loss: 0.0815 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0279\n",
      "Epoch 101/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0282 - loss: 0.0913 - value_out_loss: 0.0343 - value_out_mean_squared_error: 0.0343 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0247 - val_loss: 0.0814 - val_value_out_loss: 0.0276 - val_value_out_mean_squared_error: 0.0276\n",
      "Epoch 102/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0280 - loss: 0.0912 - value_out_loss: 0.0340 - value_out_mean_squared_error: 0.0341 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0254 - val_loss: 0.0824 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0280\n",
      "Epoch 103/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - exists_out_accuracy: 0.0012 - exists_out_loss: 0.0301 - loss: 0.0951 - value_out_loss: 0.0360 - value_out_mean_squared_error: 0.0362 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0251 - val_loss: 0.0847 - val_value_out_loss: 0.0309 - val_value_out_mean_squared_error: 0.0308\n",
      "Epoch 104/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - exists_out_accuracy: 0.0047 - exists_out_loss: 0.0293 - loss: 0.0952 - value_out_loss: 0.0368 - value_out_mean_squared_error: 0.0370 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0253 - val_loss: 0.0866 - val_value_out_loss: 0.0320 - val_value_out_mean_squared_error: 0.0321\n",
      "Epoch 105/400\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - exists_out_accuracy: 0.0000e+00 - exists_out_loss: 0.0286 - loss: 0.0939 - value_out_loss: 0.0358 - value_out_mean_squared_error: 0.0360 - val_exists_out_accuracy: 0.0000e+00 - val_exists_out_loss: 0.0245 - val_loss: 0.0823 - val_value_out_loss: 0.0280 - val_value_out_mean_squared_error: 0.0281\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        # (optional) sanity check the output order\n",
    "        print(\"Output order:\", model.output_names)  # e.g. ['value_out', 'exists_out']\n",
    "        \n",
    "        # --- make value_out sample weights 1D so it matches loss shape [N] ---\n",
    "        value_sw_train = np.asarray(y_exists_train).astype(\"float32\")\n",
    "        value_sw_val   = np.asarray(y_exists_val).astype(\"float32\")\n",
    "        \n",
    "        # If y_exists is (N,16), collapse to (N,)\n",
    "        if value_sw_train.ndim == 2:\n",
    "            value_sw_train = value_sw_train.max(axis=1)   # or .mean(axis=1)\n",
    "        if value_sw_val.ndim == 2:\n",
    "            value_sw_val = value_sw_val.max(axis=1)       # or .mean(axis=1)\n",
    "        \n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            [np.asarray(y_value_train), np.asarray(y_exists_train)],\n",
    "            sample_weight=[\n",
    "                value_sw_train,                                     # NOW (N,)\n",
    "                np.ones((len(y_exists_train),), dtype=\"float32\"),\n",
    "            ],\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                [np.asarray(y_value_val), np.asarray(y_exists_val)],\n",
    "                [\n",
    "                    value_sw_val,                                   # NOW (N,)\n",
    "                    np.ones((len(y_exists_val),), dtype=\"float32\"),\n",
    "                ],\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping, lr_monitor],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_learning_rate.pdf')\n",
    "    plt.show()\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp_linear = tuner_linear_encoding.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model_linear = tuner_linear_encoding.hypermodel.build(best_hp_linear)\n",
    "\n",
    "        lr_monitor_linear_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        history_linear_encoding = model_linear.fit(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping, lr_monitor_linear_encoding],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model_linear\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    plt.plot(history_linear_encoding.history['loss'])\n",
    "    plt.plot(history_linear_encoding.history['val_loss'])\n",
    "    plt.title('Model loss linear encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor_linear_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs linear encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47150b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I needed to restart the kernal and skip the block above to run this block-otherwise i got memory allocation error. \n",
    "#theres probably a better way to do this--like clearing the memory before running this block so you can run both models sequentially\n",
    "\n",
    "if 'Try Both' in ENCODING_TYPE and KERAS_TUNER:\n",
    "    best_hp_onehot = tuner_one_hot_encoding.get_best_hyperparameters(1)[0]\n",
    "    model_onehot = tuner_one_hot_encoding.hypermodel.build(best_hp_onehot)\n",
    "\n",
    "    lr_monitor_one_hot_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "    \n",
    "    history_one_hot_encoding = model_onehot.fit(\n",
    "        np.asarray(X_train_one_hot_encoding),\n",
    "        {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "        callbacks=[early_stopping, lr_monitor_one_hot_encoding],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    plt.plot(history_one_hot_encoding.history['loss'])\n",
    "    plt.plot(history_one_hot_encoding.history['val_loss'])\n",
    "    plt.title('Model loss one hot encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_history.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(lr_monitor_one_hot_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs one hot encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a331d8-70ea-4ea4-8f5b-256472850784",
   "metadata": {},
   "source": [
    "Measure and print metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32ff7d16-5709-41d6-b3f7-e6c9a062b35c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss one_hot encoding mae: 0.1299285739660263\n",
      "   Encoding Type Train Loss Metric  Test Loss\n",
      "one hot Encoding               mae   0.129929\n"
     ]
    }
   ],
   "source": [
    "#take a look at the loss results and save them \n",
    "\n",
    "# clear everything so we start with a blank slate memory wise\n",
    "tf.keras.backend.clear_session()                         #clear tf backend\n",
    "gc.collect()                                             #just collect stray things\n",
    "#tf.config.experimental.reset_memory_stats('GPU:0')       #clear gpus\n",
    "\n",
    "\n",
    "def get_loss(eval_out):\n",
    "    # eval_out can be float, list/tuple/ndarray, or dict\n",
    "    if isinstance(eval_out, dict):\n",
    "        return float(eval_out.get('loss', list(eval_out.values())[0]))\n",
    "    if isinstance(eval_out, (list, tuple, np.ndarray)):\n",
    "        return float(eval_out[0])\n",
    "    return float(eval_out)\n",
    "\n",
    "def mlp_signature(m, prefix=\"mlp\"):\n",
    "    #get the model input sizze first\n",
    "    in_shape = m.input_shape\n",
    "    if isinstance(in_shape, list):     #just get the first one\n",
    "        in_shape = in_shape[0]\n",
    "    dims = [d for d in in_shape[1:] if d is not None]\n",
    "    input_size = int(np.prod(dims)) if dims else \"None\"\n",
    "\n",
    "    # now get the dense laysers in order\n",
    "    dense_units = [l.units for l in m.layers if isinstance(l, Dense)]\n",
    "\n",
    "    parts = [prefix, str(input_size)] + [str(u) for u in dense_units]\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "    \n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    model = load_model(best_model_file, compile=False)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result = model.evaluate(\n",
    "        np.asarray(X_test),\n",
    "        {'value_out': np.asarray(y_value_test), 'exists_out': np.asarray(y_exists_test)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result = get_loss(test_loss_result)\n",
    "    \n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape = mlp_signature(model)\n",
    "\n",
    "    print('Current loss {} encoding {}: {}'.format(encoding, TRAIN_LOSS, test_loss_result))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': f'{ENCODING_TYPE} Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result},\n",
    "        ])\n",
    "\n",
    "else:\n",
    "    # we need to do some fancy allocation of recources if we are going to load both models\n",
    "    # do the first on one GPU\n",
    "    linear_model = load_model(best_model_file_linear, compile=False)\n",
    "    linear_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result_linear_encoding = linear_model.evaluate(\n",
    "        np.asarray(X_test_linear_encoding),\n",
    "        {'value_out': np.asarray(y_value_test_linear_encoding), 'exists_out': np.asarray(y_exists_test_linear_encoding)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result_linear_encoding = get_loss(test_loss_result_linear_encoding)\n",
    "    \n",
    "    # now do on CPU to avoid GPU allocation\n",
    "    with tf.device('/GPU:0'):\n",
    "        onehot_model = load_model(best_model_file_onehot, compile=False)\n",
    "        onehot_model.compile(\n",
    "            optimizer='adam',\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = onehot_model.evaluate(\n",
    "            np.asarray(X_test_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_test_one_hot_encoding), 'exists_out': np.asarray(y_exists_test_one_hot_encoding)},\n",
    "            verbose=0\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = get_loss(test_loss_result_one_hot_encoding)\n",
    "\n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape_one_hot_encoding = mlp_signature(onehot_model)\n",
    "    model_shape_linear_encoding  = mlp_signature(linear_model)\n",
    "    \n",
    "    print('Current loss linear encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_linear_encoding))\n",
    "    print('Current loss one hot encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_one_hot_encoding))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': 'linear Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_linear_encoding},\n",
    "        {'Encoding Type': 'One Hot Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_one_hot_encoding}\n",
    "    ])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv('test_loss_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7812af-2596-44d2-bb25-68741e0506ba",
   "metadata": {},
   "source": [
    "## Compare predictions vs. test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60157266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92858_row0_col3, #T_92858_row1_col3, #T_92858_row2_col3, #T_92858_row3_col3, #T_92858_row4_col3, #T_92858_row5_col3, #T_92858_row6_col3, #T_92858_row7_col3, #T_92858_row8_col3, #T_92858_row9_col3, #T_92858_row10_col3 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92858\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92858_level0_col0\" class=\"col_heading level0 col0\" >data_augmentation</th>\n",
       "      <th id=\"T_92858_level0_col1\" class=\"col_heading level0 col1\" >model_shape</th>\n",
       "      <th id=\"T_92858_level0_col2\" class=\"col_heading level0 col2\" >encoding_type</th>\n",
       "      <th id=\"T_92858_level0_col3\" class=\"col_heading level0 col3\" >test_loss</th>\n",
       "      <th id=\"T_92858_level0_col4\" class=\"col_heading level0 col4\" >train_loss</th>\n",
       "      <th id=\"T_92858_level0_col5\" class=\"col_heading level0 col5\" >train_dropout_rate</th>\n",
       "      <th id=\"T_92858_level0_col6\" class=\"col_heading level0 col6\" >train_early_stop_patience</th>\n",
       "      <th id=\"T_92858_level0_col7\" class=\"col_heading level0 col7\" >train_batch_size</th>\n",
       "      <th id=\"T_92858_level0_col8\" class=\"col_heading level0 col8\" >train_val_split</th>\n",
       "      <th id=\"T_92858_level0_col9\" class=\"col_heading level0 col9\" >lr_initial</th>\n",
       "      <th id=\"T_92858_level0_col10\" class=\"col_heading level0 col10\" >lr_decay_step</th>\n",
       "      <th id=\"T_92858_level0_col11\" class=\"col_heading level0 col11\" >lr_decay_rate</th>\n",
       "      <th id=\"T_92858_level0_col12\" class=\"col_heading level0 col12\" >lr_stair_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_92858_row0_col0\" class=\"data row0 col0\" >True</td>\n",
       "      <td id=\"T_92858_row0_col1\" class=\"data row0 col1\" >mlp_2_1500_2800_1300_2100_45</td>\n",
       "      <td id=\"T_92858_row0_col2\" class=\"data row0 col2\" >One Hot</td>\n",
       "      <td id=\"T_92858_row0_col3\" class=\"data row0 col3\" >0.026580</td>\n",
       "      <td id=\"T_92858_row0_col4\" class=\"data row0 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row0_col5\" class=\"data row0 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row0_col6\" class=\"data row0 col6\" >50</td>\n",
       "      <td id=\"T_92858_row0_col7\" class=\"data row0 col7\" >32</td>\n",
       "      <td id=\"T_92858_row0_col8\" class=\"data row0 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row0_col9\" class=\"data row0 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row0_col10\" class=\"data row0 col10\" >100</td>\n",
       "      <td id=\"T_92858_row0_col11\" class=\"data row0 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row0_col12\" class=\"data row0 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_92858_row1_col0\" class=\"data row1 col0\" >True</td>\n",
       "      <td id=\"T_92858_row1_col1\" class=\"data row1 col1\" >mlp_2_600_100_2600_5000_45</td>\n",
       "      <td id=\"T_92858_row1_col2\" class=\"data row1 col2\" >Linear</td>\n",
       "      <td id=\"T_92858_row1_col3\" class=\"data row1 col3\" >0.027197</td>\n",
       "      <td id=\"T_92858_row1_col4\" class=\"data row1 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row1_col5\" class=\"data row1 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row1_col6\" class=\"data row1 col6\" >50</td>\n",
       "      <td id=\"T_92858_row1_col7\" class=\"data row1 col7\" >32</td>\n",
       "      <td id=\"T_92858_row1_col8\" class=\"data row1 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row1_col9\" class=\"data row1 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row1_col10\" class=\"data row1 col10\" >100</td>\n",
       "      <td id=\"T_92858_row1_col11\" class=\"data row1 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row1_col12\" class=\"data row1 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_92858_row2_col0\" class=\"data row2 col0\" >True</td>\n",
       "      <td id=\"T_92858_row2_col1\" class=\"data row2 col1\" >mlp_2_1500_2800_1300_2100_45</td>\n",
       "      <td id=\"T_92858_row2_col2\" class=\"data row2 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row2_col3\" class=\"data row2 col3\" >0.026581</td>\n",
       "      <td id=\"T_92858_row2_col4\" class=\"data row2 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row2_col5\" class=\"data row2 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row2_col6\" class=\"data row2 col6\" >50</td>\n",
       "      <td id=\"T_92858_row2_col7\" class=\"data row2 col7\" >32</td>\n",
       "      <td id=\"T_92858_row2_col8\" class=\"data row2 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row2_col9\" class=\"data row2 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row2_col10\" class=\"data row2 col10\" >100</td>\n",
       "      <td id=\"T_92858_row2_col11\" class=\"data row2 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row2_col12\" class=\"data row2 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_92858_row3_col0\" class=\"data row3 col0\" >True</td>\n",
       "      <td id=\"T_92858_row3_col1\" class=\"data row3 col1\" >mlp_2_3300_200_4600_1700_45</td>\n",
       "      <td id=\"T_92858_row3_col2\" class=\"data row3 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row3_col3\" class=\"data row3 col3\" >0.023184</td>\n",
       "      <td id=\"T_92858_row3_col4\" class=\"data row3 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row3_col5\" class=\"data row3 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row3_col6\" class=\"data row3 col6\" >50</td>\n",
       "      <td id=\"T_92858_row3_col7\" class=\"data row3 col7\" >32</td>\n",
       "      <td id=\"T_92858_row3_col8\" class=\"data row3 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row3_col9\" class=\"data row3 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row3_col10\" class=\"data row3 col10\" >100</td>\n",
       "      <td id=\"T_92858_row3_col11\" class=\"data row3 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row3_col12\" class=\"data row3 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_92858_row4_col0\" class=\"data row4 col0\" >True</td>\n",
       "      <td id=\"T_92858_row4_col1\" class=\"data row4 col1\" >mlp_2_3300_200_4600_1700_45</td>\n",
       "      <td id=\"T_92858_row4_col2\" class=\"data row4 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row4_col3\" class=\"data row4 col3\" >0.023925</td>\n",
       "      <td id=\"T_92858_row4_col4\" class=\"data row4 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row4_col5\" class=\"data row4 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row4_col6\" class=\"data row4 col6\" >50</td>\n",
       "      <td id=\"T_92858_row4_col7\" class=\"data row4 col7\" >32</td>\n",
       "      <td id=\"T_92858_row4_col8\" class=\"data row4 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row4_col9\" class=\"data row4 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row4_col10\" class=\"data row4 col10\" >100</td>\n",
       "      <td id=\"T_92858_row4_col11\" class=\"data row4 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row4_col12\" class=\"data row4 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_92858_row5_col0\" class=\"data row5 col0\" >True</td>\n",
       "      <td id=\"T_92858_row5_col1\" class=\"data row5 col1\" >mlp_2_700_3800_400_1800_16</td>\n",
       "      <td id=\"T_92858_row5_col2\" class=\"data row5 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row5_col3\" class=\"data row5 col3\" >0.045630</td>\n",
       "      <td id=\"T_92858_row5_col4\" class=\"data row5 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row5_col5\" class=\"data row5 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row5_col6\" class=\"data row5 col6\" >50</td>\n",
       "      <td id=\"T_92858_row5_col7\" class=\"data row5 col7\" >32</td>\n",
       "      <td id=\"T_92858_row5_col8\" class=\"data row5 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row5_col9\" class=\"data row5 col9\" >0.001456</td>\n",
       "      <td id=\"T_92858_row5_col10\" class=\"data row5 col10\" >100</td>\n",
       "      <td id=\"T_92858_row5_col11\" class=\"data row5 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row5_col12\" class=\"data row5 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_92858_row6_col0\" class=\"data row6 col0\" >True</td>\n",
       "      <td id=\"T_92858_row6_col1\" class=\"data row6 col1\" >mlp_2_700_3800_400_1800_16</td>\n",
       "      <td id=\"T_92858_row6_col2\" class=\"data row6 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row6_col3\" class=\"data row6 col3\" >0.041409</td>\n",
       "      <td id=\"T_92858_row6_col4\" class=\"data row6 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row6_col5\" class=\"data row6 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row6_col6\" class=\"data row6 col6\" >50</td>\n",
       "      <td id=\"T_92858_row6_col7\" class=\"data row6 col7\" >32</td>\n",
       "      <td id=\"T_92858_row6_col8\" class=\"data row6 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row6_col9\" class=\"data row6 col9\" >0.002648</td>\n",
       "      <td id=\"T_92858_row6_col10\" class=\"data row6 col10\" >100</td>\n",
       "      <td id=\"T_92858_row6_col11\" class=\"data row6 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row6_col12\" class=\"data row6 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_92858_row7_col0\" class=\"data row7 col0\" >True</td>\n",
       "      <td id=\"T_92858_row7_col1\" class=\"data row7 col1\" >mlp_2_2000_400_1300_1700_16_16</td>\n",
       "      <td id=\"T_92858_row7_col2\" class=\"data row7 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row7_col3\" class=\"data row7 col3\" >0.087074</td>\n",
       "      <td id=\"T_92858_row7_col4\" class=\"data row7 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row7_col5\" class=\"data row7 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row7_col6\" class=\"data row7 col6\" >50</td>\n",
       "      <td id=\"T_92858_row7_col7\" class=\"data row7 col7\" >32</td>\n",
       "      <td id=\"T_92858_row7_col8\" class=\"data row7 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row7_col9\" class=\"data row7 col9\" >0.002648</td>\n",
       "      <td id=\"T_92858_row7_col10\" class=\"data row7 col10\" >100</td>\n",
       "      <td id=\"T_92858_row7_col11\" class=\"data row7 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row7_col12\" class=\"data row7 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_92858_row8_col0\" class=\"data row8 col0\" >True</td>\n",
       "      <td id=\"T_92858_row8_col1\" class=\"data row8 col1\" >mlp_2_2000_400_1300_1700_16_16</td>\n",
       "      <td id=\"T_92858_row8_col2\" class=\"data row8 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row8_col3\" class=\"data row8 col3\" >0.080590</td>\n",
       "      <td id=\"T_92858_row8_col4\" class=\"data row8 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row8_col5\" class=\"data row8 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row8_col6\" class=\"data row8 col6\" >50</td>\n",
       "      <td id=\"T_92858_row8_col7\" class=\"data row8 col7\" >32</td>\n",
       "      <td id=\"T_92858_row8_col8\" class=\"data row8 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row8_col9\" class=\"data row8 col9\" >0.002505</td>\n",
       "      <td id=\"T_92858_row8_col10\" class=\"data row8 col10\" >100</td>\n",
       "      <td id=\"T_92858_row8_col11\" class=\"data row8 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row8_col12\" class=\"data row8 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_92858_row9_col0\" class=\"data row9 col0\" >True</td>\n",
       "      <td id=\"T_92858_row9_col1\" class=\"data row9 col1\" >mlp_2_2000_2700_500_4000_16_16</td>\n",
       "      <td id=\"T_92858_row9_col2\" class=\"data row9 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row9_col3\" class=\"data row9 col3\" >0.086770</td>\n",
       "      <td id=\"T_92858_row9_col4\" class=\"data row9 col4\" >mean_squared_error</td>\n",
       "      <td id=\"T_92858_row9_col5\" class=\"data row9 col5\" >0.400000</td>\n",
       "      <td id=\"T_92858_row9_col6\" class=\"data row9 col6\" >50</td>\n",
       "      <td id=\"T_92858_row9_col7\" class=\"data row9 col7\" >32</td>\n",
       "      <td id=\"T_92858_row9_col8\" class=\"data row9 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row9_col9\" class=\"data row9 col9\" >0.002505</td>\n",
       "      <td id=\"T_92858_row9_col10\" class=\"data row9 col10\" >100</td>\n",
       "      <td id=\"T_92858_row9_col11\" class=\"data row9 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row9_col12\" class=\"data row9 col12\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92858_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_92858_row10_col0\" class=\"data row10 col0\" >True</td>\n",
       "      <td id=\"T_92858_row10_col1\" class=\"data row10 col1\" >mlp_2_640_550_850_550_1410_16_16</td>\n",
       "      <td id=\"T_92858_row10_col2\" class=\"data row10 col2\" >one hot</td>\n",
       "      <td id=\"T_92858_row10_col3\" class=\"data row10 col3\" >0.129929</td>\n",
       "      <td id=\"T_92858_row10_col4\" class=\"data row10 col4\" >mae</td>\n",
       "      <td id=\"T_92858_row10_col5\" class=\"data row10 col5\" >0.000000</td>\n",
       "      <td id=\"T_92858_row10_col6\" class=\"data row10 col6\" >60</td>\n",
       "      <td id=\"T_92858_row10_col7\" class=\"data row10 col7\" >128</td>\n",
       "      <td id=\"T_92858_row10_col8\" class=\"data row10 col8\" >0.15/0.15</td>\n",
       "      <td id=\"T_92858_row10_col9\" class=\"data row10 col9\" >0.000982</td>\n",
       "      <td id=\"T_92858_row10_col10\" class=\"data row10 col10\" >140</td>\n",
       "      <td id=\"T_92858_row10_col11\" class=\"data row10 col11\" >0.990000</td>\n",
       "      <td id=\"T_92858_row10_col12\" class=\"data row10 col12\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1188334340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape,\n",
    "        ENCODING_TYPE,\n",
    "        test_loss_result,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df = df.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "\n",
    "else:\n",
    "    #---------------------------------------------------one hot---------------------------------------\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_one_hot_encoding,\n",
    "        'One Hot',\n",
    "        test_loss_result_one_hot_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "            \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_one_hot_encoding = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_one_hot_encoding = df_one_hot_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    #---------------------------------------------------linear---------------------------------------\n",
    "    csv_data_linear_encoding = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_linear_encoding,\n",
    "        'linear',\n",
    "        test_loss_result_linear_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file_linear_encoding = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    with open(csv_file_linear_encoding, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data_linear_encoding)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_linear_encoding = pd.read_csv(csv_file_linear_encoding)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_linear_encoding = df_linear_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df_linear_encoding)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ea88851-ed24-42d4-b36c-e79175af6847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decide which model file & test set to use\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    chosen_path = best_model_file\n",
    "    X_test_cur = np.asarray(X_test)\n",
    "    y_value_test_cur = np.asarray(y_value_test)\n",
    "    y_exists_test_cur = np.asarray(y_exists_test)\n",
    "else:\n",
    "    if test_loss_result_linear_encoding < test_loss_result_one_hot_encoding:\n",
    "        chosen_path = best_model_file_linear\n",
    "        X_test_cur = np.asarray(X_test_linear_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_linear_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_linear_encoding)\n",
    "        y_encoding_format_name = 'linear'\n",
    "    else:\n",
    "        chosen_path = best_model_file_onehot\n",
    "        X_test_cur = np.asarray(X_test_one_hot_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_one_hot_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_one_hot_encoding)\n",
    "        y_encoding_format_name = 'one_hot'\n",
    "\n",
    "# clear everything again, then load & predict on one cpu device to avoid the memory thing again\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    chosen_model = load_model(chosen_path, compile=False)\n",
    "    pred = chosen_model.predict(X_test_cur, verbose=0)\n",
    "\n",
    "# Unpack model outputs into proper numeric arrays\n",
    "if isinstance(pred, dict):\n",
    "    y_value_pred = np.asarray(pred['value_out'])\n",
    "    y_exists_pred = np.asarray(pred['exists_out'])\n",
    "else:\n",
    "    y_value_pred, y_exists_pred = pred\n",
    "    y_value_pred = np.asarray(y_value_pred)\n",
    "    y_exists_pred = np.asarray(y_exists_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6ffa127-c6a4-4a52-8a29-4c08ae0cca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_one_hot.csv\n",
      "\n",
      " Sample 0  X: cavity_frequency=0.0208384, kappa=0.16982\n",
      "                                                          param  exists      ref      pred  abs_error  sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.403941  0.420213   0.016272  0.000265\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000  0.097638   0.097638  0.009533\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000 -0.002075   0.002075  0.000004\n",
      "                          design_options.claw_opts.cross_length     1.0 0.000000 -0.008900   0.008900  0.000079\n",
      "                           design_options.claw_opts.cross_width     1.0 0.000000 -0.009580   0.009580  0.000092\n",
      "                             design_options.claw_opts.cross_gap     1.0 0.000000 -0.009350   0.009350  0.000087\n",
      "                           design_options.cpw_opts.total_length     1.0 0.428571  0.329074   0.099497  0.009900\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.724063   0.275937  0.076141\n",
      "                      design_options.cpw_opts.meander.asymmetry     1.0 0.956522  0.722798   0.233724  0.054627\n",
      "                       design_options.cplr_opts.coupling_length     1.0 0.700000  0.561749   0.138251  0.019113\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 1.000000  0.728904   0.271096  0.073493\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000  0.000643        NaN       NaN\n",
      "                                               coupler_type_CLT     1.0 1.000000  1.011920   0.011920  0.000142\n",
      "                                              coupler_type_NCap     1.0 0.000000 -0.009432   0.009432  0.000089\n",
      "                                            resonator_type_half     1.0 0.000000 -0.008767   0.008767  0.000077\n",
      "                                         resonator_type_quarter     1.0 1.000000  1.012665   0.012665  0.000160\n",
      "\n",
      " Sample 1  X: cavity_frequency=0.147811, kappa=0.00035887\n",
      "                                                          param  exists      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.236453  0.137109   0.099344 9.869286e-03\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000 -0.000495   0.000495 2.449658e-07\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000 -0.034733   0.034733 1.206358e-03\n",
      "                          design_options.claw_opts.cross_length     1.0 1.000000  0.988958   0.011042 1.219244e-04\n",
      "                           design_options.claw_opts.cross_width     1.0 1.000000  0.987411   0.012589 1.584944e-04\n",
      "                             design_options.claw_opts.cross_gap     1.0 1.000000  0.988160   0.011840 1.401810e-04\n",
      "                           design_options.cpw_opts.total_length     1.0 0.714286  0.675717   0.038569 1.487560e-03\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.982249   0.017751 3.150845e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0 0.652174  0.652069        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0 0.000000 -0.004198        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 0.500000  0.490310   0.009690 9.390104e-05\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000  0.000774        NaN          NaN\n",
      "                                               coupler_type_CLT     1.0 0.000000  0.013691   0.013691 1.874382e-04\n",
      "                                              coupler_type_NCap     1.0 1.000000  0.987152   0.012848 1.650747e-04\n",
      "                                            resonator_type_half     1.0 1.000000  0.987716   0.012284 1.508976e-04\n",
      "                                         resonator_type_quarter     1.0 0.000000  0.014400   0.014400 2.073516e-04\n",
      "\n",
      " Sample 2  X: cavity_frequency=0.255023, kappa=0.00060377\n",
      "                                                          param  exists      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0 0.019704  0.136913   0.117209 1.373783e-02\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0 0.000000 -0.000047   0.000047 2.205336e-09\n",
      "                                 design_options.claw_opts.pos_x     1.0 0.000000  0.054205   0.054205 2.938218e-03\n",
      "                          design_options.claw_opts.cross_length     1.0 1.000000  0.996795   0.003205 1.027433e-05\n",
      "                           design_options.claw_opts.cross_width     1.0 1.000000  0.995077   0.004923 2.423227e-05\n",
      "                             design_options.claw_opts.cross_gap     1.0 1.000000  0.995468   0.004532 2.054046e-05\n",
      "                           design_options.cpw_opts.total_length     1.0 0.500000  0.573093   0.073093 5.342517e-03\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0 1.000000  0.987086   0.012914 1.667699e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0 0.652174  0.651396        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0 0.000000 -0.006933        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0 0.500000  0.490916   0.009084 8.252206e-05\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0 0.000000  0.000401        NaN          NaN\n",
      "                                               coupler_type_CLT     1.0 0.000000  0.005688   0.005688 3.235822e-05\n",
      "                                              coupler_type_NCap     1.0 1.000000  0.994758   0.005242 2.747846e-05\n",
      "                                            resonator_type_half     1.0 1.000000  0.995757   0.004243 1.800218e-05\n",
      "                                         resonator_type_quarter     1.0 0.000000  0.005551   0.005551 3.081570e-05\n",
      "\n",
      "Global error stats (defined parameters only):\n",
      "  min abs_error: 1.735985279083252e-06\n",
      "  median abs_error: 0.01372167095541954\n",
      "  max abs_error: 0.911139316856861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nHere onehot/linear encoding and the mlp which maps categorical data to 1s and 0s is probably \\nthrowing off the global average. These will be rounded in the future and will probably always \\nround to the right number to reconstruct the correct category-- but for now it might throw off \\nthe overall average error. In the future we might want to just have it consider the non categorical \\ndata when finding an overall average and reporting that number.\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets look at a specfic case to see how the model predicts things\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    y_encoding_format_name = encoding\n",
    "    \n",
    "filename = f'y_characteristics_{y_encoding_format_name}_encoding.csv'\n",
    "with open(filename, 'r') as f:\n",
    "    headers = f.readline().strip().split(',')\n",
    "\n",
    "X_test_cur = np.asarray(X_test_cur)\n",
    "y_value_test_cur = np.asarray(y_value_test_cur)\n",
    "y_exists_test_cur = np.asarray(y_exists_test_cur)\n",
    "y_value_pred = np.asarray(y_value_pred)\n",
    "\n",
    "n_samples, n_params = y_value_test_cur.shape\n",
    "#change nsamples if you dont want to look at everything\n",
    "n_samples = 3\n",
    "\n",
    "# raw errors\n",
    "sq_errors = (y_value_test_cur - y_value_pred) ** 2\n",
    "abs_errors = np.abs(y_value_test_cur - y_value_pred)\n",
    "\n",
    "# mask out parameters that are \"not defined\" according to the ground-truth exists flag\n",
    "sq_errors_masked = np.where(y_exists_test_cur == 1.0, sq_errors, np.nan)\n",
    "abs_errors_masked = np.where(y_exists_test_cur == 1.0, abs_errors, np.nan)\n",
    "\n",
    "# make a nice dataframe so the output is comprehensible\n",
    "rows = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_cur[i, 0], X_test_cur[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref\": y_value_test_cur[i, j],\n",
    "            \"pred\": y_value_pred[i, j],\n",
    "            \"abs_error\": abs_errors_masked[i, j],\n",
    "            \"sq_error\": sq_errors_masked[i, j],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "#save it incase we want to do stuff with this in the future\n",
    "out_csv = Path(f\"predictions_and_errors_{y_encoding_format_name}.csv\")\n",
    "df.to_csv(out_csv, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv.resolve()}\\n\")\n",
    "\n",
    "# print it out nicely \n",
    "for i in range(n_samples):\n",
    "    sub = df[df[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref\", \"pred\", \"abs_error\", \"sq_error\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i}  \"\n",
    "        f\"X: cavity_frequency={X_test_cur[i,0]:.6g}, kappa={X_test_cur[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print() \n",
    "\n",
    "# (Optional) quick global stats (only over defined parameters)\n",
    "print(\"Global error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_masked)))\n",
    "\n",
    "''' \n",
    "Here onehot/linear encoding and the mlp which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304c67f-9838-491f-869c-e51d86748217",
   "metadata": {},
   "source": [
    "### Unscaled test vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e05f774-e63a-4325-86eb-c091a1c286d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_unscaled_one_hot.csv\n",
      "\n",
      " Sample 0 (Unscaled)  X: cavity_frequency=5.24699e+09, kappa=168252\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000275   2.832581e-04        8.258065e-06       6.819564e-11\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004   4.676063e-06        5.760633e-07       3.318490e-13\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500  -1.501037e-03        1.037274e-06       1.075936e-12\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000000  -2.136069e-06        2.136069e-06       4.562792e-12\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000000  -2.874005e-07        2.874005e-07       8.259905e-14\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000000  -2.805008e-07        2.805008e-07       7.868072e-14\n",
      "                           design_options.cpw_opts.total_length     1.0      0.004700   4.003518e-03        6.964822e-04       4.850875e-07\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100   8.620317e-05        1.379683e-05       1.903526e-10\n",
      "                      design_options.cpw_opts.meander.asymmetry     1.0      0.000117   2.707263e-05        8.959404e-05       8.027091e-09\n",
      "                       design_options.cplr_opts.coupling_length     1.0      0.000350   2.808745e-04        6.912551e-05       4.778336e-09\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000100   7.289043e-05        2.710957e-05       7.349286e-10\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000   6.429715e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      1.000000   1.011920e+00        1.192021e-02       1.420915e-04\n",
      "                                              coupler_type_NCap     1.0      0.000000  -9.431619e-03        9.431619e-03       8.895544e-05\n",
      "                                            resonator_type_half     1.0      0.000000  -8.767258e-03        8.767258e-03       7.686482e-05\n",
      "                                         resonator_type_quarter     1.0      1.000000   1.012665e+00        1.266479e-02       1.603970e-04\n",
      "\n",
      " Sample 1 (Unscaled)  X: cavity_frequency=8.36575e+09, kappa=768.707\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000190   1.395828e-04        5.041723e-05       2.541897e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004   4.097080e-06        2.920091e-09       8.526931e-18\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500  -1.517366e-03        1.736639e-05       3.015913e-10\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000240   2.373499e-04        2.650070e-06       7.022870e-12\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000030   2.962232e-05        3.776830e-07       1.426444e-13\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000030   2.964481e-05        3.551948e-07       1.261634e-13\n",
      "                           design_options.cpw_opts.total_length     1.0      0.006700   6.430018e-03        2.699822e-04       7.289041e-08\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100   9.911247e-05        8.875311e-07       7.877115e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0      0.000000  -4.009009e-08                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0      0.000000  -2.099097e-06                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000050   4.903098e-05        9.690242e-07       9.390079e-13\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000   7.739811e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      0.000000   1.369081e-02        1.369081e-02       1.874382e-04\n",
      "                                              coupler_type_NCap     1.0      1.000000   9.871519e-01        1.284814e-02       1.650747e-04\n",
      "                                            resonator_type_half     1.0      1.000000   9.877160e-01        1.228404e-02       1.508976e-04\n",
      "                                         resonator_type_quarter     1.0      0.000000   1.439971e-02        1.439971e-02       2.073516e-04\n",
      "\n",
      " Sample 2 (Unscaled)  X: cavity_frequency=1.09991e+10, kappa=1010.75\n",
      "                                                          param  exists  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length     1.0      0.000080   1.394833e-04        5.948332e-05       3.538266e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing     1.0      0.000004   4.099723e-06        2.770993e-10       7.678401e-20\n",
      "                                 design_options.claw_opts.pos_x     1.0     -0.001500  -1.472897e-03        2.710264e-05       7.345530e-10\n",
      "                          design_options.claw_opts.cross_length     1.0      0.000240   2.392307e-04        7.692931e-07       5.918118e-13\n",
      "                           design_options.claw_opts.cross_width     1.0      0.000030   2.985232e-05        1.476791e-07       2.180910e-14\n",
      "                             design_options.claw_opts.cross_gap     1.0      0.000030   2.986404e-05        1.359648e-07       1.848642e-14\n",
      "                           design_options.cpw_opts.total_length     1.0      0.005200   5.711648e-03        5.116477e-04       2.617834e-07\n",
      "                    design_options.cpw_opts.lead.start_straight     1.0      0.000100   9.935430e-05        6.457001e-07       4.169286e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry     0.0      0.000000  -2.981633e-07                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length     0.0      0.000000  -3.466586e-06                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight     1.0      0.000050   4.909158e-05        9.084155e-07       8.252187e-13\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0     0.0      0.000000   4.006353e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT     1.0      0.000000   5.688429e-03        5.688429e-03       3.235822e-05\n",
      "                                              coupler_type_NCap     1.0      1.000000   9.947580e-01        5.241990e-03       2.747846e-05\n",
      "                                            resonator_type_half     1.0      1.000000   9.957571e-01        4.242897e-03       1.800218e-05\n",
      "                                         resonator_type_quarter     1.0      0.000000   5.551189e-03        5.551189e-03       3.081570e-05\n",
      "\n",
      "Global unscaled error stats (defined parameters only):\n",
      "  min abs_error: 5.563732120179301e-11\n",
      "  median abs_error: 3.5888357792282475e-05\n",
      "  max abs_error: 0.14548468589782715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably \\nthrowing off the global average. These will be rounded in the future and will probably always \\nround to the right number to reconstruct the correct category-- but for now it might throw off \\nthe overall average error. In the future we might want to just have it consider the non-categorical \\ndata when finding an overall average and reporting that number.\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unscale everything and look at errors again. \n",
    "#You can compare the unscaled actual values to the ml_00...py notebook to convice yourself that unscaling worked\n",
    "\n",
    "with open('X_names', 'r') as f:\n",
    "    X_index_names = f.read().splitlines()\n",
    "\n",
    "# unscaling x\n",
    "X_test_unscaled = np.asarray(X_test_cur.copy())\n",
    "for i in range(X_test_unscaled.shape[0]):\n",
    "    for j in range(X_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_X_{X_index_names[j]}.save')\n",
    "        X_test_unscaled[i, j] = scaler.inverse_transform([[X_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y (value head only)\n",
    "y_value_test_unscaled = np.asarray(y_value_test_cur.copy())\n",
    "for i in range(y_value_test_unscaled.shape[0]):\n",
    "    for j in range(y_value_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_test_unscaled[i, j] = scaler.inverse_transform([[y_value_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y predictions (value head only)\n",
    "y_value_pred_unscaled = np.asarray(y_value_pred.copy())\n",
    "for i in range(y_value_pred_unscaled.shape[0]):\n",
    "    for j in range(y_value_pred_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_pred_unscaled[i, j] = scaler.inverse_transform([[y_value_pred_unscaled[i, j]]])[0][0]\n",
    "\n",
    "n_samples, n_params = y_value_test_unscaled.shape\n",
    "n_samples = 3 \n",
    "\n",
    "# find how good or bad we did (the errors)\n",
    "sq_errors_unscaled = (y_value_test_unscaled - y_value_pred_unscaled) ** 2\n",
    "abs_errors_unscaled = np.abs(y_value_test_unscaled - y_value_pred_unscaled)\n",
    "\n",
    "# mask out parameters that are not defined according to ground-truth exists flag\n",
    "sq_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, sq_errors_unscaled, np.nan)\n",
    "abs_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, abs_errors_unscaled, np.nan)\n",
    "\n",
    "# making a nice fancy dataframe, we like fancy things\n",
    "rows_unscaled = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_unscaled[i, 0], X_test_unscaled[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows_unscaled.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref_unscaled\": y_value_test_unscaled[i, j],\n",
    "            \"pred_unscaled\": y_value_pred_unscaled[i, j],\n",
    "            \"abs_error_unscaled\": abs_errors_unscaled_masked[i, j],\n",
    "            \"sq_error_unscaled\": sq_errors_unscaled_masked[i, j],\n",
    "        })\n",
    "\n",
    "df_unscaled = pd.DataFrame(rows_unscaled)\n",
    "\n",
    "# save csv of unscaled results uncase we lose this notebook due to github blowing up, ya never know\n",
    "out_csv_unscaled = Path(f\"predictions_and_errors_unscaled_{y_encoding_format_name}.csv\")\n",
    "df_unscaled.to_csv(out_csv_unscaled, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv_unscaled.resolve()}\\n\")\n",
    "\n",
    "# print out stuff so you can see it here if you are to lazy like me to open a csv\n",
    "for i in range(n_samples):\n",
    "    sub = df_unscaled[df_unscaled[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref_unscaled\", \"pred_unscaled\", \"abs_error_unscaled\", \"sq_error_unscaled\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i} (Unscaled)  \"\n",
    "        f\"X: cavity_frequency={X_test_unscaled[i,0]:.6g}, kappa={X_test_unscaled[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# look at overall stats, see below comment for a caviat \n",
    "print(\"Global unscaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_unscaled_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_unscaled_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_unscaled_masked)))\n",
    "\n",
    "'''\n",
    "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non-categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da89f-f7e8-4672-b054-bcf439f5b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a76783-7ab4-4458-b944-4ddb2526ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f91622-6756-4bdb-b440-2a0b844fa80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b20419-4bce-427c-afe3-58004c5c0439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6f856-dfb6-4216-a01d-11ec59931913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b4acc-f517-4f14-95be-46d0c00c78f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72d605-bb06-44e7-ba56-d920a7716ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81094893-d64f-4900-952a-c3c5ea8b7f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d4152-ebf4-4922-ab41-8fbfb1bc15be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
