{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b8e1e",
   "metadata": {},
   "source": [
    "# Model Training (cavity_claw_RouteMeander_eigenmode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7659a-fe1b-4fdf-8c09-a398e498373b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9418886-6a3f-4473-ae89-53bab6428eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter file is where the hyperparameters are set. \n",
    "# It's reccomended to look at that file first, its interesting and you can set stuff there\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17135-58ce-45e4-9c16-1d1b76f34ea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa89948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, joblib\n",
    "\n",
    "# Disable some console warnings so you can be free of them printing. \n",
    "# Comment the next two lines if you are a professional and like looking at warnings.\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "os.environ.pop(\"TF_XLA_FLAGS\", None)      # disable XLA \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # show warnings/errors while debugging\n",
    "\n",
    "import tensorflow as tf, gc\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float32\") # make the backend use float32 which will be the same as the data--helps speed it up\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35ed7bf-9c4f-41d4-8652-1fe11dd8c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# Input seed value. If this value is the same, the random number generator \n",
    "# will generate the same set of random values every time. We like reproducibility:)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the seed value for reproducibility in tensorflow\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9e65e-f247-4388-a274-6041e8cdcc27",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dc079f-6430-41bc-8342-0cc5ffbe4a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8928889423323089946\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 40538013696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4475277137049396685\n",
      "physical_device_desc: \"device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768334733.052146    5002 gpu_device.cc:2020] Created device /device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Look at what you are working with. If you dont have a nice GPU I highly reccomend finding one\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad03d-ae5d-4bc6-b055-3e8579849c5d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0b8c-6699-4caf-b257-abc4f8e49b99",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667c238f-0e0f-4e4c-b185-f76d1ca261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the nice data you saved from the previous notebook, or downloaded from the drive\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        encoding = ENCODING_TYPE.replace(' ','_')\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec9efd-ee93-429d-95b4-4e6efef296db",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb45684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (851, 2)\n",
      "X_val.shape: (182, 2)\n",
      "y_value_train.shape: (851, 16)\n",
      "y_value_val.shape: (182, 16)\n",
      "y_exists_train.shape: (851, 16)\n",
      "y_exists_val.shape: (182, 16)\n",
      "y_value_train[0]: [0.1773399  0.         0.         1.         1.         1.\n",
      " 0.35714286 1.         0.65217391 0.         0.5        0.\n",
      " 0.         1.         1.         0.        ]\n",
      "y_exists_train[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "y_exists_val[0]: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Look at the shapes of training and test sets in case you want to orient yourself\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    print('X_train.shape:', X_train.shape)\n",
    "    print('X_val.shape:', X_val.shape)\n",
    "    print('y_value_train.shape:', y_value_train.shape)\n",
    "    print('y_value_val.shape:', y_value_val.shape)\n",
    "    print('y_exists_train.shape:', y_exists_train.shape)\n",
    "    print('y_exists_val.shape:', y_exists_val.shape)\n",
    "    print('y_value_train[0]:', y_value_train[0])\n",
    "    print('y_exists_train[0]:', y_exists_train[0])\n",
    "    print('y_exists_val[0]:', y_exists_val[0])\n",
    "\n",
    "else:\n",
    "    print('X_train_linear_encoding.shape:', X_train_linear_encoding.shape)\n",
    "    print('X_val_linear_encoding.shape:', X_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding.shape:', y_value_train_linear_encoding.shape)\n",
    "    print('y_value_val_linear_encoding.shape:', y_value_val_linear_encoding.shape)\n",
    "    print('y_exists_train_linear_encoding.shape:', y_exists_train_linear_encoding.shape)\n",
    "    print('y_exists_val_linear_encoding.shape:', y_exists_val_linear_encoding.shape)\n",
    "    print('y_value_train_linear_encoding[0]:', y_value_train_linear_encoding[0])\n",
    "    print('y_exists_train_linear_encoding[0]:', y_exists_train_linear_encoding[0])\n",
    "\n",
    "    print('X_train_one_hot_encoding.shape:', X_train_one_hot_encoding.shape)\n",
    "    print('X_val_one_hot_encoding.shape:', X_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding.shape:', y_value_train_one_hot_encoding.shape)\n",
    "    print('y_value_val_one_hot_encoding.shape:', y_value_val_one_hot_encoding.shape)\n",
    "    print('y_exists_train_one_hot_encoding.shape:', y_exists_train_one_hot_encoding.shape)\n",
    "    print('y_exists_val_one_hot_encoding.shape:', y_exists_val_one_hot_encoding.shape)\n",
    "    print('y_value_train_one_hot_encoding[0]:', y_value_train_one_hot_encoding[0])\n",
    "    print('y_exists_train_one_hot_encoding[0]:', y_exists_train_one_hot_encoding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e90f9a-14a8-41e2-ad9a-cfe4e3000d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33514963, 0.00078676],\n",
       "       [0.01809174, 0.15265725],\n",
       "       [0.01032841, 0.14763822],\n",
       "       ...,\n",
       "       [0.05754841, 0.25609945],\n",
       "       [0.57781303, 0.0013409 ],\n",
       "       [0.06168676, 0.26742149]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    display(X_train) #can check this in previous script as well after loading to make sure it matches\n",
    "else:\n",
    "    display(X_train_one_hot_encoding)\n",
    "    display(X_train_linear_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95debf17-6de3-49fc-9064-b01c985c3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Train set shape x:                851, 69.98%\n",
      "Validation set shape x:           182, 14.97%\n",
      "Test set shape x:                 183, 15.05%\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Train set shape y_value:          851, 69.98%\n",
      "Validation set shape y_value:     182, 14.97%\n",
      "Test set shape y_value:           183, 15.05%\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Look at how it was split and decide if you like the split\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    total = len(X_train) + len(X_test) + len(X_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x:                {}, {:.2f}%'.format(len(X_train), (len(X_train) * 100.) / total))\n",
    "    print('Validation set shape x:           {}, {:.2f}%'.format(len(X_val), (len(X_val) * 100.) / total))\n",
    "    print('Test set shape x:                 {}, {:.2f}%'.format(len(X_test), (len(X_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train) + len(y_value_test) + len(y_value_val)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value:          {}, {:.2f}%'.format(len(y_value_train), (len(y_value_train) * 100.) / total))\n",
    "    print('Validation set shape y_value:     {}, {:.2f}%'.format(len(y_value_val), (len(y_value_val) * 100.) / total))\n",
    "    print('Test set shape y_value:           {}, {:.2f}%'.format(len(y_value_test), (len(y_value_test) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "else:\n",
    "    total = len(X_train_one_hot_encoding) + len(X_test_one_hot_encoding) + len(X_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x one_hot_encoding:      {}, {:.2f}%'.format(len(X_train_one_hot_encoding), (len(X_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape x one_hot_encoding: {}, {:.2f}%'.format(len(X_val_one_hot_encoding), (len(X_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape x one_hot_encoding:       {}, {:.2f}%'.format(len(X_test_one_hot_encoding), (len(X_test_one_hot_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_one_hot_encoding) + len(y_value_test_one_hot_encoding) + len(y_value_val_one_hot_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value one_hot_encoding:      {}, {:.2f}%'.format(len(y_value_train_one_hot_encoding), (len(y_value_train_one_hot_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value one_hot_encoding: {}, {:.2f}%'.format(len(y_value_val_one_hot_encoding), (len(y_value_val_one_hot_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value one_hot_encoding:       {}, {:.2f}%'.format(len(y_value_test_one_hot_encoding), (len(y_value_test_one_hot_encoding) * 100.) / total))\n",
    "\n",
    "    total = len(X_train_linear_encoding) + len(X_test_linear_encoding) + len(X_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape x linear_encoding:      {}, {:.2f}%'.format(len(X_train_linear_encoding), (len(X_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape x linear_encoding: {}, {:.2f}%'.format(len(X_val_linear_encoding), (len(X_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape x linear_encoding:       {}, {:.2f}%'.format(len(X_test_linear_encoding), (len(X_test_linear_encoding) * 100.) / total))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    total = len(y_value_train_linear_encoding) + len(y_value_test_linear_encoding) + len(y_value_val_linear_encoding)\n",
    "    print('---------------------------------------')\n",
    "    print('Train set shape y_value linear_encoding:      {}, {:.2f}%'.format(len(y_value_train_linear_encoding), (len(y_value_train_linear_encoding) * 100.) / total))\n",
    "    print('Validation set shape y_value linear_encoding: {}, {:.2f}%'.format(len(y_value_val_linear_encoding), (len(y_value_val_linear_encoding) * 100.) / total))\n",
    "    print('Test set shape y_value linear_encoding:       {}, {:.2f}%'.format(len(y_value_test_linear_encoding), (len(y_value_test_linear_encoding) * 100.) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6e25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b32e05-b5df-4647-8dae-6ee5f8cddcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bin the data and look at how its distributed, probably the more random/spread out the better \n",
    "# for training, but this will improve as the database fills out\n",
    "\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    #--------------------Training Set---------------------\n",
    "    save_encoding = ENCODING_TYPE.replace(' ','_')\n",
    "    \n",
    "    num_cols = X_train.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/training_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/validation_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/test_set_data_distribution{save_encoding}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "else: #just plot linear encoding for now to not get plot overwhelm\n",
    "    #--------------------Training Set---------------------\n",
    "    num_cols = X_train_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_train_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Training Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/training_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #--------------------Validation Set---------------------\n",
    "    num_cols = X_val_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_val_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Validation Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/validation_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #--------------------Test Set---------------------\n",
    "    num_cols = X_test_linear_encoding.shape[1]\n",
    "    num_rows = math.ceil(num_cols / 3)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, 3 * num_rows))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    with open('X_names', 'r') as f:\n",
    "        column_labels = f.read().splitlines()\n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        axes[i].hist(X_test_linear_encoding[:, i], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'Test Set {column_labels[i]}')\n",
    "        axes[i].set_xlabel(f'{column_labels[i]}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/test_set_data_distribution_linear_encoding.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8215af-8030-4399-bbc5-b235f2ca3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(np.ceil(len(X_train) / TRAIN_BATCH_SIZE))\n",
    "LR_DECAY_STEPS = steps_per_epoch * 20   # decay every ~20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecc581",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251cf19c",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4f8c5",
   "metadata": {},
   "source": [
    "Create a classical multi-layer perceptron for regression. Taking some inspiration from [Deep learning-based I-V Global Parameter Extraction for BSIM-CMG](https://www.sciencedirect.com/science/article/pii/S003811012300179X), Solid-State Electronics, Vol. 209, November 2023.\n",
    "\n",
    "The above publication predicted parameters for BSIM, which is a physics model for advanced transistors that is complicated and might be a similar complexity to the physics we are trying to target/map with these SC qubit hamiltonian values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945bd67-9923-4f7c-8e32-56672a6c3a4a",
   "metadata": {},
   "source": [
    "Reccomended to download a third party app like \"Sleep control Center\" or \"Amphetamine\" to prevent computer from sleeping during the many hour/day long training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4f485-e3da-4663-832c-3bc917660e45",
   "metadata": {},
   "source": [
    "### Create Model by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce671ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # n output neurons for n parameters (value and exists heads both use this size)\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Multilayer perceptron (MLP)\n",
    "        model_shape = f'mlp_{len(X_test[0])}_'\n",
    "        # inner layer sizes\n",
    "        model_shape += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        print(len(y_value_train[0]))\n",
    "        model_shape += f'_{len(y_value_train[0])}'\n",
    "    else:\n",
    "        # Multilayer perceptron (MLP) for both encodings\n",
    "        model_shape_one_hot_encoding = f'mlp_{len(X_test_one_hot_encoding[0])}_'\n",
    "        model_shape_linear_encoding = f'mlp_{len(X_test_linear_encoding[0])}_'\n",
    "        model_shape_one_hot_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "        model_shape_linear_encoding += '_'.join(str(l) for l in NEURONS_PER_LAYER)\n",
    "\n",
    "        print('one hot:', len(y_value_train_one_hot_encoding[0]))\n",
    "        model_shape_one_hot_encoding += f'_{len(y_value_train_one_hot_encoding[0])}'\n",
    "        print('linear:', len(y_value_train_linear_encoding[0]))\n",
    "        model_shape_linear_encoding += f'_{len(y_value_train_linear_encoding[0])}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ba881d-a212-402c-86d8-ed5ab2bed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        #initialize a model, which lets us build a stack of layers\n",
    "        inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "        x = inputs\n",
    "\n",
    "        #iterate over the configuration of neurons for each hidden layer specified in NEURONS_PER_LAYER\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            # add a fully connected (dense) hidden layer with specified number of neurons\n",
    "            # the LeCun uniform initializer is used when initializing weights, this makes the model more stable\n",
    "            # l2 regularization is used in each layer to penalizing large weights, which prevents overfitting\n",
    "            x = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "\n",
    "            # apply a Leaky ReLU activation function to the outputs of the dense layer\n",
    "            # this introduces non-linearities, allowing the network to learn complex functions\n",
    "            #leaky ReLU is chosen over standard ReLU to help mitigate the \"dying ReLU\" problem:\n",
    "            #     - this problem is when neurons using the ReLU activation function output zero for all inputs and stop learning\n",
    "            #     - can be mitigated by using variations like Leaky ReLU or proper initialization\n",
    "            x = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x)\n",
    "            \n",
    "            # add a dropout layer to reduce overfitting -- randomly drops a set fraction (like 30%) of outputs from the layer\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x)\n",
    "        \n",
    "        # add the output layers consisting of # neurons, corresponding to the # target variables we aim to predict.\n",
    "        # value_out predicts the numerical parameter values; exists_out predicts if each parameter is defined (0/1).\n",
    "        value_out = Dense(len(y_value_train[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x)\n",
    "        exists_out = Dense(len(y_value_train[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x)\n",
    "\n",
    "        model = tf.keras.Model(\n",
    "            inputs=inputs,\n",
    "            outputs={'value_out': value_out, 'exists_out': exists_out},\n",
    "            name='mlp_multi_output'\n",
    "        )\n",
    "\n",
    "    \n",
    "    else:\n",
    "        # One-hot encoding model\n",
    "        inputs_one_hot = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "        x_oh = inputs_one_hot\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_oh = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_oh)\n",
    "            x_oh = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_oh)\n",
    "            x_oh = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_oh)\n",
    "        value_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        exists_out_oh = Dense(len(y_value_train_one_hot_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_oh)\n",
    "        model_one_hot_encoding = tf.keras.Model(\n",
    "            inputs=inputs_one_hot,\n",
    "            outputs={'value_out': value_out_oh, 'exists_out': exists_out_oh},\n",
    "            name='mlp_multi_output_one_hot'\n",
    "        )\n",
    "\n",
    "        # Linear encoding model\n",
    "        inputs_lin = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "        x_lin = inputs_lin\n",
    "        for i, n in enumerate(NEURONS_PER_LAYER):\n",
    "            x_lin = Dense(n, name='fc{}'.format(i), kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_lin)\n",
    "            x_lin = LeakyReLU(negative_slope=0.01, name='leaky_relu{}'.format(i))(x_lin)\n",
    "            x_lin = Dropout(rate=TRAIN_DROPOUT_RATE, name='dropout{}'.format(i))(x_lin)\n",
    "        value_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='linear', name='value_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        exists_out_lin = Dense(len(y_value_train_linear_encoding[0]), activation='sigmoid', name='exists_out', kernel_initializer='lecun_uniform')(x_lin)\n",
    "        model_linear_encoding = tf.keras.Model(\n",
    "            inputs=inputs_lin,\n",
    "            outputs={'value_out': value_out_lin, 'exists_out': exists_out_lin},\n",
    "            name='mlp_multi_output_linear'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0181fd2-e4ee-4e41-aaae-4603c1a853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    # The exponential decay learning rate schedule gradually reduces the learning rate, fine-tuning the learning process for better convergence\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LR_INITIAL,\n",
    "        decay_steps=LR_DECAY_STEPS,\n",
    "        decay_rate=LR_DECAY_RATE,\n",
    "        staircase=LR_STAIRCASE\n",
    "    )\n",
    "    \n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Set model to minimize loss specified by TRAIN_LOSS, and also to report the loss during training\n",
    "        model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "    else:\n",
    "        # Linear encoding model\n",
    "        model_linear_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n",
    "        # One-hot encoding model\n",
    "        model_one_hot_encoding.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "            metrics={'value_out': [TRAIN_LOSS], 'exists_out': ['accuracy']}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e3657d-d0ac-40e6-9829-694436270bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    !mkdir -p model\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model_file = 'model/{}_best_model.keras'.format(model_shape)\n",
    "        last_model_file = 'model/{}_last_model.keras'.format(model_shape)\n",
    "    else:\n",
    "        best_model_file_one_hot_encoding = 'model/{}_best_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "        last_model_file_one_hot_encoding = 'model/{}_last_model_one_hot_encoding.keras'.format(model_shape_one_hot_encoding)\n",
    "    \n",
    "        best_model_file_linear_encoding = 'model/{}_best_model_linear_encoding.keras'.format(model_shape_linear_encoding)\n",
    "        last_model_file_linear_encoding = 'model/{}_last_model_linear_encoding.keras'.format(model_shape_linear_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49516260-5078-4162-ab99-cdb45f9f9827",
   "metadata": {},
   "source": [
    "Enable training (`train_and_save`) to overwrite the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95e4501-3aea-4053-9788-30b4532d7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2957910-f200-4e9f-91c3-6e7ed0926ceb",
   "metadata": {},
   "source": [
    "We use Adam optimizer, minimize the Mean Squared Logarithmic Error, and early stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a00680-7b7f-4877-babb-481f0682b7b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b4fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Set up monitors and plots for later tracking purposes\n",
    "\n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    class TrainingPlot(tf.keras.callbacks.Callback):\n",
    "         \n",
    "        # This function is called when the training begins\n",
    "        def on_train_begin(self, logs={}):\n",
    "            # Initialize the lists for holding the logs, losses \n",
    "            self.losses = []\n",
    "            self.val_losses = []\n",
    "            self.logs = []\n",
    "        \n",
    "        # This function is called at the end of each epoch\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            \n",
    "            # Append the logs, losses  to the lists\n",
    "            self.logs.append(logs)\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            \n",
    "            # Before plotting ensure at least 2 epochs have passed\n",
    "            if len(self.losses) > 1:\n",
    "                \n",
    "                # Clear the previous plot\n",
    "                clear_output(wait=True)\n",
    "                N = np.arange(0, len(self.losses))\n",
    "                \n",
    "                # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "                plt.figure()\n",
    "                plt.plot(N, self.losses, label = \"train_loss\")\n",
    "                plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "                plt.title(\"Training Loss [Epoch {}]\".format(epoch))\n",
    "                plt.xlabel(\"Epoch #\")\n",
    "                plt.ylabel(\"Loss/Accuracy\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "           \n",
    "\n",
    "class LearningRateMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.learning_rates = []\n",
    "\n",
    "    #we have to do some checking for versions here or else we will get an Adam error when using this monitor\n",
    "    def _current_lr(self, optimizer):\n",
    "        # look and see if you get \"lr\" ir \"learning_rate\" depending on the version\n",
    "        lr = getattr(optimizer, \"lr\", None) or getattr(optimizer, \"learning_rate\", None)\n",
    "\n",
    "        # if this is a shecdule then evaluate it at current iteration step\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            return float(lr(optimizer.iterations).numpy())\n",
    "\n",
    "        # if not a schedule, its a scalar/variable/tensor\n",
    "        return float(tf.keras.backend.get_value(lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            lr_val = self._current_lr(self.model.optimizer)\n",
    "        except Exception:\n",
    "            # for anything else fallback\n",
    "            lr_val = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.learning_rates.append(lr_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef223c28-cc33-4721-b049-be7023eb13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "history = None  \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if train_and_save: \n",
    "        # Set up early stopping to prevent overfitting by halting training when validation loss stops improving\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_value_out_loss',                      # Monitor validation loss for stopping criteria \n",
    "            mode='min',                              # Stop when the monitored quantity has stopped decreasing\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,  # Number of epochs to wait after last improvement\n",
    "            verbose=1                                # Enable logging when early stopping happens\n",
    "        )\n",
    "    \n",
    "        # Train the model on the training data and validate on a portion of it\n",
    "        if 'Try Both' not in ENCODING_TYPE:\n",
    "            plot_callback = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            # sample weights: use exists mask for value_out, ones for exists_out\n",
    "            value_sample_weight_train = np.asarray(y_exists_train)\n",
    "            value_sample_weight_val = np.asarray(y_exists_val)  # not used directly but handy to keep\n",
    "            exists_sample_weight_train = np.ones_like(value_sample_weight_train)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                filepath=best_model_file,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "   \n",
    "            history = model.fit(\n",
    "                np.asarray(X_train),\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_value_train),\n",
    "                    \"exists_out\": np.asarray(y_exists_train),\n",
    "                },\n",
    "                sample_weight={\n",
    "                    # Mask value loss wherever the param doesn't exist\n",
    "                    \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),\n",
    "                    # Always train the existence head\n",
    "                    \"exists_out\": np.ones_like(np.asarray(y_exists_train), dtype=\"float32\"),\n",
    "                },\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val),\n",
    "                    {\n",
    "                        \"value_out\": np.asarray(y_value_val),\n",
    "                        \"exists_out\": np.asarray(y_exists_val),\n",
    "                    },\n",
    "                    {\n",
    "                        \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                        \"exists_out\": np.ones_like(np.asarray(y_exists_val), dtype=\"float32\"),\n",
    "                    },\n",
    "                ),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                callbacks=[early_stopping, model_checkpoint, plot_callback, lr_monitor],\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "            model.save(last_model_file)  # Save the final model when done training!\n",
    "        \n",
    "        else:\n",
    "            #-----------------------------------------linear--------------------------------------------\n",
    "            plot_callback_linear_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_linear_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_linear = np.asarray(y_exists_train_linear_encoding)\n",
    "            value_sample_weight_val_linear = np.asarray(y_exists_val_linear_encoding)\n",
    "            exists_sample_weight_train_linear = np.ones_like(value_sample_weight_train_linear)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_linear_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_linear_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_linear_encoding = model_linear_encoding.fit(\n",
    "                np.asarray(X_train_linear_encoding),\n",
    "                [\n",
    "                    np.asarray(y_value_train_linear_encoding),\n",
    "                    np.asarray(y_exists_train_linear_encoding)\n",
    "                ],\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_linear_encoding),\n",
    "                    [\n",
    "                        np.asarray(y_value_val_linear_encoding),\n",
    "                        np.asarray(y_exists_val_linear_encoding)\n",
    "                    ]\n",
    "                ),\n",
    "                sample_weight=[\n",
    "                    np.asarray(y_exists_train_linear_encoding),\n",
    "                    np.ones(len(y_exists_train_linear_encoding), dtype=float)\n",
    "                ],\n",
    "                callbacks=[early_stopping, model_checkpoint_linear_encoding, plot_callback_linear_encoding, lr_monitor_linear_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "            \n",
    "            model_linear_encoding.save(last_model_file_linear_encoding)  # Save the final model when done training!\n",
    "            \n",
    "            #-----------------------------------------one hot--------------------------------------------\n",
    "            plot_callback_one_hot_encoding = TrainingPlot()      # Plot training progress\n",
    "            lr_monitor_one_hot_encoding = LearningRateMonitor()  # Watch learning rate changes\n",
    "            \n",
    "            value_sample_weight_train_oh = np.asarray(y_exists_train_one_hot_encoding)\n",
    "            value_sample_weight_val_oh = np.asarray(y_exists_val_one_hot_encoding)\n",
    "            exists_sample_weight_train_oh = np.ones_like(value_sample_weight_train_oh)\n",
    "            \n",
    "            # Set up model checkpointing to save the model at its best validation loss:\n",
    "            model_checkpoint_one_hot_encoding = ModelCheckpoint(\n",
    "                filepath=best_model_file_one_hot_encoding,          \n",
    "                monitor='val_value_out_loss',            # Save the model based on validation loss improvement\n",
    "                mode='min',                    # Favor lower validation loss values for saving (minimize)\n",
    "                save_best_only=True,           # Save only when validation loss improves\n",
    "                verbose=0                      # No logging for model saving\n",
    "            )\n",
    "            \n",
    "            history_one_hot_encoding = model_one_hot_encoding.fit(\n",
    "                np.asarray(X_train_one_hot_encoding),\n",
    "                {\n",
    "                    'value_out': np.asarray(y_value_train_one_hot_encoding),\n",
    "                    'exists_out': np.asarray(y_exists_train_one_hot_encoding)\n",
    "                },\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=TRAIN_BATCH_SIZE,\n",
    "                validation_data=(\n",
    "                    np.asarray(X_val_one_hot_encoding),\n",
    "                    {\n",
    "                        'value_out': np.asarray(y_value_val_one_hot_encoding),\n",
    "                        'exists_out': np.asarray(y_exists_val_one_hot_encoding)\n",
    "                    }\n",
    "                ),\n",
    "                callbacks=[early_stopping, model_checkpoint_one_hot_encoding, plot_callback_one_hot_encoding, lr_monitor_one_hot_encoding],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            model_one_hot_encoding.save(last_model_file_one_hot_encoding)  # Save the final model when done training!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4074c-a8ef-4a69-a8cd-5714edb90166",
   "metadata": {},
   "source": [
    "Load the saved best model and use it from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2447145e-91b5-4070-aefe-38f8e6bc33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        model = load_model(best_model_file, custom_objects={})\n",
    "    else:\n",
    "        model_one_hot_encoding = load_model(best_model_file_one_hot_encoding, custom_objects={})\n",
    "        model_linear_encoding = load_model(best_model_file_linear_encoding, custom_objects={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002f4a5-df05-4ff2-be6d-24f8027ca4ea",
   "metadata": {},
   "source": [
    "### Sweep total number of parameters to find the right range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c72fea-fbf1-48fc-8e8d-7353f631e405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768334735.086263    5002 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38660 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 4g.40gb, pci bus id: 0000:00:10.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4,), 'depth': 1, 'width': 4, 'total_params': 172, 'best_val_loss': 0.22778232395648956, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (8,), 'depth': 1, 'width': 8, 'total_params': 312, 'best_val_loss': 0.17071521282196045, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (16,), 'depth': 1, 'width': 16, 'total_params': 592, 'best_val_loss': 0.14186370372772217, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (32,), 'depth': 1, 'width': 32, 'total_params': 1152, 'best_val_loss': 0.11529857665300369, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (64,), 'depth': 1, 'width': 64, 'total_params': 2272, 'best_val_loss': 0.10265350341796875, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (128,), 'depth': 1, 'width': 128, 'total_params': 4512, 'best_val_loss': 0.07757653295993805, 'best_epoch': 398}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (256,), 'depth': 1, 'width': 256, 'total_params': 8992, 'best_val_loss': 0.07433214038610458, 'best_epoch': 398}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (512,), 'depth': 1, 'width': 512, 'total_params': 17952, 'best_val_loss': 0.06687527894973755, 'best_epoch': 394}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (1024,), 'depth': 1, 'width': 1024, 'total_params': 35872, 'best_val_loss': 0.06501512974500656, 'best_epoch': 384}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (2048,), 'depth': 1, 'width': 2048, 'total_params': 71712, 'best_val_loss': 0.06843975931406021, 'best_epoch': 368}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4096,), 'depth': 1, 'width': 4096, 'total_params': 143392, 'best_val_loss': 0.07124888896942139, 'best_epoch': 388}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (5000,), 'depth': 1, 'width': 5000, 'total_params': 175032, 'best_val_loss': 0.07546066492795944, 'best_epoch': 381}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (6000,), 'depth': 1, 'width': 6000, 'total_params': 210032, 'best_val_loss': 0.07679197192192078, 'best_epoch': 396}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4, 4), 'depth': 2, 'width': 4, 'total_params': 192, 'best_val_loss': 0.16767635941505432, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (8, 8), 'depth': 2, 'width': 8, 'total_params': 384, 'best_val_loss': 0.0997425988316536, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (16, 16), 'depth': 2, 'width': 16, 'total_params': 864, 'best_val_loss': 0.08043938875198364, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (32, 32), 'depth': 2, 'width': 32, 'total_params': 2208, 'best_val_loss': 0.07655218243598938, 'best_epoch': 383}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (64, 64), 'depth': 2, 'width': 64, 'total_params': 6432, 'best_val_loss': 0.06554241478443146, 'best_epoch': 389}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (128, 128), 'depth': 2, 'width': 128, 'total_params': 21024, 'best_val_loss': 0.06296345591545105, 'best_epoch': 391}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (256, 256), 'depth': 2, 'width': 256, 'total_params': 74784, 'best_val_loss': 0.05858024209737778, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (512, 512), 'depth': 2, 'width': 512, 'total_params': 280608, 'best_val_loss': 0.050701674073934555, 'best_epoch': 392}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (1024, 1024), 'depth': 2, 'width': 1024, 'total_params': 1085472, 'best_val_loss': 0.048250868916511536, 'best_epoch': 383}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (2048, 2048), 'depth': 2, 'width': 2048, 'total_params': 4268064, 'best_val_loss': 0.049679141491651535, 'best_epoch': 398}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4096, 4096), 'depth': 2, 'width': 4096, 'total_params': 16924704, 'best_val_loss': 0.05141941457986832, 'best_epoch': 396}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (5000, 5000), 'depth': 2, 'width': 5000, 'total_params': 25180032, 'best_val_loss': 0.052502378821372986, 'best_epoch': 395}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (6000, 6000), 'depth': 2, 'width': 6000, 'total_params': 36216032, 'best_val_loss': 0.054495349526405334, 'best_epoch': 399}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4, 4, 4), 'depth': 3, 'width': 4, 'total_params': 212, 'best_val_loss': 0.12715712189674377, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (8, 8, 8), 'depth': 3, 'width': 8, 'total_params': 456, 'best_val_loss': 0.0906456783413887, 'best_epoch': 399}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (16, 16, 16), 'depth': 3, 'width': 16, 'total_params': 1136, 'best_val_loss': 0.07373766601085663, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (32, 32, 32), 'depth': 3, 'width': 32, 'total_params': 3264, 'best_val_loss': 0.06850412487983704, 'best_epoch': 397}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (64, 64, 64), 'depth': 3, 'width': 64, 'total_params': 10592, 'best_val_loss': 0.058141324669122696, 'best_epoch': 393}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (128, 128, 128), 'depth': 3, 'width': 128, 'total_params': 37536, 'best_val_loss': 0.04843122512102127, 'best_epoch': 393}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (256, 256, 256), 'depth': 3, 'width': 256, 'total_params': 140576, 'best_val_loss': 0.04460776969790459, 'best_epoch': 390}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (512, 512, 512), 'depth': 3, 'width': 512, 'total_params': 543264, 'best_val_loss': 0.0413937009871006, 'best_epoch': 383}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (1024, 1024, 1024), 'depth': 3, 'width': 1024, 'total_params': 2135072, 'best_val_loss': 0.042558927088975906, 'best_epoch': 378}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (2048, 2048, 2048), 'depth': 3, 'width': 2048, 'total_params': 8464416, 'best_val_loss': 0.043097589164972305, 'best_epoch': 396}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4096, 4096, 4096), 'depth': 3, 'width': 4096, 'total_params': 33706016, 'best_val_loss': 0.04405159130692482, 'best_epoch': 397}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (5000, 5000, 5000), 'depth': 3, 'width': 5000, 'total_params': 50185032, 'best_val_loss': 0.0451766736805439, 'best_epoch': 368}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (6000, 6000, 6000), 'depth': 3, 'width': 6000, 'total_params': 72222032, 'best_val_loss': 0.047805964946746826, 'best_epoch': 384}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4, 4, 4, 4), 'depth': 4, 'width': 4, 'total_params': 232, 'best_val_loss': 0.10630832612514496, 'best_epoch': 399}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (8, 8, 8, 8), 'depth': 4, 'width': 8, 'total_params': 528, 'best_val_loss': 0.08850174397230148, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (16, 16, 16, 16), 'depth': 4, 'width': 16, 'total_params': 1408, 'best_val_loss': 0.06984292715787888, 'best_epoch': 389}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (32, 32, 32, 32), 'depth': 4, 'width': 32, 'total_params': 4320, 'best_val_loss': 0.06197180226445198, 'best_epoch': 398}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (64, 64, 64, 64), 'depth': 4, 'width': 64, 'total_params': 14752, 'best_val_loss': 0.05252969264984131, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (128, 128, 128, 128), 'depth': 4, 'width': 128, 'total_params': 54048, 'best_val_loss': 0.04315211623907089, 'best_epoch': 383}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (256, 256, 256, 256), 'depth': 4, 'width': 256, 'total_params': 206368, 'best_val_loss': 0.03959257900714874, 'best_epoch': 396}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (512, 512, 512, 512), 'depth': 4, 'width': 512, 'total_params': 805920, 'best_val_loss': 0.0375816784799099, 'best_epoch': 399}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (1024, 1024, 1024, 1024), 'depth': 4, 'width': 1024, 'total_params': 3184672, 'best_val_loss': 0.038349587470293045, 'best_epoch': 372}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (2048, 2048, 2048, 2048), 'depth': 4, 'width': 2048, 'total_params': 12660768, 'best_val_loss': 0.03945731744170189, 'best_epoch': 382}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4096, 4096, 4096, 4096), 'depth': 4, 'width': 4096, 'total_params': 50487328, 'best_val_loss': 0.041370466351509094, 'best_epoch': 382}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (5000, 5000, 5000, 5000), 'depth': 4, 'width': 5000, 'total_params': 75190032, 'best_val_loss': 0.04157961905002594, 'best_epoch': 375}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (6000, 6000, 6000, 6000), 'depth': 4, 'width': 6000, 'total_params': 108228032, 'best_val_loss': 0.04518894478678703, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4, 4, 4, 4, 4), 'depth': 5, 'width': 4, 'total_params': 252, 'best_val_loss': 0.11206857115030289, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (8, 8, 8, 8, 8), 'depth': 5, 'width': 8, 'total_params': 600, 'best_val_loss': 0.0896562933921814, 'best_epoch': 393}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (16, 16, 16, 16, 16), 'depth': 5, 'width': 16, 'total_params': 1680, 'best_val_loss': 0.07715075463056564, 'best_epoch': 397}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (32, 32, 32, 32, 32), 'depth': 5, 'width': 32, 'total_params': 5376, 'best_val_loss': 0.06564342230558395, 'best_epoch': 387}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (64, 64, 64, 64, 64), 'depth': 5, 'width': 64, 'total_params': 18912, 'best_val_loss': 0.042794033885002136, 'best_epoch': 395}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (128, 128, 128, 128, 128), 'depth': 5, 'width': 128, 'total_params': 70560, 'best_val_loss': 0.03937816247344017, 'best_epoch': 397}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (256, 256, 256, 256, 256), 'depth': 5, 'width': 256, 'total_params': 272160, 'best_val_loss': 0.0383257120847702, 'best_epoch': 383}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (512, 512, 512, 512, 512), 'depth': 5, 'width': 512, 'total_params': 1068576, 'best_val_loss': 0.03635034337639809, 'best_epoch': 379}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (1024, 1024, 1024, 1024, 1024), 'depth': 5, 'width': 1024, 'total_params': 4234272, 'best_val_loss': 0.037879232317209244, 'best_epoch': 400}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (2048, 2048, 2048, 2048, 2048), 'depth': 5, 'width': 2048, 'total_params': 16857120, 'best_val_loss': 0.04000173881649971, 'best_epoch': 394}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (4096, 4096, 4096, 4096, 4096), 'depth': 5, 'width': 4096, 'total_params': 67268640, 'best_val_loss': 0.04269370809197426, 'best_epoch': 396}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n",
      "{'neurons_per_layer': (5000, 5000, 5000, 5000, 5000), 'depth': 5, 'width': 5000, 'total_params': 100195032, 'best_val_loss': 0.04636311158537865, 'best_epoch': 397}\n",
      "yv_tr (851, 16) float64\n",
      "ye_tr (851, 16) float32 unique: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    \n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def train_one_config(neurons_per_layer, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=X_train.shape[1],\n",
    "            output_dim=y_value_train.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # returns (batch,)\n",
    "        \n",
    "        def elementwise_mae(y_true, y_pred):\n",
    "            # returns (batch, output_dim) so your (batch, output_dim) mask works correctly\n",
    "            return tf.abs(y_true - y_pred)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\n",
    "                \"value_out\": elementwise_mae,\n",
    "                \"exists_out\": bce,\n",
    "            },\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            # If your Keras supports it, this helps avoid XLA weirdness:\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor= 'val_value_out_loss', \n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        Xtr = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr = np.asarray(y_value_train)\n",
    "        ye_tr = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "        \n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr.astype(\"float32\"),                  # (batch, 16) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\"),   # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va.astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        best_val_loss = float(np.min(history.history[\"val_loss\"]))\n",
    "        best_epoch = int(np.argmin(history.history[\"val_loss\"]) + 1)\n",
    "\n",
    "        return {\n",
    "            \"neurons_per_layer\": tuple(neurons_per_layer),\n",
    "            \"depth\": len(neurons_per_layer),\n",
    "            \"width\": int(neurons_per_layer[0]),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"best_epoch\": best_epoch,\n",
    "        }\n",
    "    configs = []\n",
    "    for depth in [1, 2, 3, 4, 5]:\n",
    "        for width in [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 5000, 6000]:\n",
    "            configs.append([width] * depth)\n",
    "    for depth in [1, 2]:\n",
    "        for width in [2048, 4096]:\n",
    "            configs.append([width] * depth)\n",
    "\n",
    "    # remove duplicates if any\n",
    "    configs = [list(x) for x in {tuple(c) for c in configs}]\n",
    "\n",
    "    results = []\n",
    "    for cfg in sorted(configs, key=lambda c: (len(c), c[0])):\n",
    "        out = train_one_config(cfg, seed=0)\n",
    "        results.append(out)\n",
    "        print(out)\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(\"total_params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b9bf8-f2b1-45cd-811f-e0ab2981101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    # save the data\n",
    "\n",
    "    from datetime import datetime\n",
    "    \n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = \"sweep_outputs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(out_dir, f\"sweep_results_{run_id}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c698f-d105-46fb-84a6-60ad839aa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    plt.figure()\n",
    "    plt.scatter(df[\"total_params\"], df[\"best_val_loss\"])\n",
    "    plt.xscale(\"log\")  # will be helpful if params grow fast\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size\")\n",
    "    plt.savefig('plots/params_vs_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    plt.figure()\n",
    "    sc = plt.scatter(\n",
    "        df2[\"total_params\"],\n",
    "        df2[\"best_val_loss\"],\n",
    "        c=df2[\"depth\"],\n",
    "        s=20 + 10*np.log2(df2[\"width\"]),\n",
    "    )\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Total parameters (log scale)\")\n",
    "    plt.ylabel(\"Best val_loss\")\n",
    "    plt.title(\"Best val_loss vs model size (color=depth, size=width)\")\n",
    "    plt.colorbar(sc, label=\"Depth\")\n",
    "    plt.savefig(\"plots/params_vs_loss_width_color_coded.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f20c5e-2bb5-4847-a8ee-da10db0e828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_PARAM_NUM:\n",
    "    df.to_csv(\"sweep_results.csv\", index=False)\n",
    "\n",
    "    old = pd.read_csv(\"sweep_results.csv\")\n",
    "    combined = pd.concat([old, df], ignore_index=True).drop_duplicates(\n",
    "        subset=[\"neurons_per_layer\"], keep=\"last\"\n",
    "    )\n",
    "    combined.to_csv(\"sweep_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202f375-0326-4767-96f0-9a5252e5799f",
   "metadata": {},
   "source": [
    "### Sweep amount of data used in training to determine if data amount is limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c0f2f-1316-4e29-b09c-6d99ce882cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "\n",
    "    FIXED_DEPTH = 5\n",
    "    FIXED_WIDTH = 64\n",
    "    FIXED_NEURONS = [FIXED_WIDTH] * FIXED_DEPTH\n",
    "\n",
    "    TRAIN_FRACTIONS = np.linspace(0.3, 1.0, 20)\n",
    "\n",
    "    # avg over many seeds for error bars\n",
    "    SWEEP_SEEDS = [0, 1, 2, 3, 4]\n",
    "\n",
    "    def build_masked_mlp(neurons_per_layer, input_dim, output_dim):\n",
    "        x_in = Input(shape=(input_dim,), name=\"input1\")\n",
    "        x = x_in\n",
    "\n",
    "        for i, n in enumerate(neurons_per_layer):\n",
    "            x = Dense(\n",
    "                n,\n",
    "                name=f\"fc{i}\",\n",
    "                kernel_initializer=\"lecun_uniform\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "            )(x)\n",
    "            x = LeakyReLU(negative_slope=0.01, name=f\"leaky_relu{i}\")(x)\n",
    "            x = Dropout(rate=TRAIN_DROPOUT_RATE, name=f\"dropout{i}\")(x)\n",
    "\n",
    "        value_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"linear\",\n",
    "            name=\"value_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        exists_out = Dense(\n",
    "            output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"exists_out\",\n",
    "            kernel_initializer=\"lecun_uniform\",\n",
    "            dtype=\"float32\",\n",
    "        )(x)\n",
    "\n",
    "        return Model(inputs=x_in, outputs={\"value_out\": value_out, \"exists_out\": exists_out})\n",
    "\n",
    "    def make_optimizer():\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=LR_INITIAL,\n",
    "            decay_steps=LR_DECAY_STEPS,\n",
    "            decay_rate=LR_DECAY_RATE,\n",
    "            staircase=LR_STAIRCASE,\n",
    "        )\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    def elementwise_mae(y_true, y_pred):\n",
    "        return tf.abs(y_true - y_pred)  \n",
    "\n",
    "    def make_subset(X, y_value, y_exists, frac, seed):\n",
    "        assert 0 < frac <= 1.0\n",
    "        n = len(X)\n",
    "        m = max(1, int(np.floor(frac * n)))\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(n, size=m, replace=False)\n",
    "        return X[idx], y_value[idx], y_exists[idx], m\n",
    "\n",
    "    def train_one_fraction(neurons_per_layer, train_frac, seed=0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Full arrays\n",
    "        Xtr_full = np.asarray(X_train)\n",
    "        Xva = np.asarray(X_val)\n",
    "\n",
    "        yv_tr_full = np.asarray(y_value_train)\n",
    "        ye_tr_full = np.asarray(y_exists_train).astype(\"float32\")\n",
    "\n",
    "        yv_va = np.asarray(y_value_val)\n",
    "        ye_va = np.asarray(y_exists_val).astype(\"float32\")\n",
    "\n",
    "        Xtr, yv_tr, ye_tr, n_sub = make_subset(Xtr_full, yv_tr_full, ye_tr_full, train_frac, seed)\n",
    "\n",
    "        model = build_masked_mlp(\n",
    "            neurons_per_layer=neurons_per_layer,\n",
    "            input_dim=Xtr.shape[1],\n",
    "            output_dim=yv_tr.shape[1],\n",
    "        )\n",
    "\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=make_optimizer(),\n",
    "            loss={\"value_out\": elementwise_mae, \"exists_out\": bce},\n",
    "            loss_weights={\"value_out\": 1.0, \"exists_out\": 1.0},\n",
    "            metrics={\n",
    "                \"value_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    "                \"exists_out\": [tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\")],\n",
    "            },\n",
    "            jit_compile=False,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            Xtr,\n",
    "            {\"value_out\": yv_tr, \"exists_out\": ye_tr},\n",
    "            sample_weight={\n",
    "                \"value_out\": ye_tr,                                # (batch, output_dim) mask\n",
    "                \"exists_out\": np.ones((len(Xtr),), dtype=\"float32\") # (batch,) neutral\n",
    "            },\n",
    "            validation_data=(\n",
    "                Xva,\n",
    "                {\"value_out\": yv_va, \"exists_out\": ye_va},\n",
    "                {\n",
    "                    \"value_out\": ye_va,                              # (val_batch, output_dim) mask\n",
    "                    \"exists_out\": np.ones((len(Xva),), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # grab best epoch by val_loss\n",
    "        val_loss_hist = np.asarray(history.history[\"val_loss\"], dtype=float)\n",
    "        best_i = int(np.argmin(val_loss_hist))\n",
    "        best_epoch = best_i + 1\n",
    "\n",
    "        out = {\n",
    "            \"train_frac\": float(train_frac),\n",
    "            \"train_n\": int(n_sub),\n",
    "            \"seed\": int(seed),\n",
    "            \"neurons_per_layer\": str(list(neurons_per_layer)),\n",
    "            \"total_params\": int(model.count_params()),\n",
    "            \"best_val_loss\": float(val_loss_hist[best_i]),\n",
    "            \"best_val_value_out_loss\": float(np.asarray(history.history.get(\"val_value_out_loss\"))[best_i]),\n",
    "            \"best_val_exists_out_loss\": float(np.asarray(history.history.get(\"val_exists_out_loss\"))[best_i]),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "        }\n",
    "        return out\n",
    "\n",
    "    results = []\n",
    "    for frac in TRAIN_FRACTIONS:\n",
    "        for seed in SWEEP_SEEDS:\n",
    "            out = train_one_fraction(FIXED_NEURONS, train_frac=frac, seed=seed)\n",
    "            results.append(out)\n",
    "            print(out)\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values([\"train_frac\", \"seed\"]).reset_index(drop=True)\n",
    "\n",
    "    summary = (\n",
    "        df.groupby([\"train_frac\", \"train_n\", \"total_params\"], as_index=False)\n",
    "          .agg(\n",
    "              best_val_loss_mean=(\"best_val_loss\", \"mean\"),\n",
    "              best_val_loss_std=(\"best_val_loss\", \"std\"),\n",
    "              best_epoch_mean=(\"best_epoch\", \"mean\"),\n",
    "              best_val_value_out_loss_mean=(\"best_val_value_out_loss\", \"mean\"),\n",
    "              best_val_exists_out_loss_mean=(\"best_val_exists_out_loss\", \"mean\"),\n",
    "          )\n",
    "          .sort_values(\"train_frac\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # save to csv\n",
    "    run_id = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = os.path.join(\"sweeps\", f\"data_fraction_sweep_{run_id}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_path = os.path.join(out_dir, \"sweep_raw.csv\")\n",
    "    summary_path = os.path.join(out_dir, \"sweep_summary.csv\")\n",
    "    meta_path = os.path.join(out_dir, \"metadata.json\")\n",
    "    fig_path = os.path.join(out_dir, \"val_loss_vs_train_fraction.png\")\n",
    "\n",
    "    df.to_csv(df_path, index=False)\n",
    "    summary.to_csv(summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b458abc-b03a-4910-9dfd-d92637c4cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWEEP_DATA_AMOUNT:\n",
    "    def _jsonify(o):\n",
    "        if isinstance(o, np.ndarray): return o.tolist()\n",
    "        if isinstance(o, (np.integer,)): return int(o)\n",
    "        if isinstance(o, (np.floating,)): return float(o)\n",
    "        return o\n",
    "\n",
    "    metadata = {\n",
    "        \"run_id\": run_id,\n",
    "        \"fixed_depth\": FIXED_DEPTH,\n",
    "        \"fixed_width\": FIXED_WIDTH,\n",
    "        \"fixed_neurons\": FIXED_NEURONS,\n",
    "        \"train_fractions\": TRAIN_FRACTIONS,\n",
    "        \"seeds\": SWEEP_SEEDS,\n",
    "        \"batch_size\": int(TRAIN_BATCH_SIZE),\n",
    "        \"early_stopping_patience\": int(TRAIN_EARLY_STOPPING_PATIENCE),\n",
    "        \"notes\": \"Subset sampling only on TRAIN split. value_out loss is masked using y_exists via sample_weight.\",\n",
    "    }\n",
    "\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2, default=_jsonify)\n",
    "\n",
    "    plt.figure()\n",
    "    y = summary[\"best_val_loss_mean\"].to_numpy()\n",
    "    x = summary[\"train_frac\"].to_numpy()\n",
    "    if len(SWEEP_SEEDS) > 1:\n",
    "        yerr = summary[\"best_val_loss_std\"].fillna(0.0).to_numpy()\n",
    "        plt.errorbar(x, y, yerr=yerr, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss (mean  std)\")\n",
    "    else:\n",
    "        plt.plot(x, y, marker=\"o\")\n",
    "        plt.ylabel(\"Best val loss\")\n",
    "\n",
    "    plt.xlabel(\"Training data fraction\")\n",
    "    plt.title(f\"Val loss vs training fraction (depth={FIXED_DEPTH}, width={FIXED_WIDTH})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nSaved:\\n- {df_path}\\n- {summary_path}\\n- {meta_path}\\n- {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d39c98-db42-48fe-9e64-8c153c978203",
   "metadata": {},
   "source": [
    "### Keras Tuner to Find Best Hyperparameters and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe2de3-ba0a-4103-bfd1-466d73bd9b8c",
   "metadata": {},
   "source": [
    "Run this if you want to use keras tuner to make the model rather than doing it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d804553-ae82-4f8f-9182-806c7f22b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras_tuner import HyperModel, RandomSearch\n",
    "    from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081aa70b-c54e-48af-b895-5e9ddd2746cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        def build_hypermodel(hp):\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=100, max_value=5000, step=100) for i in range(4)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            # multi-output heads: value_out (regression) and exists_out (existence classification)\n",
    "            value_out = Dense(len(y_value_train[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "        \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "        \n",
    "            model.compile(optimizer=tf.optimizers.Adam(learning_rate=lr_schedule), \n",
    "                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model\n",
    "    else:\n",
    "        def build_hypermodel_one_hot_encoding(hp):\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=100, max_value=5000, step=100) for i in range(4)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------one hot-------------------------------------------\n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_one_hot_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_one_hot_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_one_hot_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_one_hot_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            \n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_one_hot_encoding.compile(optimizer=optimizer, \n",
    "                                           loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                           loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                           metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_one_hot_encoding\n",
    "\n",
    "        def build_hypermodel_linear_encoding(hp):\n",
    "            # Hyperparameters to tune\n",
    "            neurons_per_layer = [hp.Int(f'neurons_{i}', min_value=100, max_value=5000, step=100) for i in range(4)]\n",
    "            dropout_rate = hp.Float('dropout_rate', TRAIN_DROPOUT_RATE, 0.5, step=0.1)\n",
    "            \n",
    "            #----------------------------------------------linear------------------------------------------- \n",
    "            # Create Model in the same way that we do by hand\n",
    "            inputs = Input(shape=(len(X_test_linear_encoding[0]),), name='input1')\n",
    "            x = inputs\n",
    "        \n",
    "            for i, n in enumerate(neurons_per_layer):\n",
    "                x = Dense(n, name=f'fc{i}', kernel_initializer='lecun_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "                x = LeakyReLU(negative_slope=0.01, name=f'leaky_relu{i}')(x)\n",
    "                x = Dropout(rate=dropout_rate, name=f'dropout{i}')(x)\n",
    "        \n",
    "            value_out = Dense(len(y_value_train_linear_encoding[0]), name='value_out', activation='linear', kernel_initializer='lecun_uniform')(x)\n",
    "            exists_out = Dense(len(y_value_train_linear_encoding[0]), name='exists_out', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "            model_linear_encoding = tf.keras.Model(inputs=inputs, outputs=[value_out, exists_out])\n",
    "            #----------------------------------------------continue-------------------------------------------\n",
    "\n",
    "            # Learning rate configuration\n",
    "            lr_initial = hp.Float('learning_rate', 1e-6, 5e-3, sampling='LOG', default=0.0001)\n",
    "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr_initial, decay_steps=LR_DECAY_STEPS, decay_rate=LR_DECAY_RATE, staircase=LR_STAIRCASE)\n",
    "            optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            model_linear_encoding.compile(optimizer=optimizer, \n",
    "                                          loss={'value_out': 'mean_squared_error', 'exists_out': 'binary_crossentropy'},\n",
    "                                          loss_weights={'value_out': 1.0, 'exists_out': 1.0},\n",
    "                                          metrics={'value_out': ['mean_squared_error'], 'exists_out': ['accuracy']})\n",
    "            return model_linear_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfea157-b0b4-4148-8d0a-e37c877877a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        tuner = RandomSearch(\n",
    "            build_hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + f'/hyper_tuning_{encoding}_encoding',\n",
    "            project_name=f'mlp_tuning_{encoding}_encoding'\n",
    "        )\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # Start tuning linear encoding\n",
    "        tuner_linear_encoding = RandomSearch(\n",
    "            build_hypermodel_linear_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_linear_encoding',\n",
    "            project_name='mlp_tuning_linear_encoding'\n",
    "        )\n",
    "\n",
    "        # Start tuning one hot encoding\n",
    "        tuner_one_hot_encoding = RandomSearch(\n",
    "            build_hypermodel_one_hot_encoding,\n",
    "            objective='val_loss',\n",
    "            max_trials=KERAS_TUNER_TRIALS,\n",
    "            executions_per_trial=1,\n",
    "            directory=KERAS_DIR + '/hyper_tuning_one_hot_encoding',\n",
    "            project_name='mlp_tuning_one_hot_encoding'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11608cb-5b05-45af-af22-0bcab2827734",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    # Setup Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_value_out_loss',\n",
    "        mode='min',\n",
    "        patience=TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15440869-6be6-4005-9db4-3b37695adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        # Perform hyperparameter tuning\n",
    "        tuner.search(\n",
    "            np.asarray(X_train),\n",
    "            {'value_out': np.asarray(y_value_train), 'exists_out': np.asarray(y_exists_train)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val), {'value_out': np.asarray(y_value_val), 'exists_out': np.asarray(y_exists_val)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # one-hot encoding branch\n",
    "        tuner_one_hot_encoding.search(\n",
    "            np.asarray(X_train_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # linear encoding branch\n",
    "        tuner_linear_encoding.search(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1b58-8413-4573-a02d-fe8363165edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file= f'model/best_keras_model_{encoding}_encoding.keras'\n",
    "\n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        best_model.save(best_model_file)\n",
    "\n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_model = load_model(best_model_file, compile=False)\n",
    "    else:\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        best_model_file_linear = 'model/best_keras_model_linear_encoding.keras'\n",
    "        best_model_file_onehot = 'model/best_keras_model_one_hot_encoding.keras'\n",
    "        \n",
    "        best_linear_model = tuner_linear_encoding.get_best_models(1)[0]\n",
    "        best_onehot_model = tuner_one_hot_encoding.get_best_models(1)[0]\n",
    "        \n",
    "        best_linear_model.save(best_model_file_linear)\n",
    "        best_onehot_model.save(best_model_file_onehot)\n",
    "        \n",
    "        #gpu is thowing errors, lets try to clear its memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        #lets not compile to help with the memory bug\n",
    "        with tf.device('/CPU:0'):\n",
    "            loaded_linear_model = load_model(best_model_file_linear, compile=False)\n",
    "            loaded_onehot_model = load_model(best_model_file_onehot, compile=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291953b-7ce8-498d-88ce-20974516af77",
   "metadata": {},
   "source": [
    "### View the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d2a50-a4ef-4ccc-8cb9-04e380f0fcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if KERAS_TUNER:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        best_model.summary()\n",
    "    else:\n",
    "        best_onehot_model.summary()\n",
    "        best_linear_model.summary()\n",
    "        \n",
    "if not KERAS_TUNER  and not SWEEP_PARAM_NUM and not SWEEP_DATA_AMOUNT:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        print(\"\\n---- Model Summary ----\")\n",
    "        model.summary()\n",
    "    else:\n",
    "        print(\"\\n---- Linear Encoding Model Summary ----\")\n",
    "        model_linear_encoding.summary()\n",
    "        \n",
    "        print(\"\\n---- One-Hot Encoding Model Summary ----\")\n",
    "        model_one_hot_encoding.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f05d0a25-2890-4ddc-b888-57b849fa2a0f",
   "metadata": {},
   "source": [
    "if KERAS_TUNER:\n",
    "    keras2ascii(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57cb40-ca2c-4ac7-905c-e13beaf71a51",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5556f8-c81b-4522-b7be-d847b6f20452",
   "metadata": {},
   "source": [
    "Although we may plot and print many metrics, we focus only on **Mean Squared Error (MSE).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc9acc-ad33-4df3-ac56-8ed3913ce16d",
   "metadata": {},
   "source": [
    "Plot training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "523cc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a721cc-cc18-4bc6-96b9-520b736e2382",
   "metadata": {},
   "source": [
    "### Visualize gradients for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64ca5e-a7e8-49fe-8734-becc35d4998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        class GradientNormLogger(tf.keras.callbacks.Callback):\n",
    "            \"\"\"\n",
    "            Logs gradient norms on a fixed probe batch at epoch end.\n",
    "            Works for:\n",
    "              - single-output models (y_true array)\n",
    "              - multi-output dict models (e.g., {\"value_out\":..., \"exists_out\":...})\n",
    "            Supports passing sample_weight (incl. per-output dict), which is required for masked losses.\n",
    "            \"\"\"\n",
    "            def __init__(\n",
    "                self,\n",
    "                x_probe,\n",
    "                y_probe,\n",
    "                sample_weight_probe=None,\n",
    "                layer_name_prefixes=(\"fc\", \"value_out\", \"exists_out\"),\n",
    "                log_every=1,\n",
    "                verbose=1\n",
    "            ):\n",
    "                super().__init__()\n",
    "                self.x_probe = tf.convert_to_tensor(x_probe)\n",
    "                self.y_probe = y_probe  # keep as-is; we will convert lazily (dict vs array)\n",
    "                self.sample_weight_probe = sample_weight_probe\n",
    "                self.layer_name_prefixes = tuple(layer_name_prefixes)\n",
    "                self.log_every = int(log_every)\n",
    "                self.verbose = int(verbose)\n",
    "                self.records = []\n",
    "        \n",
    "            def _to_tensor_tree(self, obj):\n",
    "                # converts arrays (or dict of arrays) to tensors\n",
    "                if obj is None:\n",
    "                    return None\n",
    "                if isinstance(obj, dict):\n",
    "                    return {k: tf.convert_to_tensor(v) for k, v in obj.items()}\n",
    "                return tf.convert_to_tensor(obj)\n",
    "        \n",
    "            def _want_var(self, var_name: str) -> bool:\n",
    "                # var_name like \"fc0/kernel:0\", \"value_out/bias:0\", etc.\n",
    "                base = var_name.split(\":\")[0]\n",
    "                return any(base.startswith(pfx) for pfx in self.layer_name_prefixes)\n",
    "        \n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                logs = logs or {}\n",
    "                if (epoch + 1) % self.log_every != 0:\n",
    "                    return\n",
    "        \n",
    "                y_probe_t = self._to_tensor_tree(self.y_probe)\n",
    "                sw_probe_t = self._to_tensor_tree(self.sample_weight_probe)\n",
    "        \n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = self.model(self.x_probe, training=True)\n",
    "                    # IMPORTANT: use compiled_loss the same way training does\n",
    "                    loss = self.model.compiled_loss(\n",
    "                        y_probe_t,\n",
    "                        y_pred,\n",
    "                        sample_weight=sw_probe_t,\n",
    "                        regularization_losses=self.model.losses\n",
    "                    )\n",
    "        \n",
    "                grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        \n",
    "                rec = {\"epoch\": int(epoch + 1), \"probe_loss\": float(loss.numpy())}\n",
    "        \n",
    "                per_layer = {}\n",
    "                for w, g in zip(self.model.trainable_weights, grads):\n",
    "                    if g is None:\n",
    "                        continue\n",
    "        \n",
    "                    wname = w.name  # includes :0\n",
    "                    if not self._want_var(wname):\n",
    "                        continue\n",
    "        \n",
    "                    wbase = wname.split(\":\")[0]\n",
    "                    g_norm = float(tf.linalg.global_norm([g]).numpy().item())\n",
    "                    rec[f\"grad_norm__{wbase}\"] = g_norm\n",
    "        \n",
    "                    layer_key = wbase.split(\"/\")[0]\n",
    "                    per_layer.setdefault(layer_key, []).append(g_norm)\n",
    "        \n",
    "                for layer_key, norms in per_layer.items():\n",
    "                    rec[f\"grad_mean__{layer_key}\"] = float(np.mean(norms))\n",
    "                    rec[f\"grad_max__{layer_key}\"] = float(np.max(norms))\n",
    "        \n",
    "                g_all = [g for g in grads if g is not None]\n",
    "                rec[\"grad_global_norm\"] = float(tf.linalg.global_norm(g_all).numpy().item()) if g_all else float(\"nan\")\n",
    "        \n",
    "                self.records.append(rec)\n",
    "        \n",
    "                # push scalars into History\n",
    "                for k, v in rec.items():\n",
    "                    if k != \"epoch\":\n",
    "                        logs[k] = v\n",
    "        \n",
    "                if self.verbose:\n",
    "                    msg = f\"[Grad] epoch={rec['epoch']} probe_loss={rec['probe_loss']:.6g} global={rec['grad_global_norm']:.3g}\"\n",
    "                    # show a couple common layers if present\n",
    "                    for lk in (\"fc0\", \"value_out\", \"exists_out\"):\n",
    "                        mk = f\"grad_mean__{lk}\"\n",
    "                        xk = f\"grad_max__{lk}\"\n",
    "                        if mk in rec:\n",
    "                            msg += f\" | {lk}:mean={rec[mk]:.3g} max={rec[xk]:.3g}\"\n",
    "                    print(msg)\n",
    "        \n",
    "            def to_csv(self, path: str):\n",
    "                import csv, os\n",
    "                os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "                if not self.records:\n",
    "                    return\n",
    "                keys = sorted({k for r in self.records for k in r.keys()})\n",
    "                with open(path, \"w\", newline=\"\") as f:\n",
    "                    w = csv.DictWriter(f, fieldnames=keys)\n",
    "                    w.writeheader()\n",
    "                    w.writerows(self.records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969df9e-8593-4cb0-9051-2a085a051d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        # Choose a fixed probe batch (small to avoid overhead)\n",
    "        probe_n = min(256, len(X_train))\n",
    "        x_probe = np.asarray(X_train[:probe_n])\n",
    "        y_probe = np.asarray(y_train[:probe_n])\n",
    "        \n",
    "        grad_logger = GradientNormLogger(\n",
    "            x_probe=x_probe,\n",
    "            y_probe=y_probe,\n",
    "            layer_name_prefixes=(\"fc0\", \"output\"),  # just your one hidden layer + output\n",
    "            log_every=1,\n",
    "            verbose=1\n",
    "        )\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp  = tuner.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model    = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            np.asarray(y_train),\n",
    "            epochs=400,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val), np.asarray(y_val)),\n",
    "            callbacks=[early_stopping, lr_monitor, grad_logger],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save gradient logs\n",
    "        grad_logger.to_csv(f\"plots/{encoding}_gradients.csv\")        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30d21b-458b-4518-bdae-04f505e45c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER and not SWEEP_PARAM_NUM and VISUALIZE_GRADIENTS:\n",
    "        dfg = pd.DataFrame(grad_logger.records)\n",
    "        \n",
    "        # Plot global grad norm\n",
    "        plt.figure()\n",
    "        plt.plot(dfg[\"epoch\"], dfg[\"grad_global_norm\"])\n",
    "        plt.yscale(\"log\")  # very helpful to see vanishing/exploding\n",
    "        plt.title(\"Gradient tracking for a single batch across epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Gradient magnitude (log scale)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"plots/{encoding}_grad_global_norm.pdf\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot fc0 and output mean norms if present\n",
    "        for lk in [\"fc0\", \"output\"]:\n",
    "            col = f\"grad_mean__{lk}\"\n",
    "            if col in dfg.columns:\n",
    "                plt.figure()\n",
    "                plt.plot(dfg[\"epoch\"], dfg[col])\n",
    "                plt.yscale(\"log\")\n",
    "                plt.title(f\"Gradient Mean Norm: {lk} (probe batch)\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Mean grad norm (log scale)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"plots/{encoding}_grad_mean_{lk}.pdf\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa8eb5-11a2-4ca0-832f-e0cfb057a75a",
   "metadata": {},
   "source": [
    "### Look at the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "347263a8-570e-4a04-bbae-3ea0662e4012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m     46\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 48\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "        lr_monitor = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        history = model.fit(\n",
    "            np.asarray(X_train),\n",
    "            {\n",
    "                \"value_out\": np.asarray(y_value_train),\n",
    "                \"exists_out\": np.asarray(y_exists_train),\n",
    "            },\n",
    "            sample_weight={\n",
    "                \"value_out\": np.asarray(y_exists_train).astype(\"float32\"),\n",
    "                \"exists_out\": np.ones_like(np.asarray(y_exists_train), dtype=\"float32\"),\n",
    "            },\n",
    "            validation_data=(\n",
    "                np.asarray(X_val),\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_value_val),\n",
    "                    \"exists_out\": np.asarray(y_exists_val),\n",
    "                },\n",
    "                {\n",
    "                    \"value_out\": np.asarray(y_exists_val).astype(\"float32\"),\n",
    "                    \"exists_out\": np.ones_like(np.asarray(y_exists_val), dtype=\"float32\"),\n",
    "                },\n",
    "            ),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            callbacks=[early_stopping, lr_monitor],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{encoding}_learning_rate.pdf')\n",
    "    plt.show()\n",
    "else:\n",
    "    if KERAS_TUNER:\n",
    "        # now both searches should have completed, so lets get the best hyperparams \n",
    "        # and retrain with history saved so we can look at it\n",
    "        best_hp_linear = tuner_linear_encoding.get_best_hyperparameters(1)[0]\n",
    "        \n",
    "        # make the models again using the best hyperparams\n",
    "        model_linear = tuner_linear_encoding.hypermodel.build(best_hp_linear)\n",
    "\n",
    "        lr_monitor_linear_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "        \n",
    "        # retrain with history so we can plot it\n",
    "        history_linear_encoding = model_linear.fit(\n",
    "            np.asarray(X_train_linear_encoding),\n",
    "            {'value_out': np.asarray(y_value_train_linear_encoding), 'exists_out': np.asarray(y_exists_train_linear_encoding)},\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            validation_data=(np.asarray(X_val_linear_encoding), {'value_out': np.asarray(y_value_val_linear_encoding), 'exists_out': np.asarray(y_exists_val_linear_encoding)}),\n",
    "            callbacks=[early_stopping, lr_monitor_linear_encoding],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # keep getting a memory allocation error on EAF so lets free everything after the first \n",
    "        # model fit, before moving to the next one\n",
    "        \n",
    "        del model_linear\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    plt.plot(history_linear_encoding.history['loss'])\n",
    "    plt.plot(history_linear_encoding.history['val_loss'])\n",
    "    plt.title('Model loss linear encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_history.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(lr_monitor_linear_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs linear encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/linear_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47150b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I needed to restart the kernal and skip the block above to run this block-otherwise i got memory allocation error. \n",
    "#theres probably a better way to do this--like clearing the memory before running this block so you can run both models sequentially\n",
    "\n",
    "if 'Try Both' in ENCODING_TYPE and KERAS_TUNER:\n",
    "    best_hp_onehot = tuner_one_hot_encoding.get_best_hyperparameters(1)[0]\n",
    "    model_onehot = tuner_one_hot_encoding.hypermodel.build(best_hp_onehot)\n",
    "\n",
    "    lr_monitor_one_hot_encoding = LearningRateMonitor()  # make learning rate monitor\n",
    "    \n",
    "    history_one_hot_encoding = model_onehot.fit(\n",
    "        np.asarray(X_train_one_hot_encoding),\n",
    "        {'value_out': np.asarray(y_value_train_one_hot_encoding), 'exists_out': np.asarray(y_exists_train_one_hot_encoding)},\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        validation_data=(np.asarray(X_val_one_hot_encoding), {'value_out': np.asarray(y_value_val_one_hot_encoding), 'exists_out': np.asarray(y_exists_val_one_hot_encoding)}),\n",
    "        callbacks=[early_stopping, lr_monitor_one_hot_encoding],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    plt.plot(history_one_hot_encoding.history['loss'])\n",
    "    plt.plot(history_one_hot_encoding.history['val_loss'])\n",
    "    plt.title('Model loss one hot encoding')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_history.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(lr_monitor_one_hot_encoding.learning_rates)\n",
    "    plt.title(\"Learning Rate over Epochs one hot encoding\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/one_hot_encoding_learning_rate.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a331d8-70ea-4ea4-8f5b-256472850784",
   "metadata": {},
   "source": [
    "Measure and print metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32ff7d16-5709-41d6-b3f7-e6c9a062b35c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTry Both\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ENCODING_TYPE:\n\u001b[0;32m---> 33\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(\u001b[43mbest_model_file\u001b[49m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     35\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m         loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_out\u001b[39m\u001b[38;5;124m'\u001b[39m: TRAIN_LOSS, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexists_out\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m     37\u001b[0m         loss_weights\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_out\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexists_out\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m}\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m     test_loss_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     40\u001b[0m         np\u001b[38;5;241m.\u001b[39masarray(X_test),\n\u001b[1;32m     41\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_out\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39masarray(y_value_test), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexists_out\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39masarray(y_exists_test)},\n\u001b[1;32m     42\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     43\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model_file' is not defined"
     ]
    }
   ],
   "source": [
    "#take a look at the loss results and save them \n",
    "\n",
    "# clear everything so we start with a blank slate memory wise\n",
    "tf.keras.backend.clear_session()                         #clear tf backend\n",
    "gc.collect()                                             #just collect stray things\n",
    "#tf.config.experimental.reset_memory_stats('GPU:0')       #clear gpus\n",
    "\n",
    "\n",
    "def get_loss(eval_out):\n",
    "    # eval_out can be float, list/tuple/ndarray, or dict\n",
    "    if isinstance(eval_out, dict):\n",
    "        return float(eval_out.get('loss', list(eval_out.values())[0]))\n",
    "    if isinstance(eval_out, (list, tuple, np.ndarray)):\n",
    "        return float(eval_out[0])\n",
    "    return float(eval_out)\n",
    "\n",
    "def mlp_signature(m, prefix=\"mlp\"):\n",
    "    #get the model input sizze first\n",
    "    in_shape = m.input_shape\n",
    "    if isinstance(in_shape, list):     #just get the first one\n",
    "        in_shape = in_shape[0]\n",
    "    dims = [d for d in in_shape[1:] if d is not None]\n",
    "    input_size = int(np.prod(dims)) if dims else \"None\"\n",
    "\n",
    "    # now get the dense laysers in order\n",
    "    dense_units = [l.units for l in m.layers if isinstance(l, Dense)]\n",
    "\n",
    "    parts = [prefix, str(input_size)] + [str(u) for u in dense_units]\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "    \n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    model = load_model(best_model_file, compile=False)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result = model.evaluate(\n",
    "        np.asarray(X_test),\n",
    "        {'value_out': np.asarray(y_value_test), 'exists_out': np.asarray(y_exists_test)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result = get_loss(test_loss_result)\n",
    "    \n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape = mlp_signature(model)\n",
    "\n",
    "    print('Current loss {} encoding {}: {}'.format(encoding, TRAIN_LOSS, test_loss_result))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': f'{ENCODING_TYPE} Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result},\n",
    "        ])\n",
    "\n",
    "else:\n",
    "    # we need to do some fancy allocation of recources if we are going to load both models\n",
    "    # do the first on one GPU\n",
    "    linear_model = load_model(best_model_file_linear, compile=False)\n",
    "    linear_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "        loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "    )\n",
    "    test_loss_result_linear_encoding = linear_model.evaluate(\n",
    "        np.asarray(X_test_linear_encoding),\n",
    "        {'value_out': np.asarray(y_value_test_linear_encoding), 'exists_out': np.asarray(y_exists_test_linear_encoding)},\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss_result_linear_encoding = get_loss(test_loss_result_linear_encoding)\n",
    "    \n",
    "    # now do on CPU to avoid GPU allocation\n",
    "    with tf.device('/GPU:0'):\n",
    "        onehot_model = load_model(best_model_file_onehot, compile=False)\n",
    "        onehot_model.compile(\n",
    "            optimizer='adam',\n",
    "            loss={'value_out': TRAIN_LOSS, 'exists_out': 'binary_crossentropy'},\n",
    "            loss_weights={'value_out': 1.0, 'exists_out': 1.0}\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = onehot_model.evaluate(\n",
    "            np.asarray(X_test_one_hot_encoding),\n",
    "            {'value_out': np.asarray(y_value_test_one_hot_encoding), 'exists_out': np.asarray(y_exists_test_one_hot_encoding)},\n",
    "            verbose=0\n",
    "        )\n",
    "        test_loss_result_one_hot_encoding = get_loss(test_loss_result_one_hot_encoding)\n",
    "\n",
    "    #save the shape for the next block so we can save it using the definition above\n",
    "    model_shape_one_hot_encoding = mlp_signature(onehot_model)\n",
    "    model_shape_linear_encoding  = mlp_signature(linear_model)\n",
    "    \n",
    "    print('Current loss linear encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_linear_encoding))\n",
    "    print('Current loss one hot encoding {}: {}'.format(TRAIN_LOSS, test_loss_result_one_hot_encoding))\n",
    "    \n",
    "    results_df = pd.DataFrame([\n",
    "        {'Encoding Type': 'linear Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_linear_encoding},\n",
    "        {'Encoding Type': 'One Hot Encoding', 'Train Loss Metric': TRAIN_LOSS, 'Test Loss': test_loss_result_one_hot_encoding}\n",
    "    ])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv('test_loss_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7812af-2596-44d2-bb25-68741e0506ba",
   "metadata": {},
   "source": [
    "## Compare predictions vs. test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60157266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape,\n",
    "        ENCODING_TYPE,\n",
    "        test_loss_result,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df = df.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "\n",
    "else:\n",
    "    #---------------------------------------------------one hot---------------------------------------\n",
    "    csv_data = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_one_hot_encoding,\n",
    "        'One Hot',\n",
    "        test_loss_result_one_hot_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as file:\n",
    "            file.write('data_augmentation,model_shape,encoding_type,test_loss,train_loss,train_dropout_rate,train_early_stop_patience,'+\n",
    "                        'train_batch_size,train_val_split,lr_initial,lr_decay_step,lr_decay_rate,lr_stair_case\\n')\n",
    "            \n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_one_hot_encoding = pd.read_csv(csv_file)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_one_hot_encoding = df_one_hot_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    #---------------------------------------------------linear---------------------------------------\n",
    "    csv_data_linear_encoding = [[\n",
    "        DATA_AUGMENTATION,\n",
    "        model_shape_linear_encoding,\n",
    "        'linear',\n",
    "        test_loss_result_linear_encoding,\n",
    "        TRAIN_LOSS,\n",
    "        TRAIN_DROPOUT_RATE,\n",
    "        TRAIN_EARLY_STOPPING_PATIENCE,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        '0.15/0.15',\n",
    "        LR_INITIAL,\n",
    "        LR_DECAY_STEPS,\n",
    "        LR_DECAY_RATE,\n",
    "        LR_STAIRCASE\n",
    "        ]]\n",
    "    \n",
    "    csv_file_linear_encoding = 'history_losses.csv'  #this doesnt reqrite this file so you need to delete this if you want something fresh\n",
    "    \n",
    "    with open(csv_file_linear_encoding, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data_linear_encoding)\n",
    "    \n",
    "    # Convert data to DataFrame for easier display\n",
    "    df_linear_encoding = pd.read_csv(csv_file_linear_encoding)\n",
    "    \n",
    "    def color_red_column(s):\n",
    "        return ['color: red' if v else '' for v in s]\n",
    "    \n",
    "    styled_df_linear_encoding = df_linear_encoding.style.apply(color_red_column, subset=['test_loss'])\n",
    "    \n",
    "    # Display the DataFrame as a table\n",
    "    display(styled_df_linear_encoding)\n",
    "    #qgrid_widget = qgrid.show_grid(df, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea88851-ed24-42d4-b36c-e79175af6847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Decide which model file & test set to use\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTry Both\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ENCODING_TYPE:\n\u001b[0;32m----> 3\u001b[0m     chosen_path \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model_file\u001b[49m\n\u001b[1;32m      4\u001b[0m     X_test_cur \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X_test)\n\u001b[1;32m      5\u001b[0m     y_value_test_cur \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_value_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Decide which model file & test set to use\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    chosen_path = best_model_file\n",
    "    X_test_cur = np.asarray(X_test)\n",
    "    y_value_test_cur = np.asarray(y_value_test)\n",
    "    y_exists_test_cur = np.asarray(y_exists_test)\n",
    "else:\n",
    "    if test_loss_result_linear_encoding < test_loss_result_one_hot_encoding:\n",
    "        chosen_path = best_model_file_linear\n",
    "        X_test_cur = np.asarray(X_test_linear_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_linear_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_linear_encoding)\n",
    "        y_encoding_format_name = 'linear'\n",
    "    else:\n",
    "        chosen_path = best_model_file_onehot\n",
    "        X_test_cur = np.asarray(X_test_one_hot_encoding)\n",
    "        y_value_test_cur = np.asarray(y_value_test_one_hot_encoding)\n",
    "        y_exists_test_cur = np.asarray(y_exists_test_one_hot_encoding)\n",
    "        y_encoding_format_name = 'one_hot'\n",
    "\n",
    "# clear everything again, then load & predict on one cpu device to avoid the memory thing again\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    chosen_model = load_model(chosen_path, compile=False)\n",
    "    pred = chosen_model.predict(X_test_cur, verbose=0)\n",
    "\n",
    "# Unpack model outputs into proper numeric arrays\n",
    "if isinstance(pred, dict):\n",
    "    y_value_pred = np.asarray(pred['value_out'])\n",
    "    y_exists_pred = np.asarray(pred['exists_out'])\n",
    "else:\n",
    "    y_value_pred, y_exists_pred = pred\n",
    "    y_value_pred = np.asarray(y_value_pred)\n",
    "    y_exists_pred = np.asarray(y_exists_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffa127-c6a4-4a52-8a29-4c08ae0cca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets look at a specfic case to see how the model predicts things\n",
    "if 'Try Both' not in ENCODING_TYPE:\n",
    "    y_encoding_format_name = encoding\n",
    "    \n",
    "filename = f'y_characteristics_{y_encoding_format_name}_encoding.csv'\n",
    "with open(filename, 'r') as f:\n",
    "    headers = f.readline().strip().split(',')\n",
    "\n",
    "X_test_cur = np.asarray(X_test_cur)\n",
    "y_value_test_cur = np.asarray(y_value_test_cur)\n",
    "y_exists_test_cur = np.asarray(y_exists_test_cur)\n",
    "y_value_pred = np.asarray(y_value_pred)\n",
    "\n",
    "n_samples, n_params = y_value_test_cur.shape\n",
    "#change nsamples if you dont want to look at everything\n",
    "n_samples = 3\n",
    "\n",
    "# raw errors\n",
    "sq_errors = (y_value_test_cur - y_value_pred) ** 2\n",
    "abs_errors = np.abs(y_value_test_cur - y_value_pred)\n",
    "\n",
    "# mask out parameters that are \"not defined\" according to the ground-truth exists flag\n",
    "sq_errors_masked = np.where(y_exists_test_cur == 1.0, sq_errors, np.nan)\n",
    "abs_errors_masked = np.where(y_exists_test_cur == 1.0, abs_errors, np.nan)\n",
    "\n",
    "# make a nice dataframe so the output is comprehensible\n",
    "rows = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_cur[i, 0], X_test_cur[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref\": y_value_test_cur[i, j],\n",
    "            \"pred\": y_value_pred[i, j],\n",
    "            \"abs_error\": abs_errors_masked[i, j],\n",
    "            \"sq_error\": sq_errors_masked[i, j],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "#save it incase we want to do stuff with this in the future\n",
    "out_csv = Path(f\"predictions_and_errors_{y_encoding_format_name}.csv\")\n",
    "df.to_csv(out_csv, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv.resolve()}\\n\")\n",
    "\n",
    "# print it out nicely \n",
    "for i in range(n_samples):\n",
    "    sub = df[df[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref\", \"pred\", \"abs_error\", \"sq_error\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i}  \"\n",
    "        f\"X: cavity_frequency={X_test_cur[i,0]:.6g}, kappa={X_test_cur[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print() \n",
    "\n",
    "# (Optional) quick global stats (only over defined parameters)\n",
    "print(\"Global error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_masked)))\n",
    "\n",
    "''' \n",
    "Here onehot/linear encoding and the mlp which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304c67f-9838-491f-869c-e51d86748217",
   "metadata": {},
   "source": [
    "### Unscaled test vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05f774-e63a-4325-86eb-c091a1c286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unscale everything and look at errors again. \n",
    "#You can compare the unscaled actual values to the ml_00...py notebook to convice yourself that unscaling worked\n",
    "\n",
    "with open('X_names', 'r') as f:\n",
    "    X_index_names = f.read().splitlines()\n",
    "\n",
    "# unscaling x\n",
    "X_test_unscaled = np.asarray(X_test_cur.copy())\n",
    "for i in range(X_test_unscaled.shape[0]):\n",
    "    for j in range(X_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_X_{X_index_names[j]}.save')\n",
    "        X_test_unscaled[i, j] = scaler.inverse_transform([[X_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y (value head only)\n",
    "y_value_test_unscaled = np.asarray(y_value_test_cur.copy())\n",
    "for i in range(y_value_test_unscaled.shape[0]):\n",
    "    for j in range(y_value_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_test_unscaled[i, j] = scaler.inverse_transform([[y_value_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscaling y predictions (value head only)\n",
    "y_value_pred_unscaled = np.asarray(y_value_pred.copy())\n",
    "for i in range(y_value_pred_unscaled.shape[0]):\n",
    "    for j in range(y_value_pred_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_pred_unscaled[i, j] = scaler.inverse_transform([[y_value_pred_unscaled[i, j]]])[0][0]\n",
    "\n",
    "n_samples, n_params = y_value_test_unscaled.shape\n",
    "n_samples = 3 \n",
    "\n",
    "# find how good or bad we did (the errors)\n",
    "sq_errors_unscaled = (y_value_test_unscaled - y_value_pred_unscaled) ** 2\n",
    "abs_errors_unscaled = np.abs(y_value_test_unscaled - y_value_pred_unscaled)\n",
    "\n",
    "# mask out parameters that are not defined according to ground-truth exists flag\n",
    "sq_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, sq_errors_unscaled, np.nan)\n",
    "abs_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, abs_errors_unscaled, np.nan)\n",
    "\n",
    "# making a nice fancy dataframe, we like fancy things\n",
    "rows_unscaled = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_unscaled[i, 0], X_test_unscaled[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows_unscaled.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists\": y_exists_test_cur[i, j],\n",
    "            \"ref_unscaled\": y_value_test_unscaled[i, j],\n",
    "            \"pred_unscaled\": y_value_pred_unscaled[i, j],\n",
    "            \"abs_error_unscaled\": abs_errors_unscaled_masked[i, j],\n",
    "            \"sq_error_unscaled\": sq_errors_unscaled_masked[i, j],\n",
    "        })\n",
    "\n",
    "df_unscaled = pd.DataFrame(rows_unscaled)\n",
    "\n",
    "# save csv of unscaled results uncase we lose this notebook due to github blowing up, ya never know\n",
    "out_csv_unscaled = Path(f\"predictions_and_errors_unscaled_{y_encoding_format_name}.csv\")\n",
    "df_unscaled.to_csv(out_csv_unscaled, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv_unscaled.resolve()}\\n\")\n",
    "\n",
    "# print out stuff so you can see it here if you are to lazy like me to open a csv\n",
    "for i in range(n_samples):\n",
    "    sub = df_unscaled[df_unscaled[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\"param\", \"exists\", \"ref_unscaled\", \"pred_unscaled\", \"abs_error_unscaled\", \"sq_error_unscaled\"]]\n",
    "    header_line = (\n",
    "        f\" Sample {i} (Unscaled)  \"\n",
    "        f\"X: cavity_frequency={X_test_unscaled[i,0]:.6g}, kappa={X_test_unscaled[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# look at overall stats, see below comment for a caviat \n",
    "print(\"Global unscaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_unscaled_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_unscaled_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_unscaled_masked)))\n",
    "\n",
    "'''\n",
    "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably \n",
    "throwing off the global average. These will be rounded in the future and will probably always \n",
    "round to the right number to reconstruct the correct category-- but for now it might throw off \n",
    "the overall average error. In the future we might want to just have it consider the non-categorical \n",
    "data when finding an overall average and reporting that number.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da89f-f7e8-4672-b054-bcf439f5b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a76783-7ab4-4458-b944-4ddb2526ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f91622-6756-4bdb-b440-2a0b844fa80e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
