{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b8e1e",
   "metadata": {},
   "source": [
    "# Model Predictions (cavity_claw_RouteMeander_eigenmode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7659a-fe1b-4fdf-8c09-a398e498373b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9418886-6a3f-4473-ae89-53bab6428eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter file is where the hyperparameters are set. \n",
    "# It's reccomended to look at that file first, its interesting and you can set stuff there\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17135-58ce-45e4-9c16-1d1b76f34ea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa89948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf# Disable some console warnings so you can be free of them printing. \n",
    "# Comment the next two lines if you are a professional and like looking at warnings.\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import os, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad03d-ae5d-4bc6-b055-3e8579849c5d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0b8c-6699-4caf-b257-abc4f8e49b99",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667c238f-0e0f-4e4c-b185-f76d1ca261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the nice data you saved from the previous notebook, or downloaded from the drive\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        encoding = ENCODING_TYPE.replace(' ','_')\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'Linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'Linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec9efd-ee93-429d-95b4-4e6efef296db",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd39ffbc-5524-4ce0-bcc1-4fd67727e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which model file & test set to use\n",
    "chosen_path = \"model/best_keras_model_one_hot_encoding.keras\"\n",
    "\n",
    "# Current test arrays (value + exists)\n",
    "X_test_cur        = np.asarray(X_test)\n",
    "y_value_test_cur  = np.asarray(y_value_test)\n",
    "y_exists_test_cur = np.asarray(y_exists_test)\n",
    "\n",
    "# Name used for CSV / scalers, e.g. \"one_hot\" or \"linear\"\n",
    "y_encoding_format_name = encoding  # e.g. \"one_hot\"\n",
    "\n",
    "# Load y headers for labeling columns\n",
    "y_headers_csv = f\"y_characteristics_{y_encoding_format_name}_encoding.csv\"\n",
    "with open(y_headers_csv, \"r\") as f:\n",
    "    headers = f.readline().strip().split(\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a01e10-6cc5-4940-8091-8dadea6062ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "—— best_keras_model_one_hot_encoding.keras ——\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">570</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,710</span> │ input1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu0         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">570</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">570</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">291,210</span> │ dropout0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">127,750</span> │ dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,440</span> │ dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">211,680</span> │ dropout3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ exists_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,696</span> │ dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,696</span> │ dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input1 (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc0 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m570\u001b[0m)       │      \u001b[38;5;34m1,710\u001b[0m │ input1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu0         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m570\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout0 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m570\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m)       │    \u001b[38;5;34m291,210\u001b[0m │ dropout0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)       │    \u001b[38;5;34m127,750\u001b[0m │ dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc3 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m)       │    \u001b[38;5;34m110,440\u001b[0m │ dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc4 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)       │    \u001b[38;5;34m211,680\u001b[0m │ dropout3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout4 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ exists_out (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m7,696\u001b[0m │ dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_out (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m7,696\u001b[0m │ dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">758,182</span> (2.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m758,182\u001b[0m (2.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">758,182</span> (2.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m758,182\u001b[0m (2.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 183 | Value targets dim: 16 | Exists targets dim: 16\n"
     ]
    }
   ],
   "source": [
    "# run on CPU\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "try:\n",
    "    tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    chosen_model = load_model(chosen_path, compile=False)\n",
    "    pred = chosen_model.predict(X_test_cur, verbose=0)\n",
    "\n",
    "# unpack model outputs into value and exists predictions\n",
    "if isinstance(pred, dict):\n",
    "    y_value_pred = np.asarray(pred['value_out'])\n",
    "    y_exists_pred = np.asarray(pred['exists_out'])\n",
    "else:\n",
    "    y_value_pred, y_exists_pred = pred\n",
    "    y_value_pred = np.asarray(y_value_pred)\n",
    "    y_exists_pred = np.asarray(y_exists_pred)\n",
    "\n",
    "y_exists_pred_prob = np.asarray(y_exists_pred, dtype=float)\n",
    "y_exists_pred_mask = (y_exists_pred_prob >= 0.5).astype(float)\n",
    "\n",
    "print(f\"\\n—— {os.path.basename(chosen_path)} ——\")\n",
    "chosen_model.summary()\n",
    "print(f\"Samples: {len(X_test_cur)} | Value targets dim: {y_value_test_cur.shape[1]} | Exists targets dim: {y_exists_test_cur.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e42f1-a716-4df1-b092-386ca784f727",
   "metadata": {},
   "source": [
    "# Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bee83ea-6fdb-484e-9dae-e2d619708fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_one_hot.csv\n",
      "\n",
      "— Sample 0 — X: cavity_frequency=0.0208384, kappa=0.16982\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999973               1.0 0.403941  0.409193   0.005252 2.758260e-05\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999976               1.0 0.000000 -0.002957   0.002957 8.742485e-06\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999971               1.0 0.000000 -0.005582   0.005582 3.115487e-05\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999969               1.0 0.000000  0.002558   0.002558 6.544872e-06\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999970               1.0 0.000000 -0.000420   0.000420 1.762846e-07\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999970               1.0 0.000000 -0.000630   0.000630 3.969078e-07\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999972               1.0 0.428571  0.338296   0.090275 8.149627e-03\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999971               1.0 1.000000  0.987233   0.012767 1.630074e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry          1.0          0.999821               1.0 0.956522  0.889393   0.067129 4.506287e-03\n",
      "                       design_options.cplr_opts.coupling_length          1.0          0.999843               1.0 0.700000  0.670904   0.029096 8.465506e-04\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.724390               1.0 1.000000  0.997789   0.002211 4.889727e-06\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000031               0.0 0.000000 -0.073937        NaN          NaN\n",
      "                                               coupler_type_CLT          1.0          0.999975               1.0 1.000000  0.997852   0.002148 4.613018e-06\n",
      "                                              coupler_type_NCap          1.0          0.999970               1.0 0.000000 -0.001914   0.001914 3.665229e-06\n",
      "                                            resonator_type_half          1.0          0.999972               1.0 0.000000  0.004170   0.004170 1.738797e-05\n",
      "                                         resonator_type_quarter          1.0          0.999964               1.0 1.000000  0.997970   0.002030 4.119267e-06\n",
      "\n",
      "— Sample 1 — X: cavity_frequency=0.147811, kappa=0.00035887\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999963               1.0 0.236453  0.128514   0.107939 1.165086e-02\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999970               1.0 0.000000 -0.004580   0.004580 2.097878e-05\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999963               1.0 0.000000 -0.003529   0.003529 1.245727e-05\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999955               1.0 1.000000  0.999734   0.000266 7.098642e-08\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999960               1.0 1.000000  0.995628   0.004372 1.911335e-05\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999962               1.0 1.000000  0.994500   0.005500 3.025348e-05\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999963               1.0 0.714286  0.685780   0.028506 8.126036e-04\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999965               1.0 1.000000  0.995155   0.004845 2.347771e-05\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.004506               0.0 0.652174  0.598722        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.004005               0.0 0.000000  0.378067        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.993564               1.0 0.500000  0.499673   0.000327 1.070791e-07\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000041               0.0 0.000000 -0.090683        NaN          NaN\n",
      "                                               coupler_type_CLT          1.0          0.999969               1.0 0.000000  0.004356   0.004356 1.897445e-05\n",
      "                                              coupler_type_NCap          1.0          0.999960               1.0 1.000000  0.994730   0.005270 2.777106e-05\n",
      "                                            resonator_type_half          1.0          0.999964               1.0 1.000000  0.998182   0.001818 3.304912e-06\n",
      "                                         resonator_type_quarter          1.0          0.999950               1.0 0.000000  0.003959   0.003959 1.567274e-05\n",
      "\n",
      "— Sample 2 — X: cavity_frequency=0.255023, kappa=0.00060377\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999961               1.0 0.019704  0.129605   0.109901 1.207814e-02\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999969               1.0 0.000000 -0.004491   0.004491 2.016718e-05\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999961               1.0 0.000000 -0.001706   0.001706 2.908804e-06\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999954               1.0 1.000000  1.001314   0.001314 1.727652e-06\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999959               1.0 1.000000  0.997063   0.002937 8.626430e-06\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999960               1.0 1.000000  0.995804   0.004196 1.760932e-05\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999961               1.0 0.500000  0.493950   0.006050 3.659842e-05\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999963               1.0 1.000000  0.994166   0.005834 3.403258e-05\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.002333               0.0 0.652174  0.579884        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.002058               0.0 0.000000  0.384524        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.995454               1.0 0.500000  0.496742   0.003258 1.061741e-05\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000043               0.0 0.000000 -0.094343        NaN          NaN\n",
      "                                               coupler_type_CLT          1.0          0.999968               1.0 0.000000  0.000445   0.000445 1.976612e-07\n",
      "                                              coupler_type_NCap          1.0          0.999958               1.0 1.000000  0.996556   0.003444 1.186166e-05\n",
      "                                            resonator_type_half          1.0          0.999962               1.0 1.000000  0.999498   0.000502 2.516354e-07\n",
      "                                         resonator_type_quarter          1.0          0.999949               1.0 0.000000 -0.000089   0.000089 8.004267e-09\n",
      "\n",
      "Global scaled error stats (defined parameters only):\n",
      "  min abs_error: 5.960464477539063e-08\n",
      "  median abs_error: 0.0042505450546741486\n",
      "  max abs_error: 1.0033009187318385\n",
      "\n",
      "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a smaller view if you want\n",
    "N_SAMPLES_TO_SHOW = 3\n",
    "\n",
    "n_samples = min(N_SAMPLES_TO_SHOW, len(X_test_cur))\n",
    "n_params  = y_value_test_cur.shape[1]\n",
    "\n",
    "# scaled errors (values only)\n",
    "sq_errors  = (y_value_test_cur - y_value_pred) ** 2\n",
    "abs_errors = np.abs(y_value_test_cur - y_value_pred)\n",
    "\n",
    "# mask out parameters that are \"not defined\" according to the ground-truth exists flag\n",
    "sq_errors_masked  = np.where(y_exists_test_cur == 1.0, sq_errors,  np.nan)\n",
    "abs_errors_masked = np.where(y_exists_test_cur == 1.0, abs_errors, np.nan)\n",
    "\n",
    "# scaled dataframe\n",
    "rows = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_cur[i, 0], X_test_cur[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists_true\": float(y_exists_test_cur[i, j]),\n",
    "            \"exists_pred_prob\": float(y_exists_pred_prob[i, j]),\n",
    "            \"exists_pred_mask\": float(y_exists_pred_mask[i, j]),\n",
    "            \"ref\":  float(y_value_test_cur[i, j]),\n",
    "            \"pred\": float(y_value_pred[i, j]),\n",
    "            \"abs_error\": float(abs_errors_masked[i, j]),\n",
    "            \"sq_error\":  float(sq_errors_masked[i, j]),\n",
    "        })\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# save scaled predictions\n",
    "out_csv = Path(f\"predictions_and_errors_{y_encoding_format_name}.csv\")\n",
    "df.to_csv(out_csv, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv.resolve()}\\n\")\n",
    "\n",
    "# pretty print per-sample (scaled)\n",
    "for i in range(n_samples):\n",
    "    sub = df[df[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\n",
    "        \"param\",\n",
    "        \"exists_true\",\n",
    "        \"exists_pred_prob\",\n",
    "        \"exists_pred_mask\",\n",
    "        \"ref\",\n",
    "        \"pred\",\n",
    "        \"abs_error\",\n",
    "        \"sq_error\"\n",
    "    ]]\n",
    "    header_line = (\n",
    "        f\"— Sample {i} — \"\n",
    "        f\"X: cavity_frequency={X_test_cur[i,0]:.6g}, kappa={X_test_cur[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# global stats over defined parameters only\n",
    "print(\"Global scaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_masked)))\n",
    "print(\"\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b3b8b-8dc3-4512-9363-14e32cabeea7",
   "metadata": {},
   "source": [
    "# Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3bc71-1fbe-4438-bcd9-efac2dc55911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X feature names for the X scalers\n",
    "with open('X_names', 'r') as f:\n",
    "    X_index_names = f.read().splitlines()\n",
    "\n",
    "# unscale X\n",
    "X_test_unscaled = np.asarray(X_test_cur.copy())\n",
    "for i in range(X_test_unscaled.shape[0]):\n",
    "    for j in range(X_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_X_{X_index_names[j]}.save')\n",
    "        X_test_unscaled[i, j] = scaler.inverse_transform([[X_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscale y VALUES (refs and preds) – exists stays as 0/1 / probabilities\n",
    "y_value_test_unscaled = np.asarray(y_value_test_cur.copy(), dtype=float)\n",
    "y_value_pred_unscaled = np.asarray(y_value_pred.copy(), dtype=float)\n",
    "n_params = y_value_test_unscaled.shape[1]\n",
    "\n",
    "for i in range(y_value_test_unscaled.shape[0]):\n",
    "    for j in range(y_value_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_test_unscaled[i, j] = scaler.inverse_transform([[y_value_test_unscaled[i, j]]])[0][0]\n",
    "        y_value_pred_unscaled[i, j] = scaler.inverse_transform([[y_value_pred_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# errors (unscaled, values only)\n",
    "sq_errors_unscaled  = (y_value_test_unscaled - y_value_pred_unscaled) ** 2\n",
    "abs_errors_unscaled = np.abs(y_value_test_unscaled - y_value_pred_unscaled)\n",
    "\n",
    "# mask out parameters that are not defined (according to ground-truth exists)\n",
    "sq_errors_unscaled_masked  = np.where(y_exists_test_cur == 1.0, sq_errors_unscaled,  np.nan)\n",
    "abs_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, abs_errors_unscaled, np.nan)\n",
    "\n",
    "# build dataframe (unscaled)\n",
    "rows_unscaled = []\n",
    "n_samples_to_show = min(N_SAMPLES_TO_SHOW, len(X_test_unscaled))\n",
    "for i in range(n_samples_to_show):\n",
    "    cav_freq, kappa = X_test_unscaled[i, 0], X_test_unscaled[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows_unscaled.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists_true\": float(y_exists_test_cur[i, j]),\n",
    "            \"exists_pred_prob\": float(y_exists_pred_prob[i, j]),\n",
    "            \"exists_pred_mask\": float(y_exists_pred_mask[i, j]),\n",
    "            \"ref_unscaled\":  float(y_value_test_unscaled[i, j]),\n",
    "            \"pred_unscaled\": float(y_value_pred_unscaled[i, j]),\n",
    "            \"abs_error_unscaled\": float(abs_errors_unscaled_masked[i, j]),\n",
    "            \"sq_error_unscaled\":  float(sq_errors_unscaled_masked[i, j]),\n",
    "        })\n",
    "df_unscaled = pd.DataFrame(rows_unscaled)\n",
    "\n",
    "# save (unscaled)\n",
    "out_csv_unscaled = Path(f\"predictions_and_errors_unscaled_{y_encoding_format_name}.csv\")\n",
    "df_unscaled.to_csv(out_csv_unscaled, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv_unscaled.resolve()}\\n\")\n",
    "\n",
    "# pretty print per-sample (unscaled)\n",
    "for i in range(n_samples_to_show):\n",
    "    sub = df_unscaled[df_unscaled[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\n",
    "        \"param\",\n",
    "        \"exists_true\",\n",
    "        \"exists_pred_prob\",\n",
    "        \"exists_pred_mask\",\n",
    "        \"ref_unscaled\",\n",
    "        \"pred_unscaled\",\n",
    "        \"abs_error_unscaled\",\n",
    "        \"sq_error_unscaled\"\n",
    "    ]]\n",
    "    header_line = (\n",
    "        f\"— Sample {i} (Unscaled) — \"\n",
    "        f\"X: cavity_frequency={X_test_unscaled[i,0]:.6g}, kappa={X_test_unscaled[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# global stats over defined parameters only\n",
    "print(\"Global unscaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_unscaled_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_unscaled_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_unscaled_masked)))\n",
    "print(\"\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810c676-fbc7-4fa0-8ebb-6d2e8d535f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125bf92-a6e5-4184-b128-f066af5281bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613ef96-143b-4551-aacf-aa52b963fdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926af15-e113-4f59-8f20-6ee916619a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860b771-2059-4f3f-88cc-05e64726b367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65de61e-3ca1-4b4f-a366-adc049c68161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
