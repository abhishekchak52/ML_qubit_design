{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b8e1e",
   "metadata": {},
   "source": [
    "# Model Predictions (cavity_claw_RouteMeander_eigenmode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7659a-fe1b-4fdf-8c09-a398e498373b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9418886-6a3f-4473-ae89-53bab6428eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter file is where the hyperparameters are set. \n",
    "# It's reccomended to look at that file first, its interesting and you can set stuff there\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17135-58ce-45e4-9c16-1d1b76f34ea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa89948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf# Disable some console warnings so you can be free of them printing. \n",
    "# Comment the next two lines if you are a professional and like looking at warnings.\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import os, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad03d-ae5d-4bc6-b055-3e8579849c5d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0b8c-6699-4caf-b257-abc4f8e49b99",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667c238f-0e0f-4e4c-b185-f76d1ca261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the nice data you saved from the previous notebook, or downloaded from the drive\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        encoding = ENCODING_TYPE.replace(' ','_')\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'Linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding_augmented.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    if 'Try Both' not in ENCODING_TYPE:\n",
    "        if 'one hot' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        elif 'Linear' in ENCODING_TYPE:\n",
    "            X_train = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_val = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            X_test = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_value_train = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_val = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_value_test = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "            y_exists_train = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_val = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "            y_exists_test = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "    elif 'Try Both' in ENCODING_TYPE:\n",
    "        # one-hot branch\n",
    "        X_train_one_hot_encoding = np.load('{}/npy/x_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_one_hot_encoding = np.load('{}/npy/x_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_one_hot_encoding = np.load('{}/npy/x_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_one_hot_encoding = np.load('{}/npy/y_value_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_one_hot_encoding = np.load('{}/npy/y_value_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_one_hot_encoding = np.load('{}/npy/y_value_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_one_hot_encoding = np.load('{}/npy/y_exists_train_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_one_hot_encoding = np.load('{}/npy/y_exists_val_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_one_hot_encoding = np.load('{}/npy/y_exists_test_one_hot_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        # linear branch\n",
    "        X_train_linear_encoding = np.load('{}/npy/x_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_val_linear_encoding = np.load('{}/npy/x_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        X_test_linear_encoding = np.load('{}/npy/x_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_value_train_linear_encoding = np.load('{}/npy/y_value_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_val_linear_encoding = np.load('{}/npy/y_value_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_value_test_linear_encoding = np.load('{}/npy/y_value_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "\n",
    "        y_exists_train_linear_encoding = np.load('{}/npy/y_exists_train_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_val_linear_encoding = np.load('{}/npy/y_exists_val_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n",
    "        y_exists_test_linear_encoding = np.load('{}/npy/y_exists_test_linear_encoding.npy'.format(DATA_DIR), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec9efd-ee93-429d-95b4-4e6efef296db",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd39ffbc-5524-4ce0-bcc1-4fd67727e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which model file & test set to use\n",
    "chosen_path = \"model/best_keras_model_one_hot_encoding.keras\"\n",
    "\n",
    "# Current test arrays (value + exists)\n",
    "X_test_cur        = np.asarray(X_test)\n",
    "y_value_test_cur  = np.asarray(y_value_test)\n",
    "y_exists_test_cur = np.asarray(y_exists_test)\n",
    "\n",
    "# Name used for CSV / scalers, e.g. \"one_hot\" or \"linear\"\n",
    "y_encoding_format_name = encoding  # e.g. \"one_hot\"\n",
    "\n",
    "# Load y headers for labeling columns\n",
    "y_headers_csv = f\"y_characteristics_{y_encoding_format_name}_encoding.csv\"\n",
    "with open(y_headers_csv, \"r\") as f:\n",
    "    headers = f.readline().strip().split(\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a01e10-6cc5-4940-8091-8dadea6062ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "—— best_keras_model_one_hot_encoding.keras ——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768504305.210812  112877 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ input1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu0         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">352,550</span> │ dropout0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">468,350</span> │ dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">468,050</span> │ dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">776,910</span> │ dropout3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fc4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1410</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_relu4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,576</span> │ dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ exists_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,576</span> │ dropout4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input1 (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc0 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)       │      \u001b[38;5;34m1,920\u001b[0m │ input1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu0         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout0 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │    \u001b[38;5;34m352,550\u001b[0m │ dropout0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)       │    \u001b[38;5;34m468,350\u001b[0m │ dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m850\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc3 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │    \u001b[38;5;34m468,050\u001b[0m │ dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fc3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_relu3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fc4 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)      │    \u001b[38;5;34m776,910\u001b[0m │ dropout3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_relu4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ fc4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout4 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1410\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ leaky_relu4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_out (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m22,576\u001b[0m │ dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ exists_out (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m22,576\u001b[0m │ dropout4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112,932</span> (8.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,112,932\u001b[0m (8.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112,932</span> (8.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,112,932\u001b[0m (8.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 183 | Value targets dim: 16 | Exists targets dim: 16\n"
     ]
    }
   ],
   "source": [
    "# run on CPU\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "try:\n",
    "    tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    chosen_model = load_model(chosen_path, compile=False)\n",
    "    pred = chosen_model.predict(X_test_cur, verbose=0)\n",
    "\n",
    "# unpack model outputs into value and exists predictions\n",
    "if isinstance(pred, dict):\n",
    "    y_value_pred = np.asarray(pred['value_out'])\n",
    "    y_exists_pred = np.asarray(pred['exists_out'])\n",
    "else:\n",
    "    y_value_pred, y_exists_pred = pred\n",
    "    y_value_pred = np.asarray(y_value_pred)\n",
    "    y_exists_pred = np.asarray(y_exists_pred)\n",
    "\n",
    "y_exists_pred_prob = np.asarray(y_exists_pred, dtype=float)\n",
    "y_exists_pred_mask = (y_exists_pred_prob >= 0.5).astype(float)\n",
    "\n",
    "print(f\"\\n—— {os.path.basename(chosen_path)} ——\")\n",
    "chosen_model.summary()\n",
    "print(f\"Samples: {len(X_test_cur)} | Value targets dim: {y_value_test_cur.shape[1]} | Exists targets dim: {y_exists_test_cur.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e42f1-a716-4df1-b092-386ca784f727",
   "metadata": {},
   "source": [
    "# Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bee83ea-6fdb-484e-9dae-e2d619708fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_one_hot.csv\n",
      "\n",
      "— Sample 0 — X: cavity_frequency=0.0208384, kappa=0.16982\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error  sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999959               1.0 0.403941  0.420213   0.016272  0.000265\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999962               1.0 0.000000  0.097638   0.097638  0.009533\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999958               1.0 0.000000 -0.002075   0.002075  0.000004\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999960               1.0 0.000000 -0.008900   0.008900  0.000079\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999960               1.0 0.000000 -0.009580   0.009580  0.000092\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999962               1.0 0.000000 -0.009350   0.009350  0.000087\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999958               1.0 0.428571  0.329074   0.099497  0.009900\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999960               1.0 1.000000  0.724063   0.275937  0.076141\n",
      "                      design_options.cpw_opts.meander.asymmetry          1.0          0.999211               1.0 0.956522  0.722798   0.233724  0.054627\n",
      "                       design_options.cplr_opts.coupling_length          1.0          0.999208               1.0 0.700000  0.561749   0.138251  0.019113\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.712510               1.0 1.000000  0.728904   0.271096  0.073493\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000041               0.0 0.000000  0.000643        NaN       NaN\n",
      "                                               coupler_type_CLT          1.0          0.999959               1.0 1.000000  1.011920   0.011920  0.000142\n",
      "                                              coupler_type_NCap          1.0          0.999963               1.0 0.000000 -0.009432   0.009432  0.000089\n",
      "                                            resonator_type_half          1.0          0.999960               1.0 0.000000 -0.008767   0.008767  0.000077\n",
      "                                         resonator_type_quarter          1.0          0.999961               1.0 1.000000  1.012665   0.012665  0.000160\n",
      "\n",
      "— Sample 1 — X: cavity_frequency=0.147811, kappa=0.00035887\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999943               1.0 0.236453  0.137109   0.099344 9.869286e-03\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999947               1.0 0.000000 -0.000495   0.000495 2.449658e-07\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999944               1.0 0.000000 -0.034733   0.034733 1.206358e-03\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999946               1.0 1.000000  0.988958   0.011042 1.219244e-04\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999944               1.0 1.000000  0.987411   0.012589 1.584944e-04\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999946               1.0 1.000000  0.988160   0.011840 1.401810e-04\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999941               1.0 0.714286  0.675717   0.038569 1.487560e-03\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999947               1.0 1.000000  0.982249   0.017751 3.150845e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.007971               0.0 0.652174  0.652069        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.008047               0.0 0.000000 -0.004198        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.982315               1.0 0.500000  0.490310   0.009690 9.390104e-05\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000057               0.0 0.000000  0.000774        NaN          NaN\n",
      "                                               coupler_type_CLT          1.0          0.999943               1.0 0.000000  0.013691   0.013691 1.874382e-04\n",
      "                                              coupler_type_NCap          1.0          0.999949               1.0 1.000000  0.987152   0.012848 1.650747e-04\n",
      "                                            resonator_type_half          1.0          0.999946               1.0 1.000000  0.987716   0.012284 1.508976e-04\n",
      "                                         resonator_type_quarter          1.0          0.999947               1.0 0.000000  0.014400   0.014400 2.073516e-04\n",
      "\n",
      "— Sample 2 — X: cavity_frequency=0.255023, kappa=0.00060377\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask      ref      pred  abs_error     sq_error\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999944               1.0 0.019704  0.136913   0.117209 1.373783e-02\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999947               1.0 0.000000 -0.000047   0.000047 2.205336e-09\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999944               1.0 0.000000  0.054205   0.054205 2.938218e-03\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999947               1.0 1.000000  0.996795   0.003205 1.027433e-05\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999944               1.0 1.000000  0.995077   0.004923 2.423227e-05\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999947               1.0 1.000000  0.995468   0.004532 2.054046e-05\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999942               1.0 0.500000  0.573093   0.073093 5.342517e-03\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999947               1.0 1.000000  0.987086   0.012914 1.667699e-04\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.004434               0.0 0.652174  0.651396        NaN          NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.004456               0.0 0.000000 -0.006933        NaN          NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.987342               1.0 0.500000  0.490916   0.009084 8.252206e-05\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000057               0.0 0.000000  0.000401        NaN          NaN\n",
      "                                               coupler_type_CLT          1.0          0.999943               1.0 0.000000  0.005688   0.005688 3.235822e-05\n",
      "                                              coupler_type_NCap          1.0          0.999949               1.0 1.000000  0.994758   0.005242 2.747846e-05\n",
      "                                            resonator_type_half          1.0          0.999947               1.0 1.000000  0.995757   0.004243 1.800218e-05\n",
      "                                         resonator_type_quarter          1.0          0.999948               1.0 0.000000  0.005551   0.005551 3.081570e-05\n",
      "\n",
      "Global scaled error stats (defined parameters only):\n",
      "  min abs_error: 1.735985279083252e-06\n",
      "  median abs_error: 0.01372167095541954\n",
      "  max abs_error: 0.911139316856861\n",
      "\n",
      "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a smaller view if you want\n",
    "N_SAMPLES_TO_SHOW = 3\n",
    "\n",
    "n_samples = min(N_SAMPLES_TO_SHOW, len(X_test_cur))\n",
    "n_params  = y_value_test_cur.shape[1]\n",
    "\n",
    "# scaled errors (values only)\n",
    "sq_errors  = (y_value_test_cur - y_value_pred) ** 2\n",
    "abs_errors = np.abs(y_value_test_cur - y_value_pred)\n",
    "\n",
    "# mask out parameters that are \"not defined\" according to the ground-truth exists flag\n",
    "sq_errors_masked  = np.where(y_exists_test_cur == 1.0, sq_errors,  np.nan)\n",
    "abs_errors_masked = np.where(y_exists_test_cur == 1.0, abs_errors, np.nan)\n",
    "\n",
    "# scaled dataframe\n",
    "rows = []\n",
    "for i in range(n_samples):\n",
    "    cav_freq, kappa = X_test_cur[i, 0], X_test_cur[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists_true\": float(y_exists_test_cur[i, j]),\n",
    "            \"exists_pred_prob\": float(y_exists_pred_prob[i, j]),\n",
    "            \"exists_pred_mask\": float(y_exists_pred_mask[i, j]),\n",
    "            \"ref\":  float(y_value_test_cur[i, j]),\n",
    "            \"pred\": float(y_value_pred[i, j]),\n",
    "            \"abs_error\": float(abs_errors_masked[i, j]),\n",
    "            \"sq_error\":  float(sq_errors_masked[i, j]),\n",
    "        })\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# save scaled predictions\n",
    "out_csv = Path(f\"predictions_and_errors_{y_encoding_format_name}.csv\")\n",
    "df.to_csv(out_csv, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv.resolve()}\\n\")\n",
    "\n",
    "# pretty print per-sample (scaled)\n",
    "for i in range(n_samples):\n",
    "    sub = df[df[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\n",
    "        \"param\",\n",
    "        \"exists_true\",\n",
    "        \"exists_pred_prob\",\n",
    "        \"exists_pred_mask\",\n",
    "        \"ref\",\n",
    "        \"pred\",\n",
    "        \"abs_error\",\n",
    "        \"sq_error\"\n",
    "    ]]\n",
    "    header_line = (\n",
    "        f\"— Sample {i} — \"\n",
    "        f\"X: cavity_frequency={X_test_cur[i,0]:.6g}, kappa={X_test_cur[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# global stats over defined parameters only\n",
    "print(\"Global scaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_masked)))\n",
    "print(\"\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b3b8b-8dc3-4512-9363-14e32cabeea7",
   "metadata": {},
   "source": [
    "# Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f3bc71-1fbe-4438-bcd9-efac2dc55911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV -> /home/olivias/ML_qubit_design/model_predict_cavity_claw_RouteMeander_eigenmode/predictions_and_errors_unscaled_one_hot.csv\n",
      "\n",
      "— Sample 0 (Unscaled) — X: cavity_frequency=5.24699e+09, kappa=168252\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999959               1.0      0.000275   2.832581e-04        8.258074e-06       6.819579e-11\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999962               1.0      0.000004   4.676063e-06        5.760632e-07       3.318488e-13\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999958               1.0     -0.001500  -1.501037e-03        1.037287e-06       1.075963e-12\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999960               1.0      0.000000  -2.136069e-06        2.136069e-06       4.562792e-12\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999960               1.0      0.000000  -2.874005e-07        2.874005e-07       8.259904e-14\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999962               1.0      0.000000  -2.805008e-07        2.805008e-07       7.868072e-14\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999958               1.0      0.004700   4.003518e-03        6.964822e-04       4.850875e-07\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999960               1.0      0.000100   8.620317e-05        1.379683e-05       1.903525e-10\n",
      "                      design_options.cpw_opts.meander.asymmetry          1.0          0.999211               1.0      0.000117   2.707263e-05        8.959404e-05       8.027091e-09\n",
      "                       design_options.cplr_opts.coupling_length          1.0          0.999208               1.0      0.000350   2.808745e-04        6.912551e-05       4.778336e-09\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.712510               1.0      0.000100   7.289044e-05        2.710956e-05       7.349284e-10\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000041               0.0      0.000000   6.429715e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT          1.0          0.999959               1.0      1.000000   1.011920e+00        1.192021e-02       1.420915e-04\n",
      "                                              coupler_type_NCap          1.0          0.999963               1.0      0.000000  -9.431619e-03        9.431619e-03       8.895544e-05\n",
      "                                            resonator_type_half          1.0          0.999960               1.0      0.000000  -8.767258e-03        8.767258e-03       7.686482e-05\n",
      "                                         resonator_type_quarter          1.0          0.999961               1.0      1.000000   1.012665e+00        1.266479e-02       1.603970e-04\n",
      "\n",
      "— Sample 1 (Unscaled) — X: cavity_frequency=8.36575e+09, kappa=768.707\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999943               1.0      0.000190   1.395828e-04        5.041722e-05       2.541896e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999947               1.0      0.000004   4.097080e-06        2.920147e-09       8.527260e-18\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999944               1.0     -0.001500  -1.517366e-03        1.736633e-05       3.015896e-10\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999946               1.0      0.000240   2.373499e-04        2.650065e-06       7.022847e-12\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999944               1.0      0.000030   2.962232e-05        3.776836e-07       1.426449e-13\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999946               1.0      0.000030   2.964481e-05        3.551942e-07       1.261629e-13\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999941               1.0      0.006700   6.430018e-03        2.699823e-04       7.289043e-08\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999947               1.0      0.000100   9.911247e-05        8.875310e-07       7.877114e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.007971               0.0      0.000000  -4.009008e-08                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.008047               0.0      0.000000  -2.099097e-06                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.982315               1.0      0.000050   4.903097e-05        9.690255e-07       9.390104e-13\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000057               0.0      0.000000   7.739811e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT          1.0          0.999943               1.0      0.000000   1.369081e-02        1.369081e-02       1.874382e-04\n",
      "                                              coupler_type_NCap          1.0          0.999949               1.0      1.000000   9.871519e-01        1.284814e-02       1.650747e-04\n",
      "                                            resonator_type_half          1.0          0.999946               1.0      1.000000   9.877160e-01        1.228404e-02       1.508976e-04\n",
      "                                         resonator_type_quarter          1.0          0.999947               1.0      0.000000   1.439971e-02        1.439971e-02       2.073516e-04\n",
      "\n",
      "— Sample 2 (Unscaled) — X: cavity_frequency=1.09991e+10, kappa=1010.75\n",
      "                                                          param  exists_true  exists_pred_prob  exists_pred_mask  ref_unscaled  pred_unscaled  abs_error_unscaled  sq_error_unscaled\n",
      "   design_options.claw_opts.connection_pads.readout.claw_length          1.0          0.999944               1.0      0.000080   1.394833e-04        5.948332e-05       3.538265e-09\n",
      "design_options.claw_opts.connection_pads.readout.ground_spacing          1.0          0.999947               1.0      0.000004   4.099723e-06        2.770700e-10       7.676776e-20\n",
      "                                 design_options.claw_opts.pos_x          1.0          0.999944               1.0     -0.001500  -1.472897e-03        2.710267e-05       7.345546e-10\n",
      "                          design_options.claw_opts.cross_length          1.0          0.999947               1.0      0.000240   2.392307e-04        7.692862e-07       5.918012e-13\n",
      "                           design_options.claw_opts.cross_width          1.0          0.999944               1.0      0.000030   2.985232e-05        1.476789e-07       2.180904e-14\n",
      "                             design_options.claw_opts.cross_gap          1.0          0.999947               1.0      0.000030   2.986404e-05        1.359648e-07       1.848641e-14\n",
      "                           design_options.cpw_opts.total_length          1.0          0.999942               1.0      0.005200   5.711648e-03        5.116476e-04       2.617833e-07\n",
      "                    design_options.cpw_opts.lead.start_straight          1.0          0.999947               1.0      0.000100   9.935430e-05        6.456971e-07       4.169248e-13\n",
      "                      design_options.cpw_opts.meander.asymmetry          0.0          0.004434               0.0      0.000000  -2.981633e-07                 NaN                NaN\n",
      "                       design_options.cplr_opts.coupling_length          0.0          0.004456               0.0      0.000000  -3.466586e-06                 NaN                NaN\n",
      "                      design_options.cpw_opts.lead.end_straight          1.0          0.987342               1.0      0.000050   4.909158e-05        9.084165e-07       8.252206e-13\n",
      "          design_options.cpw_opts.lead.start_jogged_extension.0          0.0          0.000057               0.0      0.000000   4.006353e-04                 NaN                NaN\n",
      "                                               coupler_type_CLT          1.0          0.999943               1.0      0.000000   5.688429e-03        5.688429e-03       3.235822e-05\n",
      "                                              coupler_type_NCap          1.0          0.999949               1.0      1.000000   9.947580e-01        5.241990e-03       2.747846e-05\n",
      "                                            resonator_type_half          1.0          0.999947               1.0      1.000000   9.957571e-01        4.242897e-03       1.800218e-05\n",
      "                                         resonator_type_quarter          1.0          0.999948               1.0      0.000000   5.551189e-03        5.551189e-03       3.081570e-05\n",
      "\n",
      "Global unscaled error stats (defined parameters only):\n",
      "  min abs_error: 5.577225238053812e-11\n",
      "  median abs_error: 3.588835597038269e-05\n",
      "  max abs_error: 0.14548468589782715\n",
      "\n",
      "Here onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load X feature names for the X scalers\n",
    "with open('X_names', 'r') as f:\n",
    "    X_index_names = f.read().splitlines()\n",
    "\n",
    "# unscale X\n",
    "X_test_unscaled = np.asarray(X_test_cur.copy())\n",
    "for i in range(X_test_unscaled.shape[0]):\n",
    "    for j in range(X_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_X_{X_index_names[j]}.save')\n",
    "        X_test_unscaled[i, j] = scaler.inverse_transform([[X_test_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# unscale y VALUES (refs and preds) – exists stays as 0/1 / probabilities\n",
    "y_value_test_unscaled = np.asarray(y_value_test_cur.copy(), dtype=float)\n",
    "y_value_pred_unscaled = np.asarray(y_value_pred.copy(), dtype=float)\n",
    "n_params = y_value_test_unscaled.shape[1]\n",
    "\n",
    "for i in range(y_value_test_unscaled.shape[0]):\n",
    "    for j in range(y_value_test_unscaled.shape[1]):\n",
    "        scaler = joblib.load(f'scalers/scaler_y_value__{headers[j]}_{y_encoding_format_name}_encoding.save')\n",
    "        y_value_test_unscaled[i, j] = scaler.inverse_transform([[y_value_test_unscaled[i, j]]])[0][0]\n",
    "        y_value_pred_unscaled[i, j] = scaler.inverse_transform([[y_value_pred_unscaled[i, j]]])[0][0]\n",
    "\n",
    "# errors (unscaled, values only)\n",
    "sq_errors_unscaled  = (y_value_test_unscaled - y_value_pred_unscaled) ** 2\n",
    "abs_errors_unscaled = np.abs(y_value_test_unscaled - y_value_pred_unscaled)\n",
    "\n",
    "# mask out parameters that are not defined (according to ground-truth exists)\n",
    "sq_errors_unscaled_masked  = np.where(y_exists_test_cur == 1.0, sq_errors_unscaled,  np.nan)\n",
    "abs_errors_unscaled_masked = np.where(y_exists_test_cur == 1.0, abs_errors_unscaled, np.nan)\n",
    "\n",
    "# build dataframe (unscaled)\n",
    "rows_unscaled = []\n",
    "n_samples_to_show = min(N_SAMPLES_TO_SHOW, len(X_test_unscaled))\n",
    "for i in range(n_samples_to_show):\n",
    "    cav_freq, kappa = X_test_unscaled[i, 0], X_test_unscaled[i, 1]\n",
    "    for j in range(n_params):\n",
    "        rows_unscaled.append({\n",
    "            \"sample_idx\": i,\n",
    "            \"cavity_frequency\": cav_freq,\n",
    "            \"kappa\": kappa,\n",
    "            \"param\": headers[j],\n",
    "            \"exists_true\": float(y_exists_test_cur[i, j]),\n",
    "            \"exists_pred_prob\": float(y_exists_pred_prob[i, j]),\n",
    "            \"exists_pred_mask\": float(y_exists_pred_mask[i, j]),\n",
    "            \"ref_unscaled\":  float(y_value_test_unscaled[i, j]),\n",
    "            \"pred_unscaled\": float(y_value_pred_unscaled[i, j]),\n",
    "            \"abs_error_unscaled\": float(abs_errors_unscaled_masked[i, j]),\n",
    "            \"sq_error_unscaled\":  float(sq_errors_unscaled_masked[i, j]),\n",
    "        })\n",
    "df_unscaled = pd.DataFrame(rows_unscaled)\n",
    "\n",
    "# save (unscaled)\n",
    "out_csv_unscaled = Path(f\"predictions_and_errors_unscaled_{y_encoding_format_name}.csv\")\n",
    "df_unscaled.to_csv(out_csv_unscaled, index=False, float_format=\"%.6g\")\n",
    "print(f\"\\nSaved CSV -> {out_csv_unscaled.resolve()}\\n\")\n",
    "\n",
    "# pretty print per-sample (unscaled)\n",
    "for i in range(n_samples_to_show):\n",
    "    sub = df_unscaled[df_unscaled[\"sample_idx\"] == i].copy()\n",
    "    sub = sub[[\n",
    "        \"param\",\n",
    "        \"exists_true\",\n",
    "        \"exists_pred_prob\",\n",
    "        \"exists_pred_mask\",\n",
    "        \"ref_unscaled\",\n",
    "        \"pred_unscaled\",\n",
    "        \"abs_error_unscaled\",\n",
    "        \"sq_error_unscaled\"\n",
    "    ]]\n",
    "    header_line = (\n",
    "        f\"— Sample {i} (Unscaled) — \"\n",
    "        f\"X: cavity_frequency={X_test_unscaled[i,0]:.6g}, kappa={X_test_unscaled[i,1]:.6g}\"\n",
    "    )\n",
    "    print(header_line)\n",
    "    print(sub.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# global stats over defined parameters only\n",
    "print(\"Global unscaled error stats (defined parameters only):\")\n",
    "print(\"  min abs_error:\", float(np.nanmin(abs_errors_unscaled_masked)))\n",
    "print(\"  median abs_error:\", float(np.nanmedian(abs_errors_unscaled_masked)))\n",
    "print(\"  max abs_error:\", float(np.nanmax(abs_errors_unscaled_masked)))\n",
    "print(\"\\nHere onehot/linear encoding and the MLP which maps categorical data to 1s and 0s is probably throwing off the global average. These will be rounded in the future and will probably always round to the right number to reconstruct the correct category-- but for now it might throw off the overall average error. In the future we might want to just have it consider the non-categorical data when finding an overall average and reporting that number.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810c676-fbc7-4fa0-8ebb-6d2e8d535f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125bf92-a6e5-4184-b128-f066af5281bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613ef96-143b-4551-aacf-aa52b963fdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926af15-e113-4f59-8f20-6ee916619a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860b771-2059-4f3f-88cc-05e64726b367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65de61e-3ca1-4b4f-a366-adc049c68161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
